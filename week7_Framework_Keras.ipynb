{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w6jPFfj2tFxG"
   },
   "source": [
    "### 1. NN (kaggle score: 0.98759)\n",
    "* Linear\n",
    "* 5 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 815,
     "status": "ok",
     "timestamp": 1584381038769,
     "user": {
      "displayName": "이재빈",
      "photoUrl": "",
      "userId": "06683534214657838443"
     },
     "user_tz": -540
    },
    "id": "uPxq-uBDsQ9I",
    "outputId": "a683af31-d69b-498b-fd8c-cb7a83c2d21d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/Colab Notebooks/200318_NN\n"
     ]
    }
   ],
   "source": [
    "cd /content/drive/My Drive/Colab Notebooks/200318_NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VwmQr7OfskeY"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 72370,
     "status": "ok",
     "timestamp": 1584381114261,
     "user": {
      "displayName": "이재빈",
      "photoUrl": "",
      "userId": "06683534214657838443"
     },
     "user_tz": -540
    },
    "id": "RlhTCMH7sv_2",
    "outputId": "412c9f3b-9e07-4b7e-f533-1653f22ce541"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 380.5MB 48kB/s \n",
      "\u001b[K     |████████████████████████████████| 4.3MB 49.2MB/s \n",
      "\u001b[K     |████████████████████████████████| 501kB 28.1MB/s \n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "!pip install -q tensorflow-gpu==2.0.0-rc1\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qiEh1L5Psntq"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train_df.csv\")\n",
    "test = pd.read_csv(\"test_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv(\"sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 244
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1162,
     "status": "ok",
     "timestamp": 1584381130233,
     "user": {
      "displayName": "이재빈",
      "photoUrl": "",
      "userId": "06683534214657838443"
     },
     "user_tz": -540
    },
    "id": "mpqbkRM3s-Ae",
    "outputId": "e0b3979c-cbc1-47fc-93b9-87342d976dd5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>pixel10</th>\n",
       "      <th>pixel11</th>\n",
       "      <th>pixel12</th>\n",
       "      <th>pixel13</th>\n",
       "      <th>pixel14</th>\n",
       "      <th>pixel15</th>\n",
       "      <th>pixel16</th>\n",
       "      <th>pixel17</th>\n",
       "      <th>pixel18</th>\n",
       "      <th>pixel19</th>\n",
       "      <th>pixel20</th>\n",
       "      <th>pixel21</th>\n",
       "      <th>pixel22</th>\n",
       "      <th>pixel23</th>\n",
       "      <th>pixel24</th>\n",
       "      <th>pixel25</th>\n",
       "      <th>pixel26</th>\n",
       "      <th>pixel27</th>\n",
       "      <th>pixel28</th>\n",
       "      <th>pixel29</th>\n",
       "      <th>pixel30</th>\n",
       "      <th>pixel31</th>\n",
       "      <th>pixel32</th>\n",
       "      <th>pixel33</th>\n",
       "      <th>pixel34</th>\n",
       "      <th>pixel35</th>\n",
       "      <th>pixel36</th>\n",
       "      <th>pixel37</th>\n",
       "      <th>pixel38</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel744</th>\n",
       "      <th>pixel745</th>\n",
       "      <th>pixel746</th>\n",
       "      <th>pixel747</th>\n",
       "      <th>pixel748</th>\n",
       "      <th>pixel749</th>\n",
       "      <th>pixel750</th>\n",
       "      <th>pixel751</th>\n",
       "      <th>pixel752</th>\n",
       "      <th>pixel753</th>\n",
       "      <th>pixel754</th>\n",
       "      <th>pixel755</th>\n",
       "      <th>pixel756</th>\n",
       "      <th>pixel757</th>\n",
       "      <th>pixel758</th>\n",
       "      <th>pixel759</th>\n",
       "      <th>pixel760</th>\n",
       "      <th>pixel761</th>\n",
       "      <th>pixel762</th>\n",
       "      <th>pixel763</th>\n",
       "      <th>pixel764</th>\n",
       "      <th>pixel765</th>\n",
       "      <th>pixel766</th>\n",
       "      <th>pixel767</th>\n",
       "      <th>pixel768</th>\n",
       "      <th>pixel769</th>\n",
       "      <th>pixel770</th>\n",
       "      <th>pixel771</th>\n",
       "      <th>pixel772</th>\n",
       "      <th>pixel773</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  ...  pixel780  pixel781  pixel782  pixel783\n",
       "0      7       0       0       0  ...         0         0         0         0\n",
       "1      8       0       0       0  ...         0         0         0         0\n",
       "2      7       0       0       0  ...         0         0         0         0\n",
       "3      6       0       0       0  ...         0         0         0         0\n",
       "4      5       0       0       0  ...         0         0         0         0\n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 261
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1271,
     "status": "ok",
     "timestamp": 1584381132581,
     "user": {
      "displayName": "이재빈",
      "photoUrl": "",
      "userId": "06683534214657838443"
     },
     "user_tz": -540
    },
    "id": "eHvYOT_1tG7R",
    "outputId": "495829b6-6c6d-4950-b0ff-61e44e66dbdd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>pixel10</th>\n",
       "      <th>pixel11</th>\n",
       "      <th>pixel12</th>\n",
       "      <th>pixel13</th>\n",
       "      <th>pixel14</th>\n",
       "      <th>pixel15</th>\n",
       "      <th>pixel16</th>\n",
       "      <th>pixel17</th>\n",
       "      <th>pixel18</th>\n",
       "      <th>pixel19</th>\n",
       "      <th>pixel20</th>\n",
       "      <th>pixel21</th>\n",
       "      <th>pixel22</th>\n",
       "      <th>pixel23</th>\n",
       "      <th>pixel24</th>\n",
       "      <th>pixel25</th>\n",
       "      <th>pixel26</th>\n",
       "      <th>pixel27</th>\n",
       "      <th>pixel28</th>\n",
       "      <th>pixel29</th>\n",
       "      <th>pixel30</th>\n",
       "      <th>pixel31</th>\n",
       "      <th>pixel32</th>\n",
       "      <th>pixel33</th>\n",
       "      <th>pixel34</th>\n",
       "      <th>pixel35</th>\n",
       "      <th>pixel36</th>\n",
       "      <th>pixel37</th>\n",
       "      <th>pixel38</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel744</th>\n",
       "      <th>pixel745</th>\n",
       "      <th>pixel746</th>\n",
       "      <th>pixel747</th>\n",
       "      <th>pixel748</th>\n",
       "      <th>pixel749</th>\n",
       "      <th>pixel750</th>\n",
       "      <th>pixel751</th>\n",
       "      <th>pixel752</th>\n",
       "      <th>pixel753</th>\n",
       "      <th>pixel754</th>\n",
       "      <th>pixel755</th>\n",
       "      <th>pixel756</th>\n",
       "      <th>pixel757</th>\n",
       "      <th>pixel758</th>\n",
       "      <th>pixel759</th>\n",
       "      <th>pixel760</th>\n",
       "      <th>pixel761</th>\n",
       "      <th>pixel762</th>\n",
       "      <th>pixel763</th>\n",
       "      <th>pixel764</th>\n",
       "      <th>pixel765</th>\n",
       "      <th>pixel766</th>\n",
       "      <th>pixel767</th>\n",
       "      <th>pixel768</th>\n",
       "      <th>pixel769</th>\n",
       "      <th>pixel770</th>\n",
       "      <th>pixel771</th>\n",
       "      <th>pixel772</th>\n",
       "      <th>pixel773</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>57808</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4960</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35755</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15543</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48968</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  pixel0  pixel1  pixel2  ...  pixel780  pixel781  pixel782  pixel783\n",
       "0       57808       0       0       0  ...         0         0         0         0\n",
       "1        4960       0       0       0  ...         0         0         0         0\n",
       "2       35755       0       0       0  ...         0         0         0         0\n",
       "3       15543       0       0       0  ...         0         0         0         0\n",
       "4       48968       0       0       0  ...         0         0         0         0\n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S5XFr9qytW23"
   },
   "outputs": [],
   "source": [
    "X = train.iloc[:, 1:].values / 255\n",
    "y = train.iloc[:, 0].values\n",
    "X_test = test.iloc[:, 1:].values / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1641,
     "status": "ok",
     "timestamp": 1584381140349,
     "user": {
      "displayName": "이재빈",
      "photoUrl": "",
      "userId": "06683534214657838443"
     },
     "user_tz": -540
    },
    "id": "BjLjQf5otIID",
    "outputId": "8e56cf64-98c9-466a-ccac-3e652df17745"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29400, 784) (12600, 784) (29400,) (12600,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=77)\n",
    "print(x_train.shape, x_val.shape, y_train.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 590
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3887,
     "status": "ok",
     "timestamp": 1584381150127,
     "user": {
      "displayName": "이재빈",
      "photoUrl": "",
      "userId": "06683534214657838443"
     },
     "user_tz": -540
    },
    "id": "fXmm71sKtVAK",
    "outputId": "969d96a0-77a5-48e2-d4c5-ce8a9f9e5435"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjsAAAI9CAYAAADcj7lGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n7f8DwAoREfV6wM4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x720 with 100 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(nrows=10, ncols=10, figsize=(10,10))\n",
    "\n",
    "for i in range(10): # Column by column\n",
    "    num_i = x_train[y_train == i]\n",
    "    ax[0][i].set_title(i)\n",
    "    for j in range(10): # Row by row\n",
    "        ax[j][i].axis('off')\n",
    "        ax[j][i].imshow(num_i[j, :].astype(np.uint8).reshape(28, 28), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7196,
     "status": "ok",
     "timestamp": 1584381174880,
     "user": {
      "displayName": "이재빈",
      "photoUrl": "",
      "userId": "06683534214657838443"
     },
     "user_tz": -540
    },
    "id": "UYTx4OYmt0dN",
    "outputId": "b7ebfb83-1cd3-4ac0-d5d3-ac3d691f4635"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras-rectified-adam\n",
      "  Downloading https://files.pythonhosted.org/packages/21/79/9521f66b92186702cb58a214c1b923b416266381cd824e15a1733f6a5b06/keras-rectified-adam-0.17.0.tar.gz\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from keras-rectified-adam) (1.17.5)\n",
      "Requirement already satisfied: Keras in /usr/local/lib/python3.6/dist-packages (from keras-rectified-adam) (2.2.5)\n",
      "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-rectified-adam) (1.0.8)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras->keras-rectified-adam) (3.13)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras->keras-rectified-adam) (2.8.0)\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-rectified-adam) (1.4.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-rectified-adam) (1.1.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-rectified-adam) (1.12.0)\n",
      "Building wheels for collected packages: keras-rectified-adam\n",
      "  Building wheel for keras-rectified-adam (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for keras-rectified-adam: filename=keras_rectified_adam-0.17.0-cp36-none-any.whl size=14781 sha256=f79cd1c1d1010d6254bcadb2ffb75bbedb658da24ad237ae9eefc19aa9f49c00\n",
      "  Stored in directory: /root/.cache/pip/wheels/7b/01/27/3a934e1a5644f5b93c720422a6ef97034ea78a21ba71cfb549\n",
      "Successfully built keras-rectified-adam\n",
      "Installing collected packages: keras-rectified-adam\n",
      "Successfully installed keras-rectified-adam-0.17.0\n"
     ]
    }
   ],
   "source": [
    "!pip install keras-rectified-adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1198,
     "status": "ok",
     "timestamp": 1584381178105,
     "user": {
      "displayName": "이재빈",
      "photoUrl": "",
      "userId": "06683534214657838443"
     },
     "user_tz": -540
    },
    "id": "dLNn9KsuvYYd",
    "outputId": "751f7c7a-21ef-4953-bb05-15ae1bd297cb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras_radam.training import RAdamOptimizer\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jfZFrOgiu2ty"
   },
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(512, input_shape=(784,)),\n",
    "        tf.keras.layers.BatchNormalization(momentum=0.5, epsilon=1e-5, gamma_initializer=\"uniform\"),\n",
    "        tf.keras.layers.LeakyReLU(alpha=0.1),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "\n",
    "        tf.keras.layers.Dense(256),\n",
    "        tf.keras.layers.BatchNormalization(momentum=0.5, epsilon=1e-5, gamma_initializer=\"uniform\"),\n",
    "        tf.keras.layers.LeakyReLU(alpha=0.1),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "\n",
    "        tf.keras.layers.Dense(128),\n",
    "        tf.keras.layers.BatchNormalization(momentum=0.5, epsilon=1e-5, gamma_initializer=\"uniform\"),\n",
    "        tf.keras.layers.LeakyReLU(alpha=0.1),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "\n",
    "        tf.keras.layers.Dense(64),\n",
    "        tf.keras.layers.BatchNormalization(momentum=0.5, epsilon=1e-5, gamma_initializer=\"uniform\"),\n",
    "        tf.keras.layers.LeakyReLU(alpha=0.1),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "\n",
    "        tf.keras.layers.Dense(32),\n",
    "        tf.keras.layers.BatchNormalization(momentum=0.5, epsilon=1e-5, gamma_initializer=\"uniform\"),\n",
    "        tf.keras.layers.LeakyReLU(alpha=0.1),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "\n",
    "        tf.keras.layers.Dense(num_classes, activation=\"softmax\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 977
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1143,
     "status": "ok",
     "timestamp": 1584381191204,
     "user": {
      "displayName": "이재빈",
      "photoUrl": "",
      "userId": "06683534214657838443"
     },
     "user_tz": -540
    },
    "id": "yfpqF1sEvVU0",
    "outputId": "1de322d3-0576-4b50-c321-c1530289a01f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 580,778\n",
      "Trainable params: 578,794\n",
      "Non-trainable params: 1,984\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer = RAdamOptimizer(learning_rate=1e-4), loss=\"sparse_categorical_crossentropy\", metrics=[\"acc\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 174071,
     "status": "ok",
     "timestamp": 1584381371043,
     "user": {
      "displayName": "이재빈",
      "photoUrl": "",
      "userId": "06683534214657838443"
     },
     "user_tz": -540
    },
    "id": "uSSdh0YwjCtl",
    "outputId": "e2eda61a-ab4c-4bc1-a0e7-720a69870479"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Train on 29400 samples, validate on 12600 samples\n",
      "Epoch 1/200\n",
      "29400/29400 - 4s - loss: 2.3035 - acc: 0.1050 - val_loss: 2.3013 - val_acc: 0.1247\n",
      "Epoch 2/200\n",
      "29400/29400 - 1s - loss: 2.2998 - acc: 0.1255 - val_loss: 2.2965 - val_acc: 0.2047\n",
      "Epoch 3/200\n",
      "29400/29400 - 1s - loss: 2.2934 - acc: 0.1675 - val_loss: 2.2898 - val_acc: 0.3443\n",
      "Epoch 4/200\n",
      "29400/29400 - 1s - loss: 2.2855 - acc: 0.2297 - val_loss: 2.2808 - val_acc: 0.4944\n",
      "Epoch 5/200\n",
      "29400/29400 - 1s - loss: 2.2767 - acc: 0.3086 - val_loss: 2.2712 - val_acc: 0.6060\n",
      "Epoch 6/200\n",
      "29400/29400 - 1s - loss: 2.2667 - acc: 0.3896 - val_loss: 2.2595 - val_acc: 0.6902\n",
      "Epoch 7/200\n",
      "29400/29400 - 1s - loss: 2.2573 - acc: 0.4572 - val_loss: 2.2480 - val_acc: 0.7525\n",
      "Epoch 8/200\n",
      "29400/29400 - 1s - loss: 2.2462 - acc: 0.5265 - val_loss: 2.2358 - val_acc: 0.8040\n",
      "Epoch 9/200\n",
      "29400/29400 - 1s - loss: 2.2351 - acc: 0.5876 - val_loss: 2.2221 - val_acc: 0.8316\n",
      "Epoch 10/200\n",
      "29400/29400 - 1s - loss: 2.2237 - acc: 0.6339 - val_loss: 2.2101 - val_acc: 0.8547\n",
      "Epoch 11/200\n",
      "29400/29400 - 1s - loss: 2.2118 - acc: 0.6760 - val_loss: 2.1958 - val_acc: 0.8690\n",
      "Epoch 12/200\n",
      "29400/29400 - 1s - loss: 2.1991 - acc: 0.7118 - val_loss: 2.1820 - val_acc: 0.8832\n",
      "Epoch 13/200\n",
      "29400/29400 - 1s - loss: 2.1859 - acc: 0.7442 - val_loss: 2.1688 - val_acc: 0.8931\n",
      "Epoch 14/200\n",
      "29400/29400 - 1s - loss: 2.1717 - acc: 0.7703 - val_loss: 2.1523 - val_acc: 0.8981\n",
      "Epoch 15/200\n",
      "29400/29400 - 1s - loss: 2.1576 - acc: 0.7914 - val_loss: 2.1365 - val_acc: 0.9106\n",
      "Epoch 16/200\n",
      "29400/29400 - 1s - loss: 2.1430 - acc: 0.8074 - val_loss: 2.1201 - val_acc: 0.9153\n",
      "Epoch 17/200\n",
      "29400/29400 - 1s - loss: 2.1276 - acc: 0.8266 - val_loss: 2.1025 - val_acc: 0.9237\n",
      "Epoch 18/200\n",
      "29400/29400 - 1s - loss: 2.1111 - acc: 0.8423 - val_loss: 2.0850 - val_acc: 0.9252\n",
      "Epoch 19/200\n",
      "29400/29400 - 1s - loss: 2.0945 - acc: 0.8545 - val_loss: 2.0685 - val_acc: 0.9326\n",
      "Epoch 20/200\n",
      "29400/29400 - 1s - loss: 2.0774 - acc: 0.8677 - val_loss: 2.0471 - val_acc: 0.9382\n",
      "Epoch 21/200\n",
      "29400/29400 - 1s - loss: 2.0606 - acc: 0.8780 - val_loss: 2.0296 - val_acc: 0.9413\n",
      "Epoch 22/200\n",
      "29400/29400 - 1s - loss: 2.0410 - acc: 0.8923 - val_loss: 2.0097 - val_acc: 0.9452\n",
      "Epoch 23/200\n",
      "29400/29400 - 1s - loss: 2.0232 - acc: 0.9027 - val_loss: 1.9891 - val_acc: 0.9467\n",
      "Epoch 24/200\n",
      "29400/29400 - 1s - loss: 2.0046 - acc: 0.9075 - val_loss: 1.9701 - val_acc: 0.9494\n",
      "Epoch 25/200\n",
      "29400/29400 - 1s - loss: 1.9849 - acc: 0.9173 - val_loss: 1.9503 - val_acc: 0.9516\n",
      "Epoch 26/200\n",
      "29400/29400 - 1s - loss: 1.9665 - acc: 0.9217 - val_loss: 1.9284 - val_acc: 0.9551\n",
      "Epoch 27/200\n",
      "29400/29400 - 1s - loss: 1.9455 - acc: 0.9291 - val_loss: 1.9096 - val_acc: 0.9573\n",
      "Epoch 28/200\n",
      "29400/29400 - 1s - loss: 1.9251 - acc: 0.9343 - val_loss: 1.8871 - val_acc: 0.9588\n",
      "Epoch 29/200\n",
      "29400/29400 - 1s - loss: 1.9051 - acc: 0.9394 - val_loss: 1.8624 - val_acc: 0.9606\n",
      "Epoch 30/200\n",
      "29400/29400 - 1s - loss: 1.8825 - acc: 0.9411 - val_loss: 1.8406 - val_acc: 0.9625\n",
      "Epoch 31/200\n",
      "29400/29400 - 1s - loss: 1.8614 - acc: 0.9467 - val_loss: 1.8175 - val_acc: 0.9630\n",
      "Epoch 32/200\n",
      "29400/29400 - 1s - loss: 1.8387 - acc: 0.9479 - val_loss: 1.7947 - val_acc: 0.9652\n",
      "Epoch 33/200\n",
      "29400/29400 - 1s - loss: 1.8168 - acc: 0.9508 - val_loss: 1.7711 - val_acc: 0.9672\n",
      "Epoch 34/200\n",
      "29400/29400 - 1s - loss: 1.7937 - acc: 0.9531 - val_loss: 1.7466 - val_acc: 0.9667\n",
      "Epoch 35/200\n",
      "29400/29400 - 1s - loss: 1.7701 - acc: 0.9559 - val_loss: 1.7223 - val_acc: 0.9689\n",
      "Epoch 36/200\n",
      "29400/29400 - 1s - loss: 1.7460 - acc: 0.9562 - val_loss: 1.6999 - val_acc: 0.9696\n",
      "Epoch 37/200\n",
      "29400/29400 - 1s - loss: 1.7213 - acc: 0.9610 - val_loss: 1.6732 - val_acc: 0.9714\n",
      "Epoch 38/200\n",
      "29400/29400 - 1s - loss: 1.6953 - acc: 0.9628 - val_loss: 1.6447 - val_acc: 0.9729\n",
      "Epoch 39/200\n",
      "29400/29400 - 1s - loss: 1.6732 - acc: 0.9647 - val_loss: 1.6162 - val_acc: 0.9725\n",
      "Epoch 40/200\n",
      "29400/29400 - 1s - loss: 1.6464 - acc: 0.9665 - val_loss: 1.5925 - val_acc: 0.9745\n",
      "Epoch 41/200\n",
      "29400/29400 - 1s - loss: 1.6222 - acc: 0.9676 - val_loss: 1.5692 - val_acc: 0.9744\n",
      "Epoch 42/200\n",
      "29400/29400 - 1s - loss: 1.5957 - acc: 0.9684 - val_loss: 1.5375 - val_acc: 0.9760\n",
      "Epoch 43/200\n",
      "29400/29400 - 1s - loss: 1.5714 - acc: 0.9698 - val_loss: 1.5148 - val_acc: 0.9763\n",
      "Epoch 44/200\n",
      "29400/29400 - 1s - loss: 1.5452 - acc: 0.9728 - val_loss: 1.4908 - val_acc: 0.9766\n",
      "Epoch 45/200\n",
      "29400/29400 - 1s - loss: 1.5173 - acc: 0.9741 - val_loss: 1.4586 - val_acc: 0.9765\n",
      "Epoch 46/200\n",
      "29400/29400 - 1s - loss: 1.4934 - acc: 0.9749 - val_loss: 1.4333 - val_acc: 0.9785\n",
      "Epoch 47/200\n",
      "29400/29400 - 1s - loss: 1.4666 - acc: 0.9751 - val_loss: 1.4072 - val_acc: 0.9781\n",
      "Epoch 48/200\n",
      "29400/29400 - 1s - loss: 1.4404 - acc: 0.9753 - val_loss: 1.3743 - val_acc: 0.9793\n",
      "Epoch 49/200\n",
      "29400/29400 - 1s - loss: 1.4121 - acc: 0.9782 - val_loss: 1.3499 - val_acc: 0.9791\n",
      "Epoch 50/200\n",
      "29400/29400 - 1s - loss: 1.3864 - acc: 0.9793 - val_loss: 1.3222 - val_acc: 0.9805\n",
      "Epoch 51/200\n",
      "29400/29400 - 1s - loss: 1.3592 - acc: 0.9794 - val_loss: 1.2949 - val_acc: 0.9799\n",
      "Epoch 52/200\n",
      "29400/29400 - 1s - loss: 1.3337 - acc: 0.9809 - val_loss: 1.2684 - val_acc: 0.9813\n",
      "Epoch 53/200\n",
      "29400/29400 - 1s - loss: 1.3060 - acc: 0.9821 - val_loss: 1.2438 - val_acc: 0.9813\n",
      "Epoch 54/200\n",
      "29400/29400 - 1s - loss: 1.2806 - acc: 0.9816 - val_loss: 1.2147 - val_acc: 0.9812\n",
      "Epoch 55/200\n",
      "29400/29400 - 1s - loss: 1.2534 - acc: 0.9831 - val_loss: 1.1818 - val_acc: 0.9821\n",
      "Epoch 56/200\n",
      "29400/29400 - 1s - loss: 1.2253 - acc: 0.9841 - val_loss: 1.1472 - val_acc: 0.9825\n",
      "Epoch 57/200\n",
      "29400/29400 - 1s - loss: 1.1983 - acc: 0.9848 - val_loss: 1.1241 - val_acc: 0.9831\n",
      "Epoch 58/200\n",
      "29400/29400 - 1s - loss: 1.1725 - acc: 0.9850 - val_loss: 1.1081 - val_acc: 0.9829\n",
      "Epoch 59/200\n",
      "29400/29400 - 1s - loss: 1.1457 - acc: 0.9862 - val_loss: 1.0737 - val_acc: 0.9839\n",
      "Epoch 60/200\n",
      "29400/29400 - 1s - loss: 1.1203 - acc: 0.9870 - val_loss: 1.0488 - val_acc: 0.9843\n",
      "Epoch 61/200\n",
      "29400/29400 - 1s - loss: 1.0941 - acc: 0.9877 - val_loss: 1.0166 - val_acc: 0.9836\n",
      "Epoch 62/200\n",
      "29400/29400 - 1s - loss: 1.0677 - acc: 0.9878 - val_loss: 0.9950 - val_acc: 0.9838\n",
      "Epoch 63/200\n",
      "29400/29400 - 1s - loss: 1.0430 - acc: 0.9893 - val_loss: 0.9638 - val_acc: 0.9844\n",
      "Epoch 64/200\n",
      "29400/29400 - 1s - loss: 1.0186 - acc: 0.9890 - val_loss: 0.9445 - val_acc: 0.9845\n",
      "Epoch 65/200\n",
      "29400/29400 - 1s - loss: 0.9936 - acc: 0.9887 - val_loss: 0.9174 - val_acc: 0.9849\n",
      "Epoch 66/200\n",
      "29400/29400 - 1s - loss: 0.9699 - acc: 0.9898 - val_loss: 0.8911 - val_acc: 0.9852\n",
      "Epoch 67/200\n",
      "29400/29400 - 1s - loss: 0.9449 - acc: 0.9907 - val_loss: 0.8668 - val_acc: 0.9856\n",
      "Epoch 68/200\n",
      "29400/29400 - 1s - loss: 0.9195 - acc: 0.9912 - val_loss: 0.8416 - val_acc: 0.9859\n",
      "Epoch 69/200\n",
      "29400/29400 - 1s - loss: 0.8939 - acc: 0.9922 - val_loss: 0.8145 - val_acc: 0.9853\n",
      "Epoch 70/200\n",
      "29400/29400 - 1s - loss: 0.8721 - acc: 0.9921 - val_loss: 0.7924 - val_acc: 0.9860\n",
      "Epoch 71/200\n",
      "29400/29400 - 1s - loss: 0.8494 - acc: 0.9924 - val_loss: 0.7732 - val_acc: 0.9868\n",
      "Epoch 72/200\n",
      "29400/29400 - 1s - loss: 0.8262 - acc: 0.9930 - val_loss: 0.7499 - val_acc: 0.9868\n",
      "Epoch 73/200\n",
      "29400/29400 - 1s - loss: 0.8063 - acc: 0.9929 - val_loss: 0.7240 - val_acc: 0.9858\n",
      "Epoch 74/200\n",
      "29400/29400 - 1s - loss: 0.7839 - acc: 0.9934 - val_loss: 0.7015 - val_acc: 0.9868\n",
      "Epoch 75/200\n",
      "29400/29400 - 1s - loss: 0.7620 - acc: 0.9935 - val_loss: 0.6816 - val_acc: 0.9879\n",
      "Epoch 76/200\n",
      "29400/29400 - 1s - loss: 0.7405 - acc: 0.9935 - val_loss: 0.6651 - val_acc: 0.9875\n",
      "Epoch 77/200\n",
      "29400/29400 - 1s - loss: 0.7199 - acc: 0.9947 - val_loss: 0.6361 - val_acc: 0.9870\n",
      "Epoch 78/200\n",
      "29400/29400 - 1s - loss: 0.7008 - acc: 0.9953 - val_loss: 0.6199 - val_acc: 0.9875\n",
      "Epoch 79/200\n",
      "29400/29400 - 1s - loss: 0.6820 - acc: 0.9952 - val_loss: 0.6037 - val_acc: 0.9876\n",
      "Epoch 80/200\n",
      "29400/29400 - 1s - loss: 0.6613 - acc: 0.9953 - val_loss: 0.5814 - val_acc: 0.9869\n",
      "Epoch 81/200\n",
      "29400/29400 - 1s - loss: 0.6429 - acc: 0.9957 - val_loss: 0.5625 - val_acc: 0.9876\n",
      "Epoch 82/200\n",
      "29400/29400 - 1s - loss: 0.6257 - acc: 0.9956 - val_loss: 0.5459 - val_acc: 0.9879\n",
      "Epoch 83/200\n",
      "29400/29400 - 1s - loss: 0.6091 - acc: 0.9960 - val_loss: 0.5312 - val_acc: 0.9888\n",
      "Epoch 84/200\n",
      "29400/29400 - 1s - loss: 0.5896 - acc: 0.9962 - val_loss: 0.5108 - val_acc: 0.9881\n",
      "Epoch 85/200\n",
      "29400/29400 - 1s - loss: 0.5741 - acc: 0.9968 - val_loss: 0.4949 - val_acc: 0.9883\n",
      "Epoch 86/200\n",
      "29400/29400 - 1s - loss: 0.5575 - acc: 0.9969 - val_loss: 0.4786 - val_acc: 0.9887\n",
      "Epoch 87/200\n",
      "29400/29400 - 1s - loss: 0.5414 - acc: 0.9965 - val_loss: 0.4670 - val_acc: 0.9877\n",
      "Epoch 88/200\n",
      "29400/29400 - 1s - loss: 0.5269 - acc: 0.9965 - val_loss: 0.4483 - val_acc: 0.9888\n",
      "Epoch 89/200\n",
      "29400/29400 - 1s - loss: 0.5133 - acc: 0.9971 - val_loss: 0.4357 - val_acc: 0.9880\n",
      "Epoch 90/200\n",
      "29400/29400 - 1s - loss: 0.4985 - acc: 0.9973 - val_loss: 0.4212 - val_acc: 0.9892\n",
      "Epoch 91/200\n",
      "29400/29400 - 1s - loss: 0.4832 - acc: 0.9973 - val_loss: 0.4119 - val_acc: 0.9890\n",
      "Epoch 92/200\n",
      "29400/29400 - 1s - loss: 0.4720 - acc: 0.9974 - val_loss: 0.3958 - val_acc: 0.9896\n",
      "Epoch 93/200\n",
      "29400/29400 - 1s - loss: 0.4554 - acc: 0.9978 - val_loss: 0.3852 - val_acc: 0.9884\n",
      "Epoch 94/200\n",
      "29400/29400 - 1s - loss: 0.4426 - acc: 0.9976 - val_loss: 0.3690 - val_acc: 0.9887\n",
      "Epoch 95/200\n",
      "29400/29400 - 1s - loss: 0.4317 - acc: 0.9979 - val_loss: 0.3610 - val_acc: 0.9885\n",
      "Epoch 96/200\n",
      "29400/29400 - 1s - loss: 0.4191 - acc: 0.9977 - val_loss: 0.3479 - val_acc: 0.9886\n",
      "Epoch 97/200\n",
      "29400/29400 - 1s - loss: 0.4076 - acc: 0.9979 - val_loss: 0.3386 - val_acc: 0.9897\n",
      "Epoch 98/200\n",
      "29400/29400 - 1s - loss: 0.3952 - acc: 0.9979 - val_loss: 0.3301 - val_acc: 0.9883\n",
      "Epoch 99/200\n",
      "29400/29400 - 1s - loss: 0.3849 - acc: 0.9982 - val_loss: 0.3162 - val_acc: 0.9891\n",
      "Epoch 100/200\n",
      "29400/29400 - 1s - loss: 0.3763 - acc: 0.9982 - val_loss: 0.3085 - val_acc: 0.9891\n",
      "Epoch 101/200\n",
      "29400/29400 - 1s - loss: 0.3651 - acc: 0.9985 - val_loss: 0.2955 - val_acc: 0.9894\n",
      "Epoch 102/200\n",
      "29400/29400 - 1s - loss: 0.3557 - acc: 0.9981 - val_loss: 0.2919 - val_acc: 0.9895\n",
      "Epoch 103/200\n",
      "29400/29400 - 1s - loss: 0.3451 - acc: 0.9984 - val_loss: 0.2798 - val_acc: 0.9894\n",
      "Epoch 104/200\n",
      "29400/29400 - 1s - loss: 0.3376 - acc: 0.9985 - val_loss: 0.2747 - val_acc: 0.9899\n",
      "Epoch 105/200\n",
      "29400/29400 - 1s - loss: 0.3277 - acc: 0.9984 - val_loss: 0.2643 - val_acc: 0.9883\n",
      "Epoch 106/200\n",
      "29400/29400 - 1s - loss: 0.3184 - acc: 0.9983 - val_loss: 0.2523 - val_acc: 0.9898\n",
      "Epoch 107/200\n",
      "29400/29400 - 1s - loss: 0.3083 - acc: 0.9987 - val_loss: 0.2449 - val_acc: 0.9892\n",
      "Epoch 108/200\n",
      "29400/29400 - 1s - loss: 0.3007 - acc: 0.9986 - val_loss: 0.2400 - val_acc: 0.9892\n",
      "Epoch 109/200\n",
      "29400/29400 - 1s - loss: 0.2941 - acc: 0.9987 - val_loss: 0.2331 - val_acc: 0.9901\n",
      "Epoch 110/200\n",
      "29400/29400 - 1s - loss: 0.2833 - acc: 0.9991 - val_loss: 0.2261 - val_acc: 0.9890\n",
      "Epoch 111/200\n",
      "29400/29400 - 1s - loss: 0.2764 - acc: 0.9991 - val_loss: 0.2192 - val_acc: 0.9894\n",
      "Epoch 112/200\n",
      "29400/29400 - 1s - loss: 0.2695 - acc: 0.9991 - val_loss: 0.2148 - val_acc: 0.9893\n",
      "Epoch 113/200\n",
      "29400/29400 - 1s - loss: 0.2614 - acc: 0.9990 - val_loss: 0.2085 - val_acc: 0.9894\n",
      "Epoch 114/200\n",
      "29400/29400 - 1s - loss: 0.2565 - acc: 0.9990 - val_loss: 0.2028 - val_acc: 0.9890\n",
      "Epoch 115/200\n",
      "29400/29400 - 1s - loss: 0.2482 - acc: 0.9992 - val_loss: 0.1972 - val_acc: 0.9898\n",
      "Epoch 116/200\n",
      "29400/29400 - 1s - loss: 0.2442 - acc: 0.9989 - val_loss: 0.1919 - val_acc: 0.9900\n",
      "Epoch 117/200\n",
      "29400/29400 - 1s - loss: 0.2379 - acc: 0.9991 - val_loss: 0.1900 - val_acc: 0.9898\n",
      "Epoch 118/200\n",
      "29400/29400 - 1s - loss: 0.2315 - acc: 0.9988 - val_loss: 0.1805 - val_acc: 0.9893\n",
      "Epoch 119/200\n",
      "29400/29400 - 1s - loss: 0.2244 - acc: 0.9993 - val_loss: 0.1778 - val_acc: 0.9896\n",
      "Epoch 120/200\n",
      "29400/29400 - 1s - loss: 0.2189 - acc: 0.9994 - val_loss: 0.1729 - val_acc: 0.9890\n",
      "Epoch 121/200\n",
      "29400/29400 - 1s - loss: 0.2122 - acc: 0.9994 - val_loss: 0.1691 - val_acc: 0.9896\n",
      "Epoch 122/200\n",
      "29400/29400 - 1s - loss: 0.2093 - acc: 0.9993 - val_loss: 0.1667 - val_acc: 0.9891\n",
      "Epoch 123/200\n",
      "29400/29400 - 1s - loss: 0.2021 - acc: 0.9997 - val_loss: 0.1591 - val_acc: 0.9887\n",
      "Epoch 124/200\n",
      "29400/29400 - 1s - loss: 0.1966 - acc: 0.9994 - val_loss: 0.1550 - val_acc: 0.9886\n",
      "Epoch 125/200\n",
      "29400/29400 - 1s - loss: 0.1923 - acc: 0.9994 - val_loss: 0.1539 - val_acc: 0.9897\n",
      "Epoch 126/200\n",
      "29400/29400 - 1s - loss: 0.1876 - acc: 0.9994 - val_loss: 0.1497 - val_acc: 0.9887\n",
      "Epoch 127/200\n",
      "29400/29400 - 1s - loss: 0.1836 - acc: 0.9993 - val_loss: 0.1460 - val_acc: 0.9896\n",
      "Epoch 128/200\n",
      "29400/29400 - 1s - loss: 0.1786 - acc: 0.9995 - val_loss: 0.1394 - val_acc: 0.9897\n",
      "Epoch 129/200\n",
      "29400/29400 - 1s - loss: 0.1748 - acc: 0.9997 - val_loss: 0.1373 - val_acc: 0.9898\n",
      "Epoch 130/200\n",
      "29400/29400 - 1s - loss: 0.1699 - acc: 0.9994 - val_loss: 0.1355 - val_acc: 0.9890\n",
      "Epoch 131/200\n",
      "29400/29400 - 1s - loss: 0.1665 - acc: 0.9997 - val_loss: 0.1327 - val_acc: 0.9890\n",
      "Epoch 132/200\n",
      "29400/29400 - 1s - loss: 0.1628 - acc: 0.9997 - val_loss: 0.1294 - val_acc: 0.9894\n",
      "Epoch 133/200\n",
      "29400/29400 - 1s - loss: 0.1601 - acc: 0.9994 - val_loss: 0.1259 - val_acc: 0.9900\n",
      "Epoch 134/200\n",
      "29400/29400 - 1s - loss: 0.1535 - acc: 0.9997 - val_loss: 0.1247 - val_acc: 0.9890\n",
      "Epoch 135/200\n",
      "29400/29400 - 1s - loss: 0.1504 - acc: 0.9996 - val_loss: 0.1215 - val_acc: 0.9887\n",
      "Epoch 136/200\n",
      "29400/29400 - 1s - loss: 0.1486 - acc: 0.9997 - val_loss: 0.1199 - val_acc: 0.9886\n",
      "Epoch 137/200\n",
      "29400/29400 - 1s - loss: 0.1444 - acc: 0.9995 - val_loss: 0.1152 - val_acc: 0.9898\n",
      "Epoch 138/200\n",
      "29400/29400 - 1s - loss: 0.1410 - acc: 0.9996 - val_loss: 0.1132 - val_acc: 0.9890\n",
      "Epoch 139/200\n",
      "29400/29400 - 1s - loss: 0.1382 - acc: 0.9997 - val_loss: 0.1104 - val_acc: 0.9899\n",
      "Epoch 140/200\n",
      "29400/29400 - 1s - loss: 0.1354 - acc: 0.9995 - val_loss: 0.1091 - val_acc: 0.9891\n",
      "Epoch 141/200\n",
      "29400/29400 - 1s - loss: 0.1319 - acc: 0.9998 - val_loss: 0.1081 - val_acc: 0.9898\n",
      "Epoch 142/200\n",
      "29400/29400 - 1s - loss: 0.1285 - acc: 0.9995 - val_loss: 0.1046 - val_acc: 0.9894\n",
      "Epoch 143/200\n",
      "29400/29400 - 1s - loss: 0.1255 - acc: 0.9996 - val_loss: 0.1028 - val_acc: 0.9899\n",
      "Epoch 144/200\n",
      "29400/29400 - 1s - loss: 0.1228 - acc: 0.9997 - val_loss: 0.1010 - val_acc: 0.9894\n",
      "Epoch 145/200\n",
      "29400/29400 - 1s - loss: 0.1211 - acc: 0.9996 - val_loss: 0.1010 - val_acc: 0.9898\n",
      "Epoch 146/200\n",
      "29400/29400 - 1s - loss: 0.1172 - acc: 0.9998 - val_loss: 0.0995 - val_acc: 0.9887\n",
      "Epoch 147/200\n",
      "29400/29400 - 1s - loss: 0.1150 - acc: 0.9997 - val_loss: 0.0983 - val_acc: 0.9887\n",
      "Epoch 148/200\n",
      "29400/29400 - 1s - loss: 0.1129 - acc: 0.9997 - val_loss: 0.0950 - val_acc: 0.9891\n",
      "Epoch 149/200\n",
      "29400/29400 - 1s - loss: 0.1099 - acc: 0.9999 - val_loss: 0.0932 - val_acc: 0.9898\n",
      "Epoch 150/200\n",
      "29400/29400 - 1s - loss: 0.1068 - acc: 0.9998 - val_loss: 0.0908 - val_acc: 0.9898\n",
      "Epoch 151/200\n",
      "29400/29400 - 1s - loss: 0.1047 - acc: 0.9998 - val_loss: 0.0899 - val_acc: 0.9898\n",
      "Epoch 152/200\n",
      "29400/29400 - 1s - loss: 0.1028 - acc: 0.9999 - val_loss: 0.0885 - val_acc: 0.9902\n",
      "Epoch 153/200\n",
      "29400/29400 - 1s - loss: 0.1006 - acc: 0.9996 - val_loss: 0.0868 - val_acc: 0.9901\n",
      "Epoch 154/200\n",
      "29400/29400 - 1s - loss: 0.0982 - acc: 0.9999 - val_loss: 0.0857 - val_acc: 0.9898\n",
      "Epoch 155/200\n",
      "29400/29400 - 1s - loss: 0.0960 - acc: 0.9996 - val_loss: 0.0850 - val_acc: 0.9891\n",
      "Epoch 156/200\n",
      "29400/29400 - 1s - loss: 0.0937 - acc: 0.9998 - val_loss: 0.0845 - val_acc: 0.9892\n",
      "Epoch 157/200\n",
      "29400/29400 - 1s - loss: 0.0926 - acc: 0.9998 - val_loss: 0.0814 - val_acc: 0.9902\n",
      "Epoch 158/200\n",
      "29400/29400 - 1s - loss: 0.0896 - acc: 0.9999 - val_loss: 0.0812 - val_acc: 0.9894\n",
      "Epoch 159/200\n",
      "29400/29400 - 1s - loss: 0.0878 - acc: 0.9997 - val_loss: 0.0801 - val_acc: 0.9897\n",
      "Epoch 160/200\n",
      "29400/29400 - 1s - loss: 0.0872 - acc: 0.9998 - val_loss: 0.0770 - val_acc: 0.9898\n",
      "Epoch 161/200\n",
      "29400/29400 - 1s - loss: 0.0857 - acc: 0.9997 - val_loss: 0.0775 - val_acc: 0.9894\n",
      "Epoch 162/200\n",
      "29400/29400 - 1s - loss: 0.0829 - acc: 0.9999 - val_loss: 0.0763 - val_acc: 0.9898\n",
      "Epoch 163/200\n",
      "29400/29400 - 1s - loss: 0.0810 - acc: 0.9998 - val_loss: 0.0750 - val_acc: 0.9895\n",
      "Epoch 164/200\n",
      "29400/29400 - 1s - loss: 0.0800 - acc: 0.9995 - val_loss: 0.0747 - val_acc: 0.9897\n",
      "Epoch 165/200\n",
      "29400/29400 - 1s - loss: 0.0785 - acc: 0.9999 - val_loss: 0.0733 - val_acc: 0.9898\n",
      "Epoch 166/200\n",
      "29400/29400 - 1s - loss: 0.0764 - acc: 0.9999 - val_loss: 0.0731 - val_acc: 0.9899\n",
      "Epoch 167/200\n",
      "29400/29400 - 1s - loss: 0.0761 - acc: 0.9998 - val_loss: 0.0715 - val_acc: 0.9901\n",
      "Epoch 168/200\n",
      "29400/29400 - 1s - loss: 0.0737 - acc: 0.9998 - val_loss: 0.0716 - val_acc: 0.9899\n",
      "Epoch 169/200\n",
      "29400/29400 - 1s - loss: 0.0723 - acc: 0.9998 - val_loss: 0.0717 - val_acc: 0.9894\n",
      "Epoch 170/200\n",
      "29400/29400 - 1s - loss: 0.0707 - acc: 0.9998 - val_loss: 0.0702 - val_acc: 0.9903\n",
      "Epoch 171/200\n",
      "29400/29400 - 1s - loss: 0.0692 - acc: 0.9998 - val_loss: 0.0695 - val_acc: 0.9894\n",
      "Epoch 172/200\n",
      "29400/29400 - 1s - loss: 0.0674 - acc: 0.9999 - val_loss: 0.0699 - val_acc: 0.9897\n",
      "Epoch 173/200\n",
      "29400/29400 - 1s - loss: 0.0671 - acc: 0.9998 - val_loss: 0.0683 - val_acc: 0.9902\n",
      "Epoch 174/200\n",
      "29400/29400 - 1s - loss: 0.0663 - acc: 0.9998 - val_loss: 0.0675 - val_acc: 0.9895\n",
      "Epoch 175/200\n",
      "29400/29400 - 1s - loss: 0.0653 - acc: 0.9997 - val_loss: 0.0664 - val_acc: 0.9896\n",
      "Epoch 176/200\n",
      "29400/29400 - 1s - loss: 0.0636 - acc: 0.9998 - val_loss: 0.0683 - val_acc: 0.9895\n",
      "Epoch 177/200\n",
      "29400/29400 - 1s - loss: 0.0620 - acc: 0.9998 - val_loss: 0.0656 - val_acc: 0.9902\n",
      "Epoch 178/200\n",
      "29400/29400 - 1s - loss: 0.0614 - acc: 0.9998 - val_loss: 0.0645 - val_acc: 0.9899\n",
      "Epoch 179/200\n",
      "29400/29400 - 1s - loss: 0.0589 - acc: 0.9999 - val_loss: 0.0641 - val_acc: 0.9899\n",
      "Epoch 180/200\n",
      "29400/29400 - 1s - loss: 0.0593 - acc: 0.9997 - val_loss: 0.0646 - val_acc: 0.9900\n",
      "Epoch 181/200\n",
      "29400/29400 - 1s - loss: 0.0570 - acc: 0.9997 - val_loss: 0.0640 - val_acc: 0.9898\n",
      "Epoch 182/200\n",
      "29400/29400 - 1s - loss: 0.0566 - acc: 0.9997 - val_loss: 0.0632 - val_acc: 0.9900\n",
      "Epoch 183/200\n",
      "29400/29400 - 1s - loss: 0.0552 - acc: 0.9997 - val_loss: 0.0612 - val_acc: 0.9906\n",
      "Epoch 184/200\n",
      "29400/29400 - 1s - loss: 0.0544 - acc: 0.9999 - val_loss: 0.0618 - val_acc: 0.9903\n",
      "Epoch 185/200\n",
      "29400/29400 - 1s - loss: 0.0535 - acc: 0.9999 - val_loss: 0.0615 - val_acc: 0.9902\n",
      "Epoch 186/200\n",
      "29400/29400 - 1s - loss: 0.0522 - acc: 0.9998 - val_loss: 0.0606 - val_acc: 0.9898\n",
      "Epoch 187/200\n",
      "29400/29400 - 1s - loss: 0.0513 - acc: 0.9997 - val_loss: 0.0630 - val_acc: 0.9890\n",
      "Epoch 188/200\n",
      "29400/29400 - 1s - loss: 0.0501 - acc: 0.9997 - val_loss: 0.0612 - val_acc: 0.9897\n",
      "Epoch 189/200\n",
      "29400/29400 - 1s - loss: 0.0491 - acc: 0.9998 - val_loss: 0.0614 - val_acc: 0.9890\n",
      "Epoch 190/200\n",
      "29400/29400 - 1s - loss: 0.0481 - acc: 0.9999 - val_loss: 0.0601 - val_acc: 0.9898\n",
      "Epoch 191/200\n",
      "29400/29400 - 1s - loss: 0.0479 - acc: 0.9999 - val_loss: 0.0600 - val_acc: 0.9894\n",
      "Epoch 192/200\n",
      "29400/29400 - 1s - loss: 0.0469 - acc: 0.9999 - val_loss: 0.0605 - val_acc: 0.9899\n",
      "Epoch 193/200\n",
      "29400/29400 - 1s - loss: 0.0456 - acc: 0.9999 - val_loss: 0.0599 - val_acc: 0.9900\n",
      "Epoch 194/200\n",
      "29400/29400 - 1s - loss: 0.0453 - acc: 0.9999 - val_loss: 0.0592 - val_acc: 0.9892\n",
      "Epoch 195/200\n",
      "29400/29400 - 1s - loss: 0.0441 - acc: 0.9998 - val_loss: 0.0592 - val_acc: 0.9902\n",
      "Epoch 196/200\n",
      "29400/29400 - 1s - loss: 0.0441 - acc: 0.9998 - val_loss: 0.0586 - val_acc: 0.9902\n",
      "Epoch 197/200\n",
      "29400/29400 - 1s - loss: 0.0435 - acc: 0.9999 - val_loss: 0.0585 - val_acc: 0.9901\n",
      "Epoch 198/200\n",
      "29400/29400 - 1s - loss: 0.0414 - acc: 0.9998 - val_loss: 0.0578 - val_acc: 0.9903\n",
      "Epoch 199/200\n",
      "29400/29400 - 1s - loss: 0.0411 - acc: 0.9999 - val_loss: 0.0562 - val_acc: 0.9904\n",
      "Epoch 200/200\n",
      "29400/29400 - 1s - loss: 0.0404 - acc: 0.9999 - val_loss: 0.0572 - val_acc: 0.9901\n"
     ]
    }
   ],
   "source": [
    "# early_stopping = EarlyStopping(monitor='val_loss', mode='min', patience=50) # 조기종료 콜백함수 정의 - 최적 epoch: 200 \n",
    "history = model.fit(x_train, y_train, epochs=200, batch_size=1024, validation_data=[x_val, y_val], verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1467,
     "status": "ok",
     "timestamp": 1584381372553,
     "user": {
      "displayName": "이재빈",
      "photoUrl": "",
      "userId": "06683534214657838443"
     },
     "user_tz": -540
    },
    "id": "7FioOfvhvyZG",
    "outputId": "2f91f931-ee02-4ffa-ba1f-22278f5a422b"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAacAAAEGCAYAAADBr1rTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nOzdd3zV1fnA8c9zZ272YiaBMMNQkCFo\n1RZHrajF2l9t1eJW3NZK3dZBS7W12mpdxb0qtdpaB3VWtLWCoLJnCCsDErL3Xef3x/cmhpCEC+Tm\nZjzv1+v7urnfdZ9EzJNzvuc8R4wxKKWUUt2JLdoBKKWUUq1pclJKKdXtaHJSSinV7WhyUkop1e1o\nclJKKdXtOKIdwIGy2WzG4/FEOwyllOpR6urqjDGmxzRIelxy8ng81NbWRjsMpZTqUUSkPtoxHIge\nk0WVUkr1HZqclFJKdTuanJRSSnU7Pe6ZU1vq6+vJy8sjEAhEO5QeR0Sw2+14PB4yMzNxOp3RDkkp\npXpHcsrLyyM9PZ1+/fphs2ljMFzGGEpLS6muriYhIYH8/HyGDRsW7bCUUqp3dOsFAgFNTAdBREhL\nS6OhoaH5VSnVN4nIMyJSLCJr2jkuIvKwiOSKyCoRmRzJeHrNb3NNTAdHRPZ6VUr1Wc8Bp3RwfCYw\nKrTNAR6PZDC9olsvHCYYwAR8iN0BYtdfxipswSAEAtbm97f/Wl8PXi8kJYHNBg0N0NhoXW+3WxtY\n5/h831y7vy0YBJfL2hobrfu43dbn1ddbn2PMNxvs/drWvo6OhXM+WN+jzWbF0/S3YeufUyBgXSPy\nzWaztf91fT3U1lrvW953f8Jd+edAVwjqbucfeyycdNKBXRN+LOZTEcnu4JQzgBeMtc7SEhFJFpFB\nxpiiSMTTZ5ITAT82bwBDAGwQdNgQuwux2Q/51nv27OHpp5/m5ptvPuBrv/Od7/D666+Tnp4e1vmF\nhYXYbDYGDhx4wJ/VkwWDUFdn/eIyBvbsgXXroKgIqqq++Z/c54PKSuuXeFMCaHpt2lomBr8fqqut\ne1RX73us6ZerUt3BzTcfUnJyiMjyFu8XGGMWHMD1GcDOFu/zQ/s0OR0KcbgwNnvot04AmzeIkQaC\nThvicAG2g25NlZaW8tRTT7WZnHw+X4cj4D755JOD+syewhgoK4OKCvB4IC7OSjSbN8OmTbBtm3V8\n2zZr8/ms414vlJRYrYKmv6jDIQKJiRATA04n2F1enHYHTofNeu8wOJwBnHYHDod1fOhQFwlJASSx\nAKcTsHvxOytIlaEkONLB7sNhB6fdjsMBlbZt+GyVDHaNxeEw1FECtgDumCAOZ5DK6gDBYBCby0ej\nrZQkZxqDnePZUbeeumAlaTH9iHE5aaCCcn8B6TGDSHGn0WhqcNgFt8OF2+kixuEiKD72eAuoaWjA\n57O+pxhbHI5gPMZRR1Ksh7T4JCp9pRgTJM4VT7wzgXhnAi6Hi+1VW/AZL0MSstlTX0xpQzH+oI+A\n8eO0uxgcn4HdZscbaMQbbKSysZzGQAPDkkeQGpOG2+HGbXezu66IHVXb6BfbD1/Qy+7aXaR7+kPQ\nTnFdMR57HIKNKl8ZiTEJxDhd1PqryE4eQlZSFvW+Bup89VQ3VrO7djcNvkaCxoCBQNDK/sGgweWC\nWI+dgfED8djjqPU2sKNqG/6gn8HxgwmYAA3+BhoDjcQ743HanVQ0VGAw2MWGPfTHZiAYIGiCBE2Q\ngLG+TnAlEOPwsLNqOy67i8EJGdT766lsrKTBV0+KJ5V4V7x1TYvrg7S4V2h/0z3b2pfoTmBg/EAG\nxA3AG/BSVl9G/7j+NAYaKaouIsGdgMPmoMZbQ423BqfdwcD4geyu2c2euj2hf8eh7na+6XYXhJz0\nHGDCwf7v6DfGTD3Yi7tan0lOiFhdenYHOA0mEACf10pSvgaMywZ2NyIH/uxq7ty57Ny5kzFjxjBj\nxgxmzZrFnXfeSVJSElu2bGHbtm1897vfpbCwkMbGRq688krmzp0LQEZGBsuXL6eqqoqZM2cybdo0\nli9fzsCBA3nvvfeIi4vb67Pef/99Hn74YYwxJCcnM2/ePFJTU/H7/Tz44IN89dVXBAIBLrvsMk4+\n+WSWLl3KI488gs/nIy4ujqeffhoRIScnB7v90FqNgYDVcikttVo1W7fCps2GjVsaKNwRQ0G+UFAA\nDY0BcNWCqxpcNeAOvbpqwFmLK6GGtCQ3g8cm4o6pxO8sQ5ylDIkrI8YRQ0JwCA2uAiodG6lgK06J\nIcGVzIDkRJxuH42mhjp/HckxySS44imuLWZXzS521+6moqECh81BSkwK9f56ar21GAxZiVl4A152\n1+4m0Z2IN+Clwb/vgBC72AmYAASwNu83x2xiI2iCYf2sBMGgTTB1aG4+5mYmDDjo5HSoCoCsFu8z\nQ/siotclp2uuqWLVqgP4towABghisP48b92CmjDBzyOPJLZ7iwceeIDTTz+dDRs2ALBo0SLWrl3L\n119/zZgxYwB4+eWX6d+/P7W1tRxxxBHMnj2bAQMG7HWfHTt28PLLL3P00Udz6qmn8sILL3DllVfu\ndc60adN45513GDRoEPfccw+vvvoqf/rTn7jqqqtwOBysXr2alStXkpmZSTAY5K677uLTTz/F7/fj\ndrsZMmQIgUCgwwEkFQ0VbKvYRpI7idXbdvHRio1s227weQVx+Ni4exvFtbuo8Vdi3BUQ02obEUCy\n3bhMIgF7DeynpJcXq1+gZd+AIKR4Uqjz1dHgb8BldzEydSSTUobjC/ioaKggv3EH7oCbOFcc8a44\nSmqL2VqeR/+4/kwYMIEBcQPoH9efen89ZfVlxDpjiXfFYxMbW8q34LQ5yU7OpqS2BJfdRU56Dg6b\nA4fNQaI7ka3lWympKyHOGYeINP+FnJmYSaI7kdXFq4lxxDAgbgBOuxOb2PbanDYnqZ5U8qvyWVO8\nhvH9xzMgbgAldSUEggES3AkMThhMYXUhFQ0VJLgSrJ9HwNu82cRGZmImsc5YAAyGWm8tNd4aPE4P\n9b56KhoqSItNw2lzUu2tprqxmhpvDfX+erKTs3Hb3Wyv3E7/uP4Mih+E0+7EYXPQ4G8gvyofALfd\njdvhJiUmBafdyZayLVQ0VNAYaKTB30C/2H4MSxlGaV0pTruTgfEDKaktIWAC9I/rT52vjqAJkhKT\nQo23Bm/AS7wrnu2V2ymqLiLGEYPH6SHeFc+AuAF4nJ7m/86wd0vBF/Sxq2YX9b56nHbrv5Fd7BTV\nFOGwOfA4PLgdbqobq/EH/STHJGMTGwETIBAMICJ7/Xewh54x13hrqPXWMiRpCN6Al4LqAuKccSTF\nJBHrjGVP3R7qfHXYxW5dZ7PvdY/29rXeX9lQye7a3eyu2Y3L7iLFk0JJbQkOm4PBCYOp89XhD/pJ\ncCcQ74qnwd/ArppdDIgbwID4b34nmFB/ssE0f50Wm9bh/0sR9iZwjYgsBKYDlZF63gS9MDkdMKE5\nQTWlJOsfgnAoYyYmTJjQnJgAfvvb3/L2228DsGvXLtauXbtPcsrIyODoo48GYNKkSWzdunWf+xYV\nFXHllVdSWlpKTU1N82csWbKE+fPnA1Zx3IqKCpYsWcJxxx1HxpAMioqLqKqpYvuu7cTGx2Kz2Zp/\ngRXXFHPWoz9ha9k2/D4HXnt52z8nd+jrgXY8gQGk2VNIdCeRHDOARGcOA1OSyeyXRGpsAuUN5VQ3\nVhPviifeFd/8P2K8K54EVwJxrrjm1zhnHI2BRqoaq0hyJ5EWm9b8Cydoguyp20OaJ625y6a7OGv8\nWdEOIWKOHXJstEOIuCM5MtohdCsi8gowA0gXkXzgLsAJYIx5AlgEnArkAnXARZGMp9clp45aOPvl\n92O8XjAG4zAYhx2bzXVQXX2xsbHNXy9atIjFixezfPlyEhISmDZtWptzilwuV/PXDoejzXN++ctf\ncvnll/PTn/6U559/nhdffBFjDEETxOfyUVBVQNzAOCrqKyjxlVBWX8aq3ausi+OgIdgAVaGbGRv4\nYqlvDLD2s6FQMQOnO8DYfpkMSxpFwFFFVloaJ00cz4TxTtwxQUzQzpAU66/vrmATG/3j+nfJZynV\nlxljztnPcQNc3UXh9L7kdEgcDsRux3i92Px+TDBA0FmP2FyIONodMJGcnNzhMh4VFRUkJSWRkJDA\nihUrWLly5UGF5w/4qayqJH1gOuWN5fzz3X9S663l611fM/GYibzyyisMHjsYAF+Nj6OnH8t9t95H\n5bYggwaMZk9xJbGxaSDgdhriPXE4HTb8DsPvp7yF31/A1VdnEB9/UOEppVSn0ZmrrYkgTZNKgmDz\ngvF7CQYbMO08/B4wYABTp05l1KhRXHHFFfscP/PMM/H7/QwfPpwbb7yRiRMnhhVKgAAVDRXsqtnF\nhj0bWLF7BRfPvZg5c+bw7aO/TUq/FIwx2BpsXHPFNZhaO7NPuJBzZ1zEf94owF47lVtveZarLrqc\nH8z8Njf9/EJcUkFKXDHjc+IYlm0jM9OalzN3LsyaVaWJSSnVLYjpYZM44uLiTOtWyqpVq5gwIQIj\nWAIBjNeLBIMEHWAcIOLGZuv8Bqcxhnp/PTXeGqobq6n2Wg97m3gcntBotASCBHHb3cQ4YgBhzx4o\nKLDm5YA1ZDsxEeLjrSHVbnfHkxnXr1/P2LFjm1+VUr2PiNQZY+L2f2b3oN16HbHbkZgYaOrmM0LQ\n0UiQACKuTqky0ehvZE/dHkrrS/EGrHHKTpuTRHciSe4kYhwxOO1OXPZvnkc1NkJpiTVx1Oez3ick\nQL9+1qsWFldK9XSanPZHxOriEwGfD5sRgk4/RoLYbAc3LyoQtLrr9tTtodpbDUCiO5HBCYNJcCXg\nsu+b+IJBKC+3KiNUW5cQFwexsTBwIKSnc0ijC5VSqjvR5BSOUIISmw0aG7F5haAzSJCGUILa/xDn\nQDBAaX0pNd4aKhsqCZgAbrubwQmDSfNYM/HbUl5uTXRtaLASlNsNGRmQmmp9rZRSvZEmpwPhcIDN\nhjQ0WAMlnBCkocPnUMFgkNL6UgqrC/EFfThtTpI9yaR70ol3xbfZNWiMVUOurAyKi61nSP36Wc+R\nEhO1haSU6v00OR0omw1iYhCvF/EFCBrBOBoJBoOIOPdKNk2VFvxBP3HOOEakjiDe1fFwOK8X8vKg\npsZ6n54OQ4aEX51ZKaV6A01OB8Nms/rUmgZKYCPo8AFBwI2IUFRdREF1AbHOWEakjGi3ldRSZaVV\nny4YhKFDITlZBzcopfomTU4Hq2mgBCB+PzZjI+gMYEwDJfWVFFQXkOpJJTspu806drGxsdTV1TW/\n37UL8vMB6jjssFhiYrro+1BKqW5Ik9OhaDWSr7i+jDJfBfX+RlJikhmWPCys4ebFxVZiSkmByspN\nxMQc0QXBK6VU96XJ6VCJcPXPf06/jHROv/D7xDtiee73z5Ian8zcuTdyyikzqaysxO/3c/fdd3Pu\nuec2X+rzwc6d1sCHpCQYNgxOOOF6qquraWho4LzzzuP73/8+AOvWrePee+/F7/cTFxfHU089RV1d\nHQ899BArV67E5/NxxRVX8N3vfpf09PR9isoqpVRP0uuS0/V/u4QVJas79Z5H9DucP571dJvHjDHM\n+vEsbr3lVmbPmc0Iz2D+9c93effdN3G7hXfeeZvU1DSKioqYPn06Z599dnM3X26utQ7SoEHWZrPB\nXXfdxfHHH09hYSEzZszg0ksvxev1cu211/LJJ5+QlJREWVkZ48aN46abbiItLY0lS5ZQUFBAv379\nSElJwe/3txmrUkr1FL0uOXUlYwx55XmkjUqjvKQcW7WdpRtXkJSYyMis4TSYRn7+8+v5/POl2Gw2\niouLKSgoICsrCxBqa2H4cGvOUpOFCxdy/fXX4/P52LVrF7m5uZSUlDB9+nQGDBiA3W6npKSEwsJC\nPvjgA1599VXcbjeNjY1UV1djs9lITDyEyuxKKdUN9Lrk1F4LJxIqGioobyhncMJgzjj9DF75yysU\nFRXxfz/8IRII8tSTz7FnTykrV35BTEwCmZlDqKuro7AQQEhL2zsxLV68mKVLl/L5559TWlrK2Wef\nvc+yGQkJCeTk5FBZWYnX66WsrIxRo0Yxbtw4qqqqKCkpoby8nOzs7C77OSilVGfT2TMHKWiC5Ffl\n43F4GBQ/iPPOO4/XXnuNt99+m9nnnw8uF5UVFfRL74fL5eLtt9+ksLCQggJHKDlZ85daqqysJDEx\nkdjYWAoLC1m+fDnGGKZMmcLSpUspLi5ubiH169ePE044gQULFuDz+ZrvkZGR0eHyHUop1RNocjoI\ngWCA7RXbaQw0kpmYiYgwZcoUamtrGTBgAEOHDgWHg0suuogVK1cydsxEnn/+JYYNG0lNjZ2MDIAg\n9lZVj0455RQCgQBjx47l3nvvZfLkyWzbto3y8nIefvhhfvKTnzBlyhROP/101q1bx4UXXkhjYyMT\nJ05k3LhxPP/88+Tl5ZGZmRmNH4tSSnUaXTLjAAWCATbs2UC9v55B8YMYnDC4/eHixlglwwMBfDYn\nazY4iYkJkpMjbc59ihZdMkOp3q+nLZkRsd+QIpIlIh+LyDoRWSsiP2vjHBGRh0UkV0RWicjkSMXT\nWXZW7aTeX8+o1FFkJGZ0PI9JxKokYbezexcEAjBkiBdjGulpfxQopVRXiuSf735grjFmHHAUcLWI\njGt1zkxgVGibAzwewXgOWdMyFwPjB5IUkxTeRSL47W6Ky52kJgaIjXEAwdDKupqglFKqLRFLTsaY\nImPMV6Gvq4H1QEar084AXjCWJUCyiAw6mM8LBtteQr2zGGMoqCogxhHD4ITBB3Tt7mIhGBQG9vMj\njT4EF1aCin4Lqunzox2HUkq11CUPPkQkG5gELG11KAPY2eJ9PvsmMERkjogsF5HlbU0wbZr7E8kE\nVdlQ2fycyXYACwzW11t181JSIDbJqsVn8/oRcQEBjPFGLTEYYygtLSUmJqb5VSmluoOIz3MSkXjg\ndeB6Y0zVwdzDGLMAWADWgIjWx4cPH05eXh67d+8+pFg7UlJfQpAgzj1OCigI6xpjoLTUjs8n2Gx+\nVq0J7QwEQARjE6xK5raDWlG3M4gI9tCwQR3lp5TqLiKanETEiZWYXjbG/L2NUwqArBbvM0P7DojH\n42H8+PEHF2QY3s19l5n/mMlT33+K7074btjXPfkkzJkDL78M3/teiwN/+xv8+Mdw1llsmZ/NzoL7\nGTZsPkOH3tb5wSulVA8UsaHkYg1jex4oM8Zc3845pwHXAKcC04GHjTHTOrpvW0PJI8kYw7HPHkt+\nVT6br92My+4K67qGBhg50ppo+9lnbaxe+8AD8ItfYObOZf3FuygufpnDDnuD9PQzOv+bUEr1eT1t\nKHkkW07HAOcBq0VkRWjfbcAQAGPME8AirMSUC9QBF0UwnoOyeNti/rfzfzx66qNhJyaAxx+HggJ4\n6aV2llW/4QbYtg154AHGDHmA+mM2sX79bCZN+h/x8Yd33jeglFI9UK+YhBtJZ792Nh9t/YidP99J\njCO8AQPl5VaracoUeP/9Dk4MBOCHP4S338b31ydZNvgObLYYJk/+ApcrvXO+AaWUoue1nLpPmYJu\nyBfw8W7uu8waPSvsxAQwbx5UVMDvf7+fE+12eOUVmDoV5/nXMKFxPo2NhaxbdxbBoG8/FyulVO+l\nyakD/93xXyobK/l+zvfDvmbzZnjkEbjkEgirolJsLLz1FgwcSPzZtzA28XdUVCwmN3efghpKKdVn\naHLqwFub3sJld3HS8JPCvub3v7caRPPmHcAH9e8P77wDdXX0v3ohWQPmUlj4OAUF3bpghlJKRYwm\np3YYY3hr01ucMOwE4l3xYV2zZw+88AKcdx4MHHiAHzh2LDzzDHz+OcOfDJCaehq5uddRXv7xgQev\nlFI9nCandmwp30JuWS6njzo97GueeMIaQn59mwPnw3DWWXDVVcgf/sj4osvweEaxdu2PqK/PO8gb\nKqVUz6TJqR2Lty0G4MThJ4Z1fiBgJaeTT4ZDmg98//0wZgz2i67ksH7PAIbVq2fh91cfwk2VUqpn\n0eTUjsXbFjMgbgA5aTnhnb/Ymtd06aWH+MGxsbBwIZSXE3vxrYzPWUhd3QbWr5+NMZEtbquUUt2F\nJqc2GGNYvG0xM7JndLxeUwsvvQSJiXB6+L2A7Zs4Ef78Z1i8mJT7P2TkyD9QWvom27bd1Qk3V0qp\n7k+TUxu2lG+hoLqAGdkzwjq/rg5efx1+9CPweDopiPPPhyuvhPvvJ2PJIAYOvJjt23/Nnj1vddIH\nKKXU3kTkFBHZGFoA9pY2jg8JLSL7dWiB2FMjFYsmpzY0PW8KNzn9859QXQ2zZ3dyIH/4A0ybhlx0\nEaPMz4iPn8z69edRX7+lkz9IKdXXiYgdeBRrEdhxwDltLBB7B/CqMWYScDbwWKTi0eTUhs92fkb/\nuP5hP2/605+sckXf+U4nB+J2w2uvgduN/ezzGD/8JURsrFnzfwQCdZ38YUqpPm4akGuMyTPGeIGF\nWAvCtmSAxNDXSUBhpILR5NSGzaWbGZs+NqznTcuWweefw7XXgi0SP82sLHjxRVi1Cs8tf2Ds2Jep\nrV3F5s3XRODDlFK9mKNp0dbQNqfV8XAWf70bmC0i+ViFu6+NVLCanNqQV57H8JThYZ370EOQkAAX\nXhjBgGbOhFtvhSefJO1fpQwZchu7dj3L7t0LI/ihSqlexm+MmdpiW3AQ9zgHeM4Yk4m1osSLEqGV\nUjU5tVLnq6OopogRKSP2e25VlbVu4AUXWCP1ImrePPj2t+Hyy8luPIfExKPZtOly6uu3RviDlVJ9\nRDiLv14CvApgjPkciAEisoSCJqdWtpZbv+zDaTm9/TZ4vXDOOZGOCnA4rArmHg+22eczdsRzAKxf\nf65WMFdKdYZlwCgRGSYiLqwBD2+2OmcHcCKAiIzFSk4lkQhGk1MrW8qtkXAjUvffcvrb3yAjA446\nKtJRhQweDE8/DV99hWf+U+TkLKCqagnbtt3dRQEopXorY4wfa2Xy94D1WKPy1orIPBGZFTptLnCZ\niKwEXgEuNBFaFDCSK+H2SHnlVh27/bWcqqvhX/+Cyy+P0ECI9pxxBlxxBdx/P/1P/oCyzIvZseNe\nUlJOIiXl+C4MRCnV2xhjFmENdGi5784WX6/DWuU84rTl1MqWsi0kuhNJ86R1eN6iRdDYaE287XIP\nPGBVMT//fEYl3YHHM5r162fj85VGIRillOp8mpxayauwRurtbxj5u+9Caip861tdFFhLsbHW86fy\ncuw/vYRxo1/E5yvW4eVKqV5Dk1MrW8q27HeknjHw4Ydw4onWwoJRMXGiVQb9449JeOCfDB16J8XF\nCykufi1KASmlVOfR5NRC0ATZWrF1v8+bNm2C/Hw4KfwFciPjggvgoovgvvsYUvo9EhKmsmnTZVre\nSCnV42lyaqGwuhBvwLvf5PTRR9Zr1JMTWM+f0tOxXX4V43JeAWysWXMmgUBttCNTSqmDpsmphe0V\n2wHITs7u8LwPP4Rhw2B4eEUkIislBR5+GL78Es+TbzFu3CvU1q4mL+/2aEemlFIHTZNTC/lV+QBk\nJWa1e04wCB9/bD1v6jbOOgtOOw3uuIPUqtFkZFxDQcHDVFb+L9qRKaXUQdHk1MLOKqvmYWZiZrvn\nbNgAFRVw7LFdFVUYROCxx6zXq69mWPZvcLuHsGHDhfj9NdGOTimlDpgmpxbyq/KJd8WT6G6/UN4X\nX1iv06d3UVDhGjIEfvUrWLQIx5vvM3bs89TX55Kbe120I1NKqQOmyamF/Kp8shKzOpzjtHQpJCXB\n6NFdGFi4rr3WGmJ+3XUk2yY1Vy8vLv5btCNTSqkDosmphZ1VOzvs0gMrOR15ZBeXLAqXwwF//jPs\n2gVXXUX20DtJSJjGpk1X0NhYFO3olFIqbN3xV2zUNLWc2lNfD6tWdcMuvZamT4e774aXX8b23IuM\nHfsCwWA9GzdeQoTqMyqlVKfT5BTiC/goqi7qsOX01VcQCMC0aV0Y2MG47TZrOOG11xKb52P48N9R\nVvYviooOZm0xpZTqepqcQopqijAYspLabzk1DYbo9snJboeXX7ZWQDzrLDKSLyAl5SRyc2+gri43\n2tEppdR+aXIK2Vm5/2HkX34JmZkwcGBXRXUIBgywEtSGDci995GT8ywizlD3XjDa0SmlVIc0OYU0\nTcDdX7fepEldFVEnOPFEOPdcePBBYvbAyJF/oLLyUwoKHot2ZEop1SFNTiH7qw5RWwsbN8LkyV0Z\nVSeYP98qa3HbbQwceCGpqaeQl3cz9fV50Y5MKaXaFbHkJCLPiEixiKxp5/gMEakUkRWh7c62zusq\nO6t2djgBd9Uq63d8j2o5AWRnw9y58OKLyOuvM3r0AkTs2r2nlOrWItlyeg44ZT/n/McYc0RomxfB\nWPYrvyqfzMTMdifgfvWV9drjWk5gDS2fPh0uuYSYAi8jRjxIRcViCgv/HO3IlFKqTRFLTsaYT4Gy\nSN2/sxXXFjMgbkC7x7/+GtLSrAERPY7LBX/9qzVz+Mc/ZlDqbFJSvkte3k3U12+LdnRKKbWPaD9z\nOlpEVorIv0RkfHsnicgcEVkuIsv9fn9EAimpK6FfXL92jzcNhtjP6u3d19Ch8Nxz8NVXyI03kpPz\nJACbNl2mk3OVUt1ONJPTV8BQY8xE4E/AG+2daIxZYIyZaoyZ6nA4IhJMSW0J/WLbTk5eL6xZ0wOf\nN7V2xhlW/b1HHiFmfRnDh99PefmHFBU9Fe3IlFJqL1FLTsaYKmNMTejrRYBTRNKjEUsgGKCsvqzd\n5LR5M/h8MGFCFwcWCfPmQWoq3HQTgwfPITn5BLZsmUtDw45oR6aUUs2ilpxEZKCERh+IyLRQLKXR\niKW0vhSDabdbb90663XcuC4MKlKSk+GOO+DDD5H33icn5ymMCbJxo3bvKaW6j0gOJX8F+BzIEZF8\nEblERK4QkStCp/wIWCMiK4GHgbNNlH47FtcWA7Tbclq3znrWNGZMV0YVQVddZa35cfnleLypjBjx\nW8rL32fXrmejHZlSSgEQmQc4gDHmnP0cfwR4JFKffyBKaksA6B/Xv83j69bBsGEQG9uVUUWQ2w3P\nPw/HHAM33MDgp56kuPhv5O6oh08AACAASURBVOb+nJSUk4mJ6YlDEpVSvUm0R+t1CyV1VnLqqFuv\nV3TptXTUUXDzzfDMM8jb7zBmzNMY42fTpsu1e08pFXWanPim5dRWt57fb5Ut6nXJCeCuu6xRHpdd\nhqcumeHD76WsbBG7d78Q7ciUUn2cJie+aTmlxabtc2zLFmukXq9MTm43vPAClJXBLbeQkXENSUnH\nkpt7PY2NhdGOTinVh2lywmo5pXpScdj2fQTXq0bqtWXiRGuAxDPPIBs3kZPzDMFgA5s2XaHde0qp\ngyYifxeR00TkoPKMJidC1SE6GKkHMHZsFwbU1W67zRrt8ctfEhs7imHD5lNa+hbFxa9EOzKlVM/1\nGHAusFlE7hORnAO5WJMTHZcuWr8esrIgPr6Lg+pK/fvDjTfCa6/BW2+RmfkzEhOPYvPm6/B6i6Md\nnVKqBzLGfGiM+SkwGdgGfCgi/xORi0TEub/rNTnRcemiTZsg54DyfQ91881wxBFw8cXIrmJycp4m\nEKhm8+Zrox2ZUqqHEpE04ELgUuBr4CGsZPXB/q7V5ET73XrGWMlp9OgoBNXV3G74y1+sVRUvu4y4\n2LFkZ99JScmrlJT8I9rRKaV6GBH5B/AfIBb4vjFmljHmr8aYa4H99kX1+eQUNEFK60rb7NYrKYHK\nyj6SnMB6sDZ/PrzzDixcSFbWTcTHH8HmzVfh85VHOzqlVM/ysDFmnDHmXmNMUcsDxpip+7u4zyen\n8vpyAibQZstp40brtU906zW57jqYNg2uuw5bWSU5Oc/g9ZawZcsN0Y5MKRVhInKKiGwUkVwRuaWd\nc34sIutEZK2I/KWD240TkeQW16WIyFXhxtLnk1NH1SE2bbJe+0zLCcBuh6eegooK+PnPSUiYxJAh\nN7Nr13OUlr4b7eiUUhEiInbgUWAmMA44R0TGtTpnFHArcIwxZjxwfQe3vMwYU9H0xhhTDlwWbjx9\nPjmV1lmF0NNj912tY9MmaxHZoUO7OqooO/xwuPVWeOklePddhg79JbGxY9m0aQ5+f2W0o1NKRcY0\nINcYk2eM8QILgTNanXMZ8Ggo0WCM6Wg4r71p5QloTn6ucIPp88mposFK7CkxKfsc27gRRo60GhN9\nzu23W8+gLr8ce52PnJxnaGwsYMuWG6MdmVIqMjKAnS3e54f2tTQaGC0in4nIEhE5pYP7vQv8VURO\nFJETgVdC+8KiySmUnJJikvY51mdG6rXF7ba693buhNtvJynpKLKy5lJU9CRlZe9HOzql1IFziMjy\nFtucg7kHMAqYAZwDPNnyuVIrNwMfA1eGto+Amw7kg/q0puSUHLP3zzcQgNxcmDUrGlF1E9/6Flx9\nNTzyCPzoR2QfM4/S0rfYuPFSjjxyDQ5HYrQjVEqFz7+fUXIFQFaL95mhfS3lA0uNMT5gq4hswkpW\ny1rfzBgTBB4PbQdMW05NLSf33i2n/Hyr4OuIEdGIqhu5917rhzB7NvbqBnJyntXuPaV6p2XAKBEZ\nJiIu4GzgzVbnvIHVakJE0rG6+fLaupmIjBKR10Ij+/KatnCD0eTUUIHH4cHtcO+1vyD090JmX193\nLz7empxbVATXXUdS0lFkZv6coqIFVFR8Eu3olFKdxBjjB64B3gPWA68aY9aKyDwRaepDeg8oFZF1\nWF12NxpjStu55bNYrSY/cDzwAvBSuPGElZxE5GcikiiWp0XkKxE5OdwP6c4qGir26dKDb5JTRuvH\ngX3RkUfCLbfAiy/CJ58wbNg9xMRks3HjHAKBhmhHp5TqJMaYRcaY0caYEcaY+aF9dxpj3gx9bYwx\nN4Qm1x5ujFnYwe08xpiPADHGbDfG3A2cFm4s4bacLjbGVAEnAynAecB94X5Id1bRqMkpLLfeCtnZ\ncPXV2IMuRo/+M/X1m9ixY360I1NKdU+NoeUyNovINSJyJmGULWoSbnJqGqt+KvCiMWZti309Wkct\nJ7cbUlOjEFR3FBsLf/gDrF0LzzxDaurJDBgwmx077qOmZk20o1NKdT8/w6qrdx0wBZgNXBDuxeEm\npy9F5H2s5PSeiCQAwQMMtFvqKDllZID0ihTcSc44A44+Gn71K2hoYMSIB7Hbk9i48VKCQX+0o1NK\ndROhCbc/McbUGGPyjTEXGWP+zxizJNx7hJucLgFuAY40xtQBTuCiAw+5+6lsqOwwOakWRKzCsAUF\n8PjjuFz9GDXqT1RXL2XnzvujHZ1SqpswxgSAYw/lHuEmp6OBjcaYChGZDdwB9Io6Nu21nAoLNTm1\n6fjj4aSTrCHmNTX07382/fqdxbZtd1FTszLa0Smluo+vReRNETlPRH7YtIV7cbjJ6XGgTkQmAnOB\nLVjDAns0Y0ybyckYq3EweHCUAuvu5s+31hN56CFEhFGjHsPhSGX9+vMJBhujHZ1SqnuIAUqBE4Dv\nh7bTw7043OTkN8YYrCKAjxhjHgUSDjDQbqfeX48v6NsnOVVUQH29tpzaNW2aVTrj/vuhrAyXK52c\nnKeorV3Ftm13Rzs6pVQ3EHrO1Hq7ONzrwy1fVC0it2INIT8uNDxwv2vAd3ftVYfQYeRh+PWvYfJk\nuOwyeO010tNPZ+DAS9ix43ekpX2fpKRvRTtCpVQUicizgGm9P9wEFW7L6SdAI9Z8p11YNZd6/BPw\n9urqaXIKw+GHW8+d/v53a4g5MHLkg7jdWWzYcAGBQG2UA1RKRdnbwDuh7SMgEagJ9+KwklMoIb0M\nJInI6UCDMabHP3PS5HSI5s6FH/zAen3gARyORMaMeY76+ly2bLk52tEppaLIGPN6i+1l4MfAfpdn\nbxJu+aIfA18AZ4U+YKmI/OhgAu5O9pecdEDEfojAwoVw1lnwi1/AwoWkpMwgM/N6Cgsfpazsw2hH\nqJTqPkYB/cM9Odxuvdux5jhdYIw5H2vFxF8eRHDdSnvJqbAQ0tOtChFqP9xueOUVmDgR7rwT/H6G\nDfsNsbFj2LjxIny+iv3fQynV64hItYhUNW3AW1hrPIUl3ORka7Ucb+kBXNttVTZYU7Xaajlpq+kA\n2O1wzz2weTO8/DJ2u4cxY16ksbGI3Nzroh2dUioKjDEJxpjEFttoY8zr4V4fboJ5V0TeE5ELReRC\nrAdciw4m4O6kvVVwtTrEQZg1yxq9d+edUFlJYuJUhg69nd27X6Sk5B/Rjk4p1cVE5EwRSWrxPllE\nfhDu9eEOiLgRWABMCG0LjDE9/ol3RUMFMY4YYhwxe+3X5HQQRODRR60f3nVWa2no0DuIj5/Mpk2X\n4/UW7+cGSqle5i5jTHMlIWNMBXBXuBeH3TUXGnFxQ2jrFX8Kt1UdwueD4mJNTgflqKPgjjvghRfg\njTew2ZyMHfsCfn8VmzZdjjWPWynVR7SVX8KdW9txcmr9QKvFVh16wNWjtbWWU1GRVb5Ik9NBuuMO\nGD8ebroJfD7i4sYzfPh89ux5g927X4x2dEqprrNcRB4UkRGh7UHgy3Av7jA5tfFAq2lLMMYkdnSt\niDwjIsUi0uZiP6FVdR8WkVwRWSUik8MNurNUNFTsUx2isNB61eR0kBwOuO8+a3DEk08CkJl5PUlJ\nx7F587U0NOyMcoBKqS5yLeAF/gosBBqAq8O9OJIj7p4DTung+Eysce+jgDlYxWW7VHVjNYnuvXOs\nTsDtBKedBt/+tjU4YscOROyMGfMcxgTYsOEijOkVS4EppTpgjKk1xtxijJlqjDnSGHObMSbs0jER\nS07GmE+Bsg5OOQN4IbQm/RIgWUQGRSqettR4a4h37b1qsE7A7QQiVqvJ57MqSNTV4fEMZ+TIB6mo\n+IiCgseiHaFSKsJE5AMRSW7xPkVE3gv3+mjOVcoAWvbx5If27UNE5ojIchFZ7vd33oqr7SUnl8ua\nhKsOwejR1uTcFSvg9tsBGDToMlJTZ5KXdxO1tRuiHKBSKsLSQyP0ADDGlBOBChFRZYxZEGoaTnU4\nwh7ssV813hrinHF77WuagKvLs3eCU0+FSy6xhpjn5iIi5OQ8jd0ex/r15+jaT0r1bkERGdL0RkSy\naaNKeXuimZwKgKwW7zND+7pMey0nfd7UiX71K6speuONYAxu9yBycp6lpmYFeXm3RTs6pVTk3A78\nV0ReFJGXgE+AW8O9OJrJ6U3g/NCovaOASmNMUVd9eCAYoN5fr8kp0gYOtIaXv/GGNYoPSE8/nYyM\na8jPf5DS0nejHKBSKhKMMe9iVSHfCLyCtYp6fbjXd14fWSsi8gowA0gXkXysmcFOAGPME1jlj04F\ncoE64KJIxdKWOl8dwF7JyRhrKPnpYS8krMJy002wejXcdhsMHQrnnsvw4b+jomIxGzZcwJFHrsHl\n6hftKJVSnUhELgV+htUrtgI4Cvgca9n2/YpYcjLGnLOf44YDGPPe2Wq81ppXLZNTVRXU1mrLqdPZ\nbPDss7B9O1x9NcyYgX3wYMaO/QtffjmVTZsuZ/z41xF90KdUb/Iz4EhgiTHmeBEZA/wm3It7xICI\nSGhKTnGubwZE6DDyCHK5rATV0ABXXgnGEB9/OMOG/Zo9e/7B7t0vRTtCpVTnajDGNACIiNsYswHI\nCffiPp+cWracdAJuhI0aBb/+Nbz5Jvz1rwBkZd1AUtKxWj1Cqd4nPzTP6Q3gAxH5J7A93Iv7bHKq\n9VkTlTU5dbHrr4dp0+Daa6GkpEX1CL9Wj1CqFzHGnGmMqTDG3I21OO3TQOcumdEbddRy0m69CLLb\n4ZlnrAd8oe49j2cEI0c+QEXFR+zYcV+0I1RKdTJjzCfGmDeNMd5wr9Hk1Co5paaCxxOtqPqI8eOt\n+U+vvw7PPQfAoEFz6N//XLZuvYOysrArnCileqk+n5xaVogoLNQuvS4zdy7MmGF17zVXj1hAXNxh\nrFt3DvX1W6MdoVIqivp8cmrdctLk1EXsdmtRQqcTZs8Gnw+7PY7DDvsHYFi79ocEAmHP11NK9TKa\nnFolJ33e1IWysuCJJ2DpUpg/HwCPZwRjx75ETc0KcnOvi3KASqlo6bPJqdZbi01sxDhiAPD7Yfdu\nbTl1uZ/8BM4910pOq1cDkJZ2GkOG3EpR0VPs2qWr5yrVF/XZ5NRU9LWpKsGuXRAManKKioceguRk\nq4J5aEmU7Ox5JCV9h40bL6Oi4r9RDlAp1dX6dHJqORhC5zhFUXo6PPIILFvWvPaTzebgsMNeJyZm\nKGvWnEFd3eYoB6lU7ycip4jIRhHJFZFbOjjv/0TEiMjUSMXSd5OTb+/lMgoLrVdNTlHyk59Y855+\n97vm6hFOZxoTJvwLENas+QF+f3V0Y1SqFxMRO/AoMBMYB5wjIuPaOC8Bq27e0kjG03eTU6u1nLTl\n1A388Y9wzDFwwQXwyScAeDzDGT/+VerqNrJhw4VY9YKVUhEwDcg1xuSFJssuBM5o47xfAb8FGiIZ\nTJ9NTrXe2n2Sk9Opy7NHlcsF//wnDB8Os2bB+vUApKScwIgR97Nnz9/ZsSPsosZKqb05RGR5i21O\nq+MZQMsCl/mhfc1EZDKQZYx5J8KxRm7JjO6uxltDWmxa8/uCAhg0yFrdQUVRWhq89x5MmQJnnQVf\nfAGxsWRmXk919Zds3fpL4uMnkZZ2arQjVaqn8RtjDvoZkYjYgAeBCzstog702V/Frbv1du2ykpPq\nBrKy4KWXYN06uM6a69RUQSI+fiLr1p2rAySU6nwFQFaL95mhfU0SgMOAxSKyDWvxwDcjNShCk1NI\ncTEMGBDFgNTeTj4Zbr4Znn4a3n4bALs9lvHj/4GIgzVrzsDnK49ykEr1KsuAUSIyTERcwNnAm00H\njTGVxph0Y0y2MSYbWALMMsYsj0QwfTs5OfdOTv37RzEgta+774bDD4fLLoPSUgA8nmzGj3+N+vot\nrFnzA4LBxujGqFQvYYzxA9cA7wHrgVeNMWtFZJ6IzOrqePp2cgq1nIJBTU7dkttt1d8rK7Pq7wUC\nAKSkzGDMmOeorPyU9esv0DWglOokxphFxpjRxpgRxpj5oX13GmPebOPcGZFqNUEfTU7egBdf0Ne8\nRHt5ufV7T7v1uqEjjrAqSLz7Lsyb17x7wIBzGD78d5SU/JUtW26KYoBKqUjok6P1ar17r4JbXGzt\n15ZTN3X55VZx2HnzYORIOO88ALKyfkFj407y8x/A5erHkCE3RzlQpVRn6ZPJqXVFck1O3ZwI/PnP\nsH07XHwxpKTA6acjIowc+Ud8vj3k5d2C09mPQYMujna0SqlO0Ce79TQ59UAuF/z97zBxIpx5Jrz6\nKgAiNsaMeZ6UlO+yadPllJcvjm6cSqlOockJa6kM0OTU7SUnw0cfwfTpVomjrdZquTabk3HjXsXj\nGcXatWdSXf11lANVSh2qPpmcan3WM6emquTFxVZliLS0jq5S3UJSEixcaK2ke903ixE6nckcfvgi\n7PZEVq48iZqalVEMUil1qPpkcqputKpbt+zWS0+3ft+pHiAz05oD9fbb8NRTzbs9nmyOOOLf2O2x\noQS1JnoxKqUOSd9MTl4rOSW4EwCd49Qj/exncNJJ1gTdP/yhebfHM4KJEz9GxMXKlSdoC0qpHqpP\nJqemZ04JLk1OPZbTabWcfvhDuOEGuOMOCC2nERs7kiOO+Bibzc2KFTOoqvoiysEqpQ5Un0xObXXr\naXLqgdxua9TepZfC/Plwzz3Nh2JjR3PEEf/B4Uhl1aqZ1NZuiGKgSqkD1TeTk3fv5LR7tyanHstu\nhwULrNF799zTXCQWrGdQEye+j4iDVatOob4+L4qBKqUORJ9MTjXeGmKdsdhtdhoaoKpKk1OPJgKP\nPw6TJlk1+FZ+85zJ4xnBhAmLCASq+PrrY6ipWRXFQJVS4eqTyam6sbr5eVNJibVP6+r1cB4PvPEG\nJCTA974Hm79Z7ykhYQqTJv0HsPP119+mouI/0YtTKRWWvpmcvNVaHaI3GjIE3n/fquL7ne/A2rXN\nh+LixjN58me4XANYtepkSkr+EcVAlVL70yeTU423Zq9h5KDJqdcYOxYWL7a+/va34dNPmw/FxAxl\n0qT/Ehc3kbVr/4/8/IeiE6NSar/6ZHKq9n7Traeli3qh8ePhP/+Bfv2suVChOnwALlc/jjji36Sn\n/4Dc3OvZvPl6jAlEMVilVFsimpxE5BQR2SgiuSJySxvHLxSREhFZEdoujWQ8TaobtVuv1xsxApYs\ngaOOspbY+M83z5ms5d7/RkbGzygoeIjVq7+Pz1cRxWCVUq1FLDmJiB14FJgJjAPOEZFxbZz6V2PM\nEaHtqTaOd7rW3XoeD8TFdcUnqy6VnAz//CcMGwY/+AF8+WXzIRE7o0b9kVGjHqe8/AO++mq6zoVS\nqhuJZMtpGpBrjMkzxniBhcAZEfy8sLXs1isutkbqiUQ5KBUZKSmwaJE1iu/44+Hjj/c6nJFxBRMn\n/hu/v5yvvppOWdn7UQpUKdVSJJNTBrCzxfv80L7W/k9EVonIayKS1daNRGSOiCwXkeV+v/+QA2s5\nlFyrQ/QBw4fDZ59Zo/lOOcVaF6qF5OTjmDJlOTEx2axadSoFBY9hQqWQlFLREe0BEW8B2caYCcAH\nwPNtnWSMWWCMmWqMmepwHNrivcYYarw1Wrqor8nIsEbuTZ4MP/oR/OIXUF/ffDgmZgiTJv2H1NTv\nsnnz1axceRKNjYVRDFipvi2SyakAaNkSygzta2aMKTXGNIbePgVMiWA8ANT56jCY5mdOWrqoD0lN\nhQ8/hDlz4IEHrLlQ1dXNhx2ORA4//B1Gj36C6uov+Prr46iv3xa9eJXqwyKZnJYBo0RkmIi4gLOB\nN1ueICKDWrydBayPYDxAi+UyXAkYoy2nPicuDp54wura++ormDVrrwQlYmPw4MuZOPGj0HOooygr\n+yCKASvVN0UsORlj/MA1wHtYSedVY8xaEZknIrNCp10nImtFZCVwHXBhpOJp0rIieUUF+P2anPqk\nM8+E55+3uvomTYLly/c6nJg4jUmT/ovTmcaqVSezadPV+P2VUQpWqb4nos+cjDGLjDGjjTEjjDHz\nQ/vuNMa8Gfr6VmPMeGPMRGPM8caYiI/lbV7LyZ3QPMdJ6+r1UT/9qVVNwueDY4+Fl17a63Bc3Dim\nTFlGRsZ1FBY+wRdfjNPRfEp1kWgPiOhyLbv1dAKu4rjjrO69o4+2JuuecQZs+OZvJLs9llGjHmLy\n5KU4HMmsWvU9Nm++lkCgLopBK9X79b3k1KJbT5OTAiAtzSoYO3++1ZKaOtUaONFCYuJUpkxZTmbm\n9RQUPMKXX06huvrLtu+nlDpkfS45tezW07p6qpnTCbfdBuvXW6WPTj0Vfvc78HqbT7HbPYwc+Qcm\nTPgAv7+ar746iry82/H7a6IYuFK9U59LTq279UQgPT3KQanuY/Bg+OQTOO00uPlmqzZfUdFep6Sm\nnsSRR66mf/9z2bHjN3zxxWjy8x8iEKhv56ZKqQPV95JTqFuvaUBEWhoc4rxe1dskJ8M//mFtmzZZ\ngyU++2yvU5zOFMaOfZ5Jkz7D4xlNbu71LFt2OOXl/45S0Er1Ln0uOTV16zU9c9IuPdWuH/wAPvoI\namqsBHX88bB9+16nJCV9i0mTFjNhgjUXauXKE1m9epYuB6/UIepzyanaW02MIwaHzcGuXZqc1H5M\nnw55efDww1ZV80mT4MknreHnLTR19Q0b9hsqK//D8uVHsG7dT6mry41S4Er1bH0vObUo+pqfD1lt\nlppVqoW4OLj2WmvI+ZgxVvmjMWOsSbwtChHb7R6GDr2V6dPzGDLkFvbseYNly8ayceMVNDYWdPAB\nSqnW+lxyqvFZRV8DASgogMzMaEekeoyRI61nT2+/bT2XuvBCOPHEb5ZTDnE6Uxg+/DdMn76FwYOv\nYNeuZ1i6dCS5ub/A690TndiV6mH6XHKqbqxuHgzh92vLSR0gEWsk3/Ll8NxzsGwZTJwI994LFXuv\nput2D2TUqD8xbdpG+vX7Mfn5D7J06XC2bZuH31/d9v2VUkBfTE6hhQZ3hlaa0paTOigicMEF8Pnn\ncNhh1hypiROtllWrtaA8nmGMHfs8Rx65mpSUk9i27S6WLh3O9u336rIcqlsRkVNEZKOI5IrILW0c\nv0FE1oXW4PtIRIZGKpa+l5waq4l3xZOfb73XlpM6JBMnWtUkPv8c7HZrVN/gwdYcqYaGvU6NixvP\nYYf9ncmTvyA+fhJbt97G558PYfPma7WorIo6EbEDjwIzgXHAOSIyrtVpXwNTQ2vwvQb8LlLx9Lnk\nVFZfRlpsmracVOc66ij4+mv405/gmGOs6hKTJsFvf7vP8PPExCOZOPF9pk3byODBcygoeJQlS7LZ\nvPln1Naui9I3oBTTgFxjTJ4xxgssBM5oeYIx5mNjTFNhySVY6/RFRJ9LTsW1xfSP7U9+PsTEWJNw\nleoUSUlwzTXw2muwaBF4PHDLLZCTA3ffvU9LKjZ2NKNHP8aUKctITZ1JYeETLFs2nq+/Po5du17U\nihOqszlEZHmLbU6r4xnAzhbv80P72nMJ8K/ODrJJn0pO9b56qr3V9I/rz86dVqtJJNpRqV5p5kxr\n6PnWrdbaUffcYxWU/d//9jk1IWEK48b9haOPzmf48PvxenezYcP5fP55Bps3X6+tKdVZ/MaYqS22\nBQd7IxGZDUwF7u+88PbWp5JTca1Vhrx/XH+d46S6RnY2vPKK1ZIqK7O6/KZPh/vvh40b9zrV5erH\nkCG/YNq0jUyc+G9SUk6msPAxli0bz9KlY9i48QoqKj7BmGB0vhfV2xUALX8rZob27UVETgJuB2YZ\nYxojFUyfTU5NLSelusTMmdY6UQ8/bHXv3XSTNZH3uOPghReg/psuPBEhJeV4xo9fyNFHFzBixIPE\nxo6iuPhlVqyYwZIlw8nLu53a2oivzan6lmXAKBEZJiIu4GzgzZYniMgk4M9Yiak4ksH0yeSU5ulP\nYaG2nFQXS0y0Kk2sXAk7d1qDJXbtsoakDxpkPa/68EOo+2YhQ5erH1lZP+fww9/iW9/azdixfyEu\nbiw7dtzHsmVj+fLLaeTn/wmvtySK35jqDYwxfuAa4D1gPfCqMWatiMwTkVmh0+4H4oG/icgKEXmz\nndsdMjGt5mR0d3Fxcaa2tvagrn3262e5+M2LWXL2Vo4ak81jj8GVV3ZygEodCGOsJToWLIDXX7fW\nj/J4rPWkfvxja8JvXNw+lzU2FlFc/Aq7d79ITc0KRBwkJEwjPn4i/fufS1LSMYg+UFUtiEidMWbf\nf0zdVJ9aLKKp5dRQ2g/QlpPqBkRgxgxrq66G//4X3nnHSlSvv24lqtNOswZVfO97zcNL3e5BZGXd\nQFbWDdTUrGb37peoqvqc3btfpLDwcWJiRpCaegqpqd8jOfl4HI74qH6bSh2oPtVyuuG9G1jw5QIW\nZNfw05/C6tXW5H6lup1AwEpUr75qJamm+n0JCTBrljX6b8SINi6rpbj4r+zZ8w/Ky/9NMFgXalVN\nJyXlRFJSTiQx8ShsNlcXf0Mq2npay6lPJafZf5/N/3b+j3NL8rjvPqtr36X/j6ruLhiEL76wktXG\njfDyy9YAiv79YcoUq9X1ne9Yk35b/IMOBhuprPwvZWUfUFHxb6qrvwSC2GyxJCQcSWLiNBISppGY\nOA23O0u7AXs5TU4RdijJ6eQXT6aqsYrBi5awfj2sX9/JwSnVFQoL4S9/sf4Bf/75N/+QbTYYNgzO\nP9+qmD5kyF6X+XzlVFR8QkXFx1RVLaGmZgVWIQBwuQY2J6rExGNITj4Oq5qN6i00OUXYoSSnI544\ngiFJQ9h0z5uMH2/1lijV4+3eDZ9+avVTL10K779v7c/IsEYBZmfD0Udb2+TJ4HYDVsuqpmYV1dX/\n3969x8hVnncc//7msrM3e+1de40xNrbXdlRsEewQCzUkqkKTGERDIFCchjS9SFHURCqqKgqhl4i/\nmlZp1UpRSQIo4JAShYRgVSoQKHIUReAYYoK9GGOwwSa+Za/2Xufy9I/3rHe83jVe4zlzxvN8pKM5\n+86Zs8+8c2aeOe+8myFT6gAADHlJREFU5323Mzj4IoOD2xkZCdde5XKXMX/+J2hpWUdLy1qam9eS\nyy3xs6sa5smpwt5Pcrr0m5fyqZU3sOW2B/ja1+C++y5wcM4lwd698NRTYVqP48dDU+D+/eG+uXND\nL8BrrglJa8WK0DMomwUgn++nr+8Zjh7dwuDgdvL5yUtZ0uk2WlrWRstk0mpoWORJqwbUWnKqm956\nJStxfPg4mbFFFItwxdSxdp27WKxZE5ZyR46EJsAnnwxNgg88MHlfKhUS1fr1ZDdsoHPdOjoX3ANd\nKxlvTzM0tJvh4d0MDYXl+PEfc/jwd089PJPpmCFpLYjn+bqLUt0kp76RPgqlAuN9nYAnJ1dnLrkk\ndEe/+eaQmA4eDGdTBw6E2z17wqjqU9q6Gzo6aFi8mPnr1sHHPw6rbsOWLmW8M8twcR9DQ7tOJa2j\nR39AsTg59Uc2u+i0pNXc/AGamlbT0LDYz7Tce6qb5DRxjdPJI52kUmd+sXSubmQyoTlvxYoz7xsY\nCM2Avb3htrs7nHU9/zw89hgAAnJAbtEi5i9dGjpeLNuIXXYL+cWtjCwYZajpKCOjb3Bi/C2ODDxE\n0Sab4lOpFpqbV9PUtIbm5jU0Nq6ksXE5jY3LyeUuI5XKxlMPLtHqLjkdP9BJV1eYLsM5N0VbG2zc\nGNY3bZosN4M334R33gnLwYOT66+9Bk8/jYaGaAAagLayXVoqBR0dFLoWM97Vxmh7gZG2IYbn/pze\nlscZby+Rb4dSA0CKXG5JlKwuJ5dbRmPjMnK5ZeRyS2lsXEYmMze26nDVU3fJae+vO7n2yioH41yt\nkWDVqrBMxwz6+ycTVm9vuD6rvx/19MCxY2S7u8k+tYeWnp5pd1Ga20RxfiOFOcPkW14l3/wSYy0j\nFFqM0VYozIFCK+Q7c4ytmk+6YS7Z7EIaFqymsbmLxsZlZLMdZDIdNDQsjM7CchWsFFdJddNb77cn\nfsv3nn2Bezd/ki0PtnLHHRUIzjn33vJ5OHYsNBdOXXp7oa8vJLr+fqyvD/r70OjMMzOYoNgcEleh\nJdwWm8DSUGhNUWzLkE61kk61kM60onntqL2TVNtCMrSSapqH2hei9kWkOi4hNaeDVE9f2PmaNeFs\nMlX7Y2R7b72EunTOpRzbdgs5hdFfnHNVks2Ga7CWnG2S1eBUt4nR0fB7WF9f6MTR3R3O5szQwACp\nvuNkeo+Q7u8h19+PnRjECqOk3h4mNTAKOoExAMUSmeHZfyEvNWWwpoaQpCRQOvw20NwMzc2opRU1\nzUEtraEM4O23IZ0OI3lA+K0v2p5sNtqPQnlT09mXdDo8/+XLYe3aWcdfi+rmzKlUCpdzfPjD8NOf\nViAw51xNsEKeQu875Hv3M1b8HaWRXqy3B3p+F87YTg4w1lagMNZL+sCRkBROnkQj48iAaEnlITUG\n6dHyW5EeE6lSivHFjYg02b4ipFKoJFIjRTRSQIUSGAhBoYjyhXML/q67wlQr58HPnBLql78Mo77c\nfnu1I3HOVZMyWbKdXWQ7u2iexeOKxVEkUSyOMDq6n0Khj2LxBPnCCYrFQQqFAQqFfgqFAYrFgejv\ngei+ExSLJykWR5l28tgipMdDkptY0uOQHs+RLTaTKmUpteaY/8Em3vt88+JQ0eQkaRPwH0AaeMDM\n/nnK/TngEeBDQA9wu5kdqEwsofPRjTdWYu/OuYtdOh26+KZSObLZ9ee9n1IpHyWqiYRVvj6MWR6z\nPIXCIGNjhygWT1IqjaLSGJkFqy/U00m8ijXrKYwauRf4BHCIMAXw58ysu2ybvwKuNLMvS9oM3Gxm\nZz23eT/DFznnXL2qtWa9SnZB2QjsM7O3LAx9/Bhw05RtbgIejtYfB66TXzrunHN1r5LJaQlwsOzv\nQ1HZtNtE89cPAB1TdyTpS5J2SNpRKJzjD4fOOedqVk103jez75jZ1WZ2dSZTN304nHOublUyOb0L\nLC37+7KobNptJGUIo55Mf/m4c865ulHJ5PQrYLWkFZIagM3A1inbbAW+GK3fCvyf1dqFV8455y64\nirWRmVlB0leBpwldyR8ys92S7gN2mNlW4EFgi6R9QC8hgTnnnKtzdTNChHPO1TPvSu6cc869TzV3\n5iSpBIyc58MzQFL7oic1No9rdpIaFyQ3No9rds43riYzq5kTkppLTu+HpB1mdnW145hOUmPzuGYn\nqXFBcmPzuGYnqXFdaDWTRZ1zztUPT07OOecSp96S03eqHcBZJDU2j2t2khoXJDc2j2t2khrXBVVX\nvzk555yrDfV25uScc64GeHJyzjmXOHWTnCRtkvS6pH2S7q5iHEslPS+pW9JuSX8dlX9d0ruSdkbL\nDVWI7YCkV6P/vyMqa5f0M0lvRLfzqxDXB8rqZaekQUl3VqPOJD0k6ZikXWVl09aRgv+MjrnfSNoQ\nc1z/KmlP9L+fkDQvKl8uaaSs3u6POa4ZXzdJ90T19bqkT1UqrrPE9sOyuA5I2hmVx1lnM31GVP04\ni5WZXfQLYWy/N4GVQAPwCnBFlWJZDGyI1ucQZgu+Avg68LdVrqcDwIIpZf8C3B2t3w18IwGv5RHg\n8mrUGfAxYAOw673qCLgB+F9AwDXAizHH9UkgE61/oyyu5eXbVaG+pn3dovfBK0AOWBG9Z9Nxxjbl\n/m8C/1iFOpvpM6Lqx1mcS72cOZ3LrLyxMLPDZvZytH4CeI0zJ2FMkvLZih8GPlPFWACuA940s7er\n8c/N7OeEQYrLzVRHNwGPWPACME/S4rjiMrNnLEziCfACYdqaWM1QXzO5CXjMzMbMbD+wj/DejT02\nSQL+GPjvSv3/mZzlM6Lqx1mc6iU5ncusvLGTtBxYD7wYFX01Oi1/qBrNZ4ABz0h6SdKXorJFZnY4\nWj8CLKpCXOU2c/oHRrXrDGauoyQdd39B+HY9YYWkX0vaJumjVYhnutctSfX1UeComb1RVhZ7nU35\njKiF4+yCqZfklDiSWoEfA3ea2SDwX0AXcBVwmNCkELdrzWwDcD3wFUkfK7/TQhtC1a49UJgX7NPA\nj6KiJNTZaapdR9ORdC9hLLZHo6LDwDIzWw/8DfADSXNjDClxr9s0PsfpX4Jir7NpPiNOSeJxdqHV\nS3I6l1l5YyMpSzjoHjWznwCY2VEzK5pZCfguFWzOmImZvRvdHgOeiGI4OtFEEN0eizuuMtcDL5vZ\nUUhGnUVmqqOqH3eS/gy4Efh89IFG1GzWE62/RPhtZ01cMZ3ldat6fcGpWblvAX44URZ3nU33GUGC\nj7NKqJfkdC6z8sYiast+EHjNzP6trLy8jfhmYNfUx1Y4rhZJcybWCT+m7+L02Yq/CDwZZ1xTnPZt\nttp1VmamOtoK/GnUm+oaYKCsWabiJG0C7gI+bWbDZeULJaWj9ZXAauCtGOOa6XXbCmyWlJO0Iopr\ne1xxlflDYI+ZHZooiLPOZvqMIKHHWcVUu0dGXAuhR8tewjeee6sYx7WE0/HfADuj5QZgC/BqVL4V\nWBxzXCsJPaVeAXZP1BHQATwHvAE8C7RXqd5agB6graws9jojJMfDQJ7Qtv+XM9URoffUt6Jj7lXg\n6pjj2kf4LWLiOLs/2vaz0Wu8E3gZ+KOY45rxdQPujerrdeD6uF/LqPx7wJenbBtnnc30GVH14yzO\nxYcvcs45lzj10qznnHOuhnhycs45lzienJxzziWOJyfnnHOJ48nJOedc4nhyci5Gkv5A0v9UOw7n\nks6Tk3POucTx5OTcNCTdIWl7NHfPtyWlJZ2U9O/RHDvPSVoYbXuVpBc0OW/SxDw7qyQ9K+kVSS9L\n6op23yrpcYW5lh6NRgRwzpXx5OTcFJJ+D7gd+IiZXQUUgc8TRqnYYWZrgW3AP0UPeQT4OzO7knCF\n/kT5o8C3zOyDwO8TRiOAMMr0nYQ5elYCH6n4k3KuxmSqHYBzCXQd8CHgV9FJTRNhkM0Sk4OBfh/4\niaQ2YJ6ZbYvKHwZ+FI1TuMTMngAws1GAaH/bLRq3TWGm1eXALyr/tJyrHZ6cnDuTgIfN7J7TCqV/\nmLLd+Y79NVa2XsTfh86dwZv1nDvTc8CtkjoBJLVLupzwfrk12uZPgF+Y2QDQVzb53BeAbRZmMD0k\n6TPRPnKSmmN9Fs7VMP/G5twUZtYt6e8JswKnCKNWfwUYAjZG9x0j/C4FYfqC+6Pk8xbw51H5F4Bv\nS7ov2sdtMT4N52qaj0ru3DmSdNLMWqsdh3P1wJv1nHPOJY6fOTnnnEscP3NyzjmXOJ6cnHPOJY4n\nJ+ecc4njyck551zieHJyzjmXOP8PJyqdSodfK3IAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, loss_ax = plt.subplots()\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "loss_ax.plot(history.history['loss'], 'y', label='train loss')\n",
    "loss_ax.plot(history.history['val_loss'], 'r', label='val loss')\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "loss_ax.legend(loc='upper left')\n",
    "\n",
    "acc_ax.plot(history.history['acc'], 'b', label='train acc')\n",
    "acc_ax.plot(history.history['val_acc'], 'g', label='val acc')\n",
    "acc_ax.set_ylabel('accuracy')\n",
    "acc_ax.legend(loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "etwnBI0pv_hI"
   },
   "outputs": [],
   "source": [
    "prediction1 = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i-Dh0X9bHSK7"
   },
   "source": [
    "### 2. NN \n",
    "* linear\n",
    "* 6 layers\n",
    "* weight initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1230,
     "status": "ok",
     "timestamp": 1584384226166,
     "user": {
      "displayName": "이재빈",
      "photoUrl": "",
      "userId": "06683534214657838443"
     },
     "user_tz": -540
    },
    "id": "KasKzCBFG7zF",
    "outputId": "1130cd3f-dd0b-4013-a874-4298e419002d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29400, 784) (12600, 784) (29400,) (12600,)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=22)\n",
    "print(x_train.shape, x_val.shape, y_train.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_hSkdPBicpM3"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gz9ZZdNyG7qq"
   },
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(1024, input_shape=(784,), kernel_initializer='he_normal'),\n",
    "        tf.keras.layers.BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\"),\n",
    "        tf.keras.layers.LeakyReLU(alpha=0.1),\n",
    "        tf.keras.layers.Dropout(0.25),\n",
    "\n",
    "        tf.keras.layers.Dense(512, kernel_initializer='he_normal'),\n",
    "        tf.keras.layers.BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\"),\n",
    "        tf.keras.layers.LeakyReLU(alpha=0.1),\n",
    "        tf.keras.layers.Dropout(0.25),\n",
    "\n",
    "        tf.keras.layers.Dense(256, kernel_initializer='he_normal'),\n",
    "        tf.keras.layers.BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\"),\n",
    "        tf.keras.layers.LeakyReLU(alpha=0.1),\n",
    "        tf.keras.layers.Dropout(0.25),\n",
    "\n",
    "        tf.keras.layers.Dense(128, kernel_initializer='he_normal'),\n",
    "        tf.keras.layers.BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\"),\n",
    "        tf.keras.layers.LeakyReLU(alpha=0.1),\n",
    "        tf.keras.layers.Dropout(0.25),\n",
    "\n",
    "        tf.keras.layers.Dense(64, kernel_initializer='he_normal'),\n",
    "        tf.keras.layers.BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\"),\n",
    "        tf.keras.layers.LeakyReLU(alpha=0.1),\n",
    "        tf.keras.layers.Dropout(0.25),\n",
    "\n",
    "        tf.keras.layers.Dense(32, kernel_initializer='he_normal'),\n",
    "        tf.keras.layers.BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\"),\n",
    "        tf.keras.layers.LeakyReLU(alpha=0.1),\n",
    "        tf.keras.layers.Dropout(0.25),\n",
    "\n",
    "        tf.keras.layers.Dense(num_classes, activation=\"softmax\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1252,
     "status": "ok",
     "timestamp": 1584384247641,
     "user": {
      "displayName": "이재빈",
      "photoUrl": "",
      "userId": "06683534214657838443"
     },
     "user_tz": -540
    },
    "id": "iuP1um70fD8p",
    "outputId": "74463c6e-999d-487e-d4d6-68f721c1cfcd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_24 (Dense)             (None, 1024)              803840    \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_20 (LeakyReLU)   (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_21 (LeakyReLU)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_22 (LeakyReLU)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_23 (LeakyReLU)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_24 (LeakyReLU)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_25 (LeakyReLU)   (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 1,511,594\n",
      "Trainable params: 1,507,562\n",
      "Non-trainable params: 4,032\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer = RAdamOptimizer(learning_rate=1e-4), loss=\"sparse_categorical_crossentropy\", metrics=[\"acc\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dqoAGLR6G7Y8"
   },
   "outputs": [],
   "source": [
    "filename = 'checkpoint-epoch-{}-batch-{}-trial-001.h5'.format(3000, 1024)\n",
    "checkpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
    "early_stopping = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=50, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 447533,
     "status": "ok",
     "timestamp": 1584384716355,
     "user": {
      "displayName": "이재빈",
      "photoUrl": "",
      "userId": "06683534214657838443"
     },
     "user_tz": -540
    },
    "id": "OKqDdDC1dGE-",
    "outputId": "75d3e44b-da1e-439e-94da-e592738e4e39"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 29400 samples, validate on 12600 samples\n",
      "Epoch 1/3000\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.30259, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 3s - loss: 2.3014 - acc: 0.1126 - val_loss: 2.3026 - val_acc: 0.1002\n",
      "Epoch 2/3000\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 2.30259\n",
      "29400/29400 - 1s - loss: 2.3007 - acc: 0.1177 - val_loss: 2.3026 - val_acc: 0.1002\n",
      "Epoch 3/3000\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 2.30259\n",
      "29400/29400 - 1s - loss: 2.3000 - acc: 0.1206 - val_loss: 2.3026 - val_acc: 0.1002\n",
      "Epoch 4/3000\n",
      "\n",
      "Epoch 00004: val_loss improved from 2.30259 to 2.30258, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 2.2986 - acc: 0.1342 - val_loss: 2.3026 - val_acc: 0.1002\n",
      "Epoch 5/3000\n",
      "\n",
      "Epoch 00005: val_loss improved from 2.30258 to 2.30253, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 2.2971 - acc: 0.1472 - val_loss: 2.3025 - val_acc: 0.1002\n",
      "Epoch 6/3000\n",
      "\n",
      "Epoch 00006: val_loss improved from 2.30253 to 2.30202, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 2.2950 - acc: 0.1608 - val_loss: 2.3020 - val_acc: 0.1005\n",
      "Epoch 7/3000\n",
      "\n",
      "Epoch 00007: val_loss improved from 2.30202 to 2.29921, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 2.2931 - acc: 0.1783 - val_loss: 2.2992 - val_acc: 0.1911\n",
      "Epoch 8/3000\n",
      "\n",
      "Epoch 00008: val_loss improved from 2.29921 to 2.29326, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 2.2907 - acc: 0.1976 - val_loss: 2.2933 - val_acc: 0.3333\n",
      "Epoch 9/3000\n",
      "\n",
      "Epoch 00009: val_loss improved from 2.29326 to 2.28681, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 2.2882 - acc: 0.2193 - val_loss: 2.2868 - val_acc: 0.4065\n",
      "Epoch 10/3000\n",
      "\n",
      "Epoch 00010: val_loss improved from 2.28681 to 2.28130, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 2.2853 - acc: 0.2474 - val_loss: 2.2813 - val_acc: 0.4552\n",
      "Epoch 11/3000\n",
      "\n",
      "Epoch 00011: val_loss improved from 2.28130 to 2.27685, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 2.2826 - acc: 0.2633 - val_loss: 2.2769 - val_acc: 0.4879\n",
      "Epoch 12/3000\n",
      "\n",
      "Epoch 00012: val_loss improved from 2.27685 to 2.27259, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 2.2799 - acc: 0.2855 - val_loss: 2.2726 - val_acc: 0.5165\n",
      "Epoch 13/3000\n",
      "\n",
      "Epoch 00013: val_loss improved from 2.27259 to 2.26846, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 2.2763 - acc: 0.3186 - val_loss: 2.2685 - val_acc: 0.5513\n",
      "Epoch 14/3000\n",
      "\n",
      "Epoch 00014: val_loss improved from 2.26846 to 2.26454, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 2.2734 - acc: 0.3329 - val_loss: 2.2645 - val_acc: 0.5790\n",
      "Epoch 15/3000\n",
      "\n",
      "Epoch 00015: val_loss improved from 2.26454 to 2.26053, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 2.2702 - acc: 0.3593 - val_loss: 2.2605 - val_acc: 0.6098\n",
      "Epoch 16/3000\n",
      "\n",
      "Epoch 00016: val_loss improved from 2.26053 to 2.25643, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 2.2669 - acc: 0.3797 - val_loss: 2.2564 - val_acc: 0.6409\n",
      "Epoch 17/3000\n",
      "\n",
      "Epoch 00017: val_loss improved from 2.25643 to 2.25260, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 2.2636 - acc: 0.4030 - val_loss: 2.2526 - val_acc: 0.6684\n",
      "Epoch 18/3000\n",
      "\n",
      "Epoch 00018: val_loss improved from 2.25260 to 2.24859, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 2.2602 - acc: 0.4253 - val_loss: 2.2486 - val_acc: 0.6946\n",
      "Epoch 19/3000\n",
      "\n",
      "Epoch 00019: val_loss improved from 2.24859 to 2.24476, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 2.2566 - acc: 0.4469 - val_loss: 2.2448 - val_acc: 0.7194\n",
      "Epoch 20/3000\n",
      "\n",
      "Epoch 00020: val_loss improved from 2.24476 to 2.24088, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 2.2533 - acc: 0.4716 - val_loss: 2.2409 - val_acc: 0.7387\n",
      "Epoch 21/3000\n",
      "\n",
      "Epoch 00021: val_loss improved from 2.24088 to 2.23687, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 2.2499 - acc: 0.4901 - val_loss: 2.2369 - val_acc: 0.7583\n",
      "Epoch 22/3000\n",
      "\n",
      "Epoch 00022: val_loss improved from 2.23687 to 2.23309, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 2.2465 - acc: 0.5107 - val_loss: 2.2331 - val_acc: 0.7787\n",
      "Epoch 23/3000\n",
      "\n",
      "Epoch 00023: val_loss improved from 2.23309 to 2.22906, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 2.2429 - acc: 0.5327 - val_loss: 2.2291 - val_acc: 0.7939\n",
      "Epoch 24/3000\n",
      "\n",
      "Epoch 00024: val_loss improved from 2.22906 to 2.22528, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 2.2396 - acc: 0.5549 - val_loss: 2.2253 - val_acc: 0.8067\n",
      "Epoch 25/3000\n",
      "\n",
      "Epoch 00025: val_loss improved from 2.22528 to 2.22122, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 2.2362 - acc: 0.5695 - val_loss: 2.2212 - val_acc: 0.8185\n",
      "Epoch 26/3000\n",
      "\n",
      "Epoch 00026: val_loss improved from 2.22122 to 2.21737, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 2.2324 - acc: 0.5831 - val_loss: 2.2174 - val_acc: 0.8288\n",
      "Epoch 27/3000\n",
      "\n",
      "Epoch 00027: val_loss improved from 2.21737 to 2.21336, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 2.2289 - acc: 0.6020 - val_loss: 2.2134 - val_acc: 0.8398\n",
      "Epoch 28/3000\n",
      "\n",
      "Epoch 00028: val_loss improved from 2.21336 to 2.20928, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 2.2253 - acc: 0.6196 - val_loss: 2.2093 - val_acc: 0.8478\n",
      "Epoch 29/3000\n",
      "\n",
      "Epoch 00029: val_loss improved from 2.20928 to 2.20518, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 2.2215 - acc: 0.6405 - val_loss: 2.2052 - val_acc: 0.8551\n",
      "Epoch 30/3000\n",
      "\n",
      "Epoch 00030: val_loss improved from 2.20518 to 2.20097, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 2.2176 - acc: 0.6541 - val_loss: 2.2010 - val_acc: 0.8602\n",
      "Epoch 31/3000\n",
      "\n",
      "Epoch 00031: val_loss improved from 2.20097 to 2.19656, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 2.2137 - acc: 0.6662 - val_loss: 2.1966 - val_acc: 0.8680\n",
      "Epoch 32/3000\n",
      "\n",
      "Epoch 00032: val_loss improved from 2.19656 to 2.19239, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 2.2098 - acc: 0.6786 - val_loss: 2.1924 - val_acc: 0.8743\n",
      "Epoch 33/3000\n",
      "\n",
      "Epoch 00033: val_loss improved from 2.19239 to 2.18775, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 2.2053 - acc: 0.6939 - val_loss: 2.1877 - val_acc: 0.8806\n",
      "Epoch 34/3000\n",
      "\n",
      "Epoch 00034: val_loss improved from 2.18775 to 2.18332, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 2.2016 - acc: 0.7056 - val_loss: 2.1833 - val_acc: 0.8841\n",
      "Epoch 35/3000\n",
      "\n",
      "Epoch 00035: val_loss improved from 2.18332 to 2.17882, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 2.1974 - acc: 0.7197 - val_loss: 2.1788 - val_acc: 0.8887\n",
      "Epoch 36/3000\n",
      "\n",
      "Epoch 00036: val_loss improved from 2.17882 to 2.17410, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 2.1929 - acc: 0.7356 - val_loss: 2.1741 - val_acc: 0.8931\n",
      "Epoch 37/3000\n",
      "\n",
      "Epoch 00037: val_loss improved from 2.17410 to 2.16908, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 2.1888 - acc: 0.7374 - val_loss: 2.1691 - val_acc: 0.8972\n",
      "Epoch 38/3000\n",
      "\n",
      "Epoch 00038: val_loss improved from 2.16908 to 2.16429, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 2.1847 - acc: 0.7470 - val_loss: 2.1643 - val_acc: 0.9022\n",
      "Epoch 39/3000\n",
      "\n",
      "Epoch 00039: val_loss improved from 2.16429 to 2.15963, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 2.1807 - acc: 0.7566 - val_loss: 2.1596 - val_acc: 0.9062\n",
      "Epoch 40/3000\n",
      "\n",
      "Epoch 00040: val_loss improved from 2.15963 to 2.15483, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 2.1763 - acc: 0.7650 - val_loss: 2.1548 - val_acc: 0.9103\n",
      "Epoch 41/3000\n",
      "\n",
      "Epoch 00041: val_loss improved from 2.15483 to 2.15005, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 2.1716 - acc: 0.7758 - val_loss: 2.1500 - val_acc: 0.9137\n",
      "Epoch 42/3000\n",
      "\n",
      "Epoch 00042: val_loss improved from 2.15005 to 2.14497, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 2.1671 - acc: 0.7800 - val_loss: 2.1450 - val_acc: 0.9163\n",
      "Epoch 43/3000\n",
      "\n",
      "Epoch 00043: val_loss improved from 2.14497 to 2.13967, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 2.1624 - acc: 0.7913 - val_loss: 2.1397 - val_acc: 0.9202\n",
      "Epoch 44/3000\n",
      "\n",
      "Epoch 00044: val_loss improved from 2.13967 to 2.13451, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 2.1577 - acc: 0.8010 - val_loss: 2.1345 - val_acc: 0.9240\n",
      "Epoch 45/3000\n",
      "\n",
      "Epoch 00045: val_loss improved from 2.13451 to 2.12948, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 2.1535 - acc: 0.8037 - val_loss: 2.1295 - val_acc: 0.9269\n",
      "Epoch 46/3000\n",
      "\n",
      "Epoch 00046: val_loss improved from 2.12948 to 2.12450, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 2.1488 - acc: 0.8134 - val_loss: 2.1245 - val_acc: 0.9308\n",
      "Epoch 47/3000\n",
      "\n",
      "Epoch 00047: val_loss improved from 2.12450 to 2.11991, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 2.1438 - acc: 0.8185 - val_loss: 2.1199 - val_acc: 0.9337\n",
      "Epoch 48/3000\n",
      "\n",
      "Epoch 00048: val_loss improved from 2.11991 to 2.11471, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 2.1395 - acc: 0.8248 - val_loss: 2.1147 - val_acc: 0.9356\n",
      "Epoch 49/3000\n",
      "\n",
      "Epoch 00049: val_loss improved from 2.11471 to 2.10988, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 2.1340 - acc: 0.8313 - val_loss: 2.1099 - val_acc: 0.9378\n",
      "Epoch 50/3000\n",
      "\n",
      "Epoch 00050: val_loss improved from 2.10988 to 2.10450, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 2.1293 - acc: 0.8373 - val_loss: 2.1045 - val_acc: 0.9404\n",
      "Epoch 51/3000\n",
      "\n",
      "Epoch 00051: val_loss improved from 2.10450 to 2.09885, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 2.1242 - acc: 0.8445 - val_loss: 2.0988 - val_acc: 0.9415\n",
      "Epoch 52/3000\n",
      "\n",
      "Epoch 00052: val_loss improved from 2.09885 to 2.09366, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 2.1196 - acc: 0.8472 - val_loss: 2.0937 - val_acc: 0.9439\n",
      "Epoch 53/3000\n",
      "\n",
      "Epoch 00053: val_loss improved from 2.09366 to 2.08786, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 2.1152 - acc: 0.8526 - val_loss: 2.0879 - val_acc: 0.9454\n",
      "Epoch 54/3000\n",
      "\n",
      "Epoch 00054: val_loss improved from 2.08786 to 2.08260, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 2.1095 - acc: 0.8585 - val_loss: 2.0826 - val_acc: 0.9477\n",
      "Epoch 55/3000\n",
      "\n",
      "Epoch 00055: val_loss improved from 2.08260 to 2.07712, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 2.1040 - acc: 0.8628 - val_loss: 2.0771 - val_acc: 0.9486\n",
      "Epoch 56/3000\n",
      "\n",
      "Epoch 00056: val_loss improved from 2.07712 to 2.07186, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 2.0993 - acc: 0.8672 - val_loss: 2.0719 - val_acc: 0.9499\n",
      "Epoch 57/3000\n",
      "\n",
      "Epoch 00057: val_loss improved from 2.07186 to 2.06571, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 2.0939 - acc: 0.8677 - val_loss: 2.0657 - val_acc: 0.9513\n",
      "Epoch 58/3000\n",
      "\n",
      "Epoch 00058: val_loss improved from 2.06571 to 2.06005, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 2.0888 - acc: 0.8776 - val_loss: 2.0601 - val_acc: 0.9521\n",
      "Epoch 59/3000\n",
      "\n",
      "Epoch 00059: val_loss improved from 2.06005 to 2.05402, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 2.0829 - acc: 0.8824 - val_loss: 2.0540 - val_acc: 0.9529\n",
      "Epoch 60/3000\n",
      "\n",
      "Epoch 00060: val_loss improved from 2.05402 to 2.04782, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 2.0782 - acc: 0.8846 - val_loss: 2.0478 - val_acc: 0.9538\n",
      "Epoch 61/3000\n",
      "\n",
      "Epoch 00061: val_loss improved from 2.04782 to 2.04266, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 2.0728 - acc: 0.8858 - val_loss: 2.0427 - val_acc: 0.9546\n",
      "Epoch 62/3000\n",
      "\n",
      "Epoch 00062: val_loss improved from 2.04266 to 2.03648, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 2.0666 - acc: 0.8885 - val_loss: 2.0365 - val_acc: 0.9560\n",
      "Epoch 63/3000\n",
      "\n",
      "Epoch 00063: val_loss improved from 2.03648 to 2.03060, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 2.0614 - acc: 0.8952 - val_loss: 2.0306 - val_acc: 0.9563\n",
      "Epoch 64/3000\n",
      "\n",
      "Epoch 00064: val_loss improved from 2.03060 to 2.02468, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 2.0553 - acc: 0.9009 - val_loss: 2.0247 - val_acc: 0.9573\n",
      "Epoch 65/3000\n",
      "\n",
      "Epoch 00065: val_loss improved from 2.02468 to 2.01868, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 2.0499 - acc: 0.9030 - val_loss: 2.0187 - val_acc: 0.9582\n",
      "Epoch 66/3000\n",
      "\n",
      "Epoch 00066: val_loss improved from 2.01868 to 2.01277, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 2.0443 - acc: 0.9047 - val_loss: 2.0128 - val_acc: 0.9587\n",
      "Epoch 67/3000\n",
      "\n",
      "Epoch 00067: val_loss improved from 2.01277 to 2.00684, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 2.0384 - acc: 0.9085 - val_loss: 2.0068 - val_acc: 0.9594\n",
      "Epoch 68/3000\n",
      "\n",
      "Epoch 00068: val_loss improved from 2.00684 to 2.00070, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 2.0316 - acc: 0.9116 - val_loss: 2.0007 - val_acc: 0.9609\n",
      "Epoch 69/3000\n",
      "\n",
      "Epoch 00069: val_loss improved from 2.00070 to 1.99403, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 2.0269 - acc: 0.9127 - val_loss: 1.9940 - val_acc: 0.9609\n",
      "Epoch 70/3000\n",
      "\n",
      "Epoch 00070: val_loss improved from 1.99403 to 1.98767, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 2.0202 - acc: 0.9137 - val_loss: 1.9877 - val_acc: 0.9615\n",
      "Epoch 71/3000\n",
      "\n",
      "Epoch 00071: val_loss improved from 1.98767 to 1.98172, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 2.0143 - acc: 0.9196 - val_loss: 1.9817 - val_acc: 0.9623\n",
      "Epoch 72/3000\n",
      "\n",
      "Epoch 00072: val_loss improved from 1.98172 to 1.97487, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 2.0093 - acc: 0.9200 - val_loss: 1.9749 - val_acc: 0.9631\n",
      "Epoch 73/3000\n",
      "\n",
      "Epoch 00073: val_loss improved from 1.97487 to 1.96887, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 2.0019 - acc: 0.9235 - val_loss: 1.9689 - val_acc: 0.9633\n",
      "Epoch 74/3000\n",
      "\n",
      "Epoch 00074: val_loss improved from 1.96887 to 1.96196, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 1.9965 - acc: 0.9242 - val_loss: 1.9620 - val_acc: 0.9643\n",
      "Epoch 75/3000\n",
      "\n",
      "Epoch 00075: val_loss improved from 1.96196 to 1.95522, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 1.9900 - acc: 0.9267 - val_loss: 1.9552 - val_acc: 0.9648\n",
      "Epoch 76/3000\n",
      "\n",
      "Epoch 00076: val_loss improved from 1.95522 to 1.94854, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 1.9828 - acc: 0.9308 - val_loss: 1.9485 - val_acc: 0.9652\n",
      "Epoch 77/3000\n",
      "\n",
      "Epoch 00077: val_loss improved from 1.94854 to 1.94164, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 1.9770 - acc: 0.9317 - val_loss: 1.9416 - val_acc: 0.9660\n",
      "Epoch 78/3000\n",
      "\n",
      "Epoch 00078: val_loss improved from 1.94164 to 1.93477, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 1.9704 - acc: 0.9317 - val_loss: 1.9348 - val_acc: 0.9664\n",
      "Epoch 79/3000\n",
      "\n",
      "Epoch 00079: val_loss improved from 1.93477 to 1.92808, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 1.9640 - acc: 0.9369 - val_loss: 1.9281 - val_acc: 0.9673\n",
      "Epoch 80/3000\n",
      "\n",
      "Epoch 00080: val_loss improved from 1.92808 to 1.92195, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 1.9570 - acc: 0.9370 - val_loss: 1.9220 - val_acc: 0.9679\n",
      "Epoch 81/3000\n",
      "\n",
      "Epoch 00081: val_loss improved from 1.92195 to 1.91439, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 1.9499 - acc: 0.9376 - val_loss: 1.9144 - val_acc: 0.9685\n",
      "Epoch 82/3000\n",
      "\n",
      "Epoch 00082: val_loss improved from 1.91439 to 1.90665, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 1.9441 - acc: 0.9399 - val_loss: 1.9066 - val_acc: 0.9686\n",
      "Epoch 83/3000\n",
      "\n",
      "Epoch 00083: val_loss improved from 1.90665 to 1.90001, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 1.9362 - acc: 0.9430 - val_loss: 1.9000 - val_acc: 0.9687\n",
      "Epoch 84/3000\n",
      "\n",
      "Epoch 00084: val_loss improved from 1.90001 to 1.89311, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 1.9307 - acc: 0.9448 - val_loss: 1.8931 - val_acc: 0.9690\n",
      "Epoch 85/3000\n",
      "\n",
      "Epoch 00085: val_loss improved from 1.89311 to 1.88580, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 1.9233 - acc: 0.9462 - val_loss: 1.8858 - val_acc: 0.9694\n",
      "Epoch 86/3000\n",
      "\n",
      "Epoch 00086: val_loss improved from 1.88580 to 1.87866, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 1.9165 - acc: 0.9482 - val_loss: 1.8787 - val_acc: 0.9694\n",
      "Epoch 87/3000\n",
      "\n",
      "Epoch 00087: val_loss improved from 1.87866 to 1.87107, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 1.9103 - acc: 0.9483 - val_loss: 1.8711 - val_acc: 0.9698\n",
      "Epoch 88/3000\n",
      "\n",
      "Epoch 00088: val_loss improved from 1.87107 to 1.86368, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 1.9025 - acc: 0.9519 - val_loss: 1.8637 - val_acc: 0.9704\n",
      "Epoch 89/3000\n",
      "\n",
      "Epoch 00089: val_loss improved from 1.86368 to 1.85640, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 1.8950 - acc: 0.9518 - val_loss: 1.8564 - val_acc: 0.9708\n",
      "Epoch 90/3000\n",
      "\n",
      "Epoch 00090: val_loss improved from 1.85640 to 1.84930, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 1.8876 - acc: 0.9541 - val_loss: 1.8493 - val_acc: 0.9711\n",
      "Epoch 91/3000\n",
      "\n",
      "Epoch 00091: val_loss improved from 1.84930 to 1.84148, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 1.8800 - acc: 0.9545 - val_loss: 1.8415 - val_acc: 0.9717\n",
      "Epoch 92/3000\n",
      "\n",
      "Epoch 00092: val_loss improved from 1.84148 to 1.83463, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 1.8729 - acc: 0.9564 - val_loss: 1.8346 - val_acc: 0.9727\n",
      "Epoch 93/3000\n",
      "\n",
      "Epoch 00093: val_loss improved from 1.83463 to 1.82641, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 1.8658 - acc: 0.9573 - val_loss: 1.8264 - val_acc: 0.9730\n",
      "Epoch 94/3000\n",
      "\n",
      "Epoch 00094: val_loss improved from 1.82641 to 1.81874, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 1.8578 - acc: 0.9588 - val_loss: 1.8187 - val_acc: 0.9731\n",
      "Epoch 95/3000\n",
      "\n",
      "Epoch 00095: val_loss improved from 1.81874 to 1.81091, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 1.8514 - acc: 0.9594 - val_loss: 1.8109 - val_acc: 0.9732\n",
      "Epoch 96/3000\n",
      "\n",
      "Epoch 00096: val_loss improved from 1.81091 to 1.80327, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 1.8449 - acc: 0.9600 - val_loss: 1.8033 - val_acc: 0.9733\n",
      "Epoch 97/3000\n",
      "\n",
      "Epoch 00097: val_loss improved from 1.80327 to 1.79555, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 1.8355 - acc: 0.9601 - val_loss: 1.7956 - val_acc: 0.9735\n",
      "Epoch 98/3000\n",
      "\n",
      "Epoch 00098: val_loss improved from 1.79555 to 1.78733, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 1.8286 - acc: 0.9618 - val_loss: 1.7873 - val_acc: 0.9739\n",
      "Epoch 99/3000\n",
      "\n",
      "Epoch 00099: val_loss improved from 1.78733 to 1.77997, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 1.8217 - acc: 0.9639 - val_loss: 1.7800 - val_acc: 0.9744\n",
      "Epoch 100/3000\n",
      "\n",
      "Epoch 00100: val_loss improved from 1.77997 to 1.77185, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 1.8138 - acc: 0.9650 - val_loss: 1.7719 - val_acc: 0.9749\n",
      "Epoch 101/3000\n",
      "\n",
      "Epoch 00101: val_loss improved from 1.77185 to 1.76366, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 1.8057 - acc: 0.9655 - val_loss: 1.7637 - val_acc: 0.9751\n",
      "Epoch 102/3000\n",
      "\n",
      "Epoch 00102: val_loss improved from 1.76366 to 1.75651, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 1.7980 - acc: 0.9651 - val_loss: 1.7565 - val_acc: 0.9752\n",
      "Epoch 103/3000\n",
      "\n",
      "Epoch 00103: val_loss improved from 1.75651 to 1.74781, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 1.7899 - acc: 0.9666 - val_loss: 1.7478 - val_acc: 0.9756\n",
      "Epoch 104/3000\n",
      "\n",
      "Epoch 00104: val_loss improved from 1.74781 to 1.74030, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 1.7812 - acc: 0.9691 - val_loss: 1.7403 - val_acc: 0.9763\n",
      "Epoch 105/3000\n",
      "\n",
      "Epoch 00105: val_loss improved from 1.74030 to 1.73259, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 1.7748 - acc: 0.9688 - val_loss: 1.7326 - val_acc: 0.9768\n",
      "Epoch 106/3000\n",
      "\n",
      "Epoch 00106: val_loss improved from 1.73259 to 1.72359, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 1.7655 - acc: 0.9686 - val_loss: 1.7236 - val_acc: 0.9765\n",
      "Epoch 107/3000\n",
      "\n",
      "Epoch 00107: val_loss improved from 1.72359 to 1.71522, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 1.7581 - acc: 0.9698 - val_loss: 1.7152 - val_acc: 0.9770\n",
      "Epoch 108/3000\n",
      "\n",
      "Epoch 00108: val_loss improved from 1.71522 to 1.70746, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 1.7494 - acc: 0.9709 - val_loss: 1.7075 - val_acc: 0.9775\n",
      "Epoch 109/3000\n",
      "\n",
      "Epoch 00109: val_loss improved from 1.70746 to 1.69846, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 1.7420 - acc: 0.9716 - val_loss: 1.6985 - val_acc: 0.9779\n",
      "Epoch 110/3000\n",
      "\n",
      "Epoch 00110: val_loss improved from 1.69846 to 1.68967, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 1.7335 - acc: 0.9737 - val_loss: 1.6897 - val_acc: 0.9776\n",
      "Epoch 111/3000\n",
      "\n",
      "Epoch 00111: val_loss improved from 1.68967 to 1.68183, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 1.7246 - acc: 0.9732 - val_loss: 1.6818 - val_acc: 0.9785\n",
      "Epoch 112/3000\n",
      "\n",
      "Epoch 00112: val_loss improved from 1.68183 to 1.67263, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 1.7183 - acc: 0.9746 - val_loss: 1.6726 - val_acc: 0.9783\n",
      "Epoch 113/3000\n",
      "\n",
      "Epoch 00113: val_loss improved from 1.67263 to 1.66304, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 1.7097 - acc: 0.9755 - val_loss: 1.6630 - val_acc: 0.9783\n",
      "Epoch 114/3000\n",
      "\n",
      "Epoch 00114: val_loss improved from 1.66304 to 1.65495, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 1.7021 - acc: 0.9737 - val_loss: 1.6550 - val_acc: 0.9789\n",
      "Epoch 115/3000\n",
      "\n",
      "Epoch 00115: val_loss improved from 1.65495 to 1.64620, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 1.6940 - acc: 0.9764 - val_loss: 1.6462 - val_acc: 0.9796\n",
      "Epoch 116/3000\n",
      "\n",
      "Epoch 00116: val_loss improved from 1.64620 to 1.63719, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 1.6854 - acc: 0.9763 - val_loss: 1.6372 - val_acc: 0.9801\n",
      "Epoch 117/3000\n",
      "\n",
      "Epoch 00117: val_loss improved from 1.63719 to 1.62868, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 1.6754 - acc: 0.9766 - val_loss: 1.6287 - val_acc: 0.9794\n",
      "Epoch 118/3000\n",
      "\n",
      "Epoch 00118: val_loss improved from 1.62868 to 1.61994, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 1.6676 - acc: 0.9784 - val_loss: 1.6199 - val_acc: 0.9798\n",
      "Epoch 119/3000\n",
      "\n",
      "Epoch 00119: val_loss improved from 1.61994 to 1.61146, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 1.6595 - acc: 0.9777 - val_loss: 1.6115 - val_acc: 0.9800\n",
      "Epoch 120/3000\n",
      "\n",
      "Epoch 00120: val_loss improved from 1.61146 to 1.60224, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 1.6492 - acc: 0.9799 - val_loss: 1.6022 - val_acc: 0.9805\n",
      "Epoch 121/3000\n",
      "\n",
      "Epoch 00121: val_loss improved from 1.60224 to 1.59344, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 1.6422 - acc: 0.9791 - val_loss: 1.5934 - val_acc: 0.9802\n",
      "Epoch 122/3000\n",
      "\n",
      "Epoch 00122: val_loss improved from 1.59344 to 1.58474, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 1.6345 - acc: 0.9802 - val_loss: 1.5847 - val_acc: 0.9810\n",
      "Epoch 123/3000\n",
      "\n",
      "Epoch 00123: val_loss improved from 1.58474 to 1.57637, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 1.6229 - acc: 0.9807 - val_loss: 1.5764 - val_acc: 0.9813\n",
      "Epoch 124/3000\n",
      "\n",
      "Epoch 00124: val_loss improved from 1.57637 to 1.56637, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 1.6162 - acc: 0.9807 - val_loss: 1.5664 - val_acc: 0.9811\n",
      "Epoch 125/3000\n",
      "\n",
      "Epoch 00125: val_loss improved from 1.56637 to 1.55804, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 1.6069 - acc: 0.9808 - val_loss: 1.5580 - val_acc: 0.9819\n",
      "Epoch 126/3000\n",
      "\n",
      "Epoch 00126: val_loss improved from 1.55804 to 1.54776, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 1.6004 - acc: 0.9810 - val_loss: 1.5478 - val_acc: 0.9818\n",
      "Epoch 127/3000\n",
      "\n",
      "Epoch 00127: val_loss improved from 1.54776 to 1.53941, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 1.5906 - acc: 0.9833 - val_loss: 1.5394 - val_acc: 0.9819\n",
      "Epoch 128/3000\n",
      "\n",
      "Epoch 00128: val_loss improved from 1.53941 to 1.52911, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 1.5800 - acc: 0.9823 - val_loss: 1.5291 - val_acc: 0.9822\n",
      "Epoch 129/3000\n",
      "\n",
      "Epoch 00129: val_loss improved from 1.52911 to 1.51995, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 1.5709 - acc: 0.9821 - val_loss: 1.5200 - val_acc: 0.9825\n",
      "Epoch 130/3000\n",
      "\n",
      "Epoch 00130: val_loss improved from 1.51995 to 1.51166, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 1.5652 - acc: 0.9829 - val_loss: 1.5117 - val_acc: 0.9831\n",
      "Epoch 131/3000\n",
      "\n",
      "Epoch 00131: val_loss improved from 1.51166 to 1.50228, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 1.5539 - acc: 0.9841 - val_loss: 1.5023 - val_acc: 0.9829\n",
      "Epoch 132/3000\n",
      "\n",
      "Epoch 00132: val_loss improved from 1.50228 to 1.49249, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 1.5461 - acc: 0.9839 - val_loss: 1.4925 - val_acc: 0.9826\n",
      "Epoch 133/3000\n",
      "\n",
      "Epoch 00133: val_loss improved from 1.49249 to 1.48482, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 1.5357 - acc: 0.9844 - val_loss: 1.4848 - val_acc: 0.9830\n",
      "Epoch 134/3000\n",
      "\n",
      "Epoch 00134: val_loss improved from 1.48482 to 1.47499, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 1.5262 - acc: 0.9849 - val_loss: 1.4750 - val_acc: 0.9834\n",
      "Epoch 135/3000\n",
      "\n",
      "Epoch 00135: val_loss improved from 1.47499 to 1.46458, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 1.5192 - acc: 0.9851 - val_loss: 1.4646 - val_acc: 0.9835\n",
      "Epoch 136/3000\n",
      "\n",
      "Epoch 00136: val_loss improved from 1.46458 to 1.45612, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 1.5090 - acc: 0.9846 - val_loss: 1.4561 - val_acc: 0.9837\n",
      "Epoch 137/3000\n",
      "\n",
      "Epoch 00137: val_loss improved from 1.45612 to 1.44561, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 1.5002 - acc: 0.9863 - val_loss: 1.4456 - val_acc: 0.9841\n",
      "Epoch 138/3000\n",
      "\n",
      "Epoch 00138: val_loss improved from 1.44561 to 1.43528, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 1.4910 - acc: 0.9864 - val_loss: 1.4353 - val_acc: 0.9843\n",
      "Epoch 139/3000\n",
      "\n",
      "Epoch 00139: val_loss improved from 1.43528 to 1.42584, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 1.4816 - acc: 0.9882 - val_loss: 1.4258 - val_acc: 0.9847\n",
      "Epoch 140/3000\n",
      "\n",
      "Epoch 00140: val_loss improved from 1.42584 to 1.41633, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 1.4726 - acc: 0.9874 - val_loss: 1.4163 - val_acc: 0.9852\n",
      "Epoch 141/3000\n",
      "\n",
      "Epoch 00141: val_loss improved from 1.41633 to 1.40725, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 1.4645 - acc: 0.9882 - val_loss: 1.4073 - val_acc: 0.9846\n",
      "Epoch 142/3000\n",
      "\n",
      "Epoch 00142: val_loss improved from 1.40725 to 1.39867, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 1.4542 - acc: 0.9883 - val_loss: 1.3987 - val_acc: 0.9847\n",
      "Epoch 143/3000\n",
      "\n",
      "Epoch 00143: val_loss improved from 1.39867 to 1.38912, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 1.4449 - acc: 0.9885 - val_loss: 1.3891 - val_acc: 0.9850\n",
      "Epoch 144/3000\n",
      "\n",
      "Epoch 00144: val_loss improved from 1.38912 to 1.37926, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 1.4357 - acc: 0.9889 - val_loss: 1.3793 - val_acc: 0.9847\n",
      "Epoch 145/3000\n",
      "\n",
      "Epoch 00145: val_loss improved from 1.37926 to 1.37047, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 1.4279 - acc: 0.9890 - val_loss: 1.3705 - val_acc: 0.9852\n",
      "Epoch 146/3000\n",
      "\n",
      "Epoch 00146: val_loss improved from 1.37047 to 1.35915, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 1.4188 - acc: 0.9890 - val_loss: 1.3591 - val_acc: 0.9860\n",
      "Epoch 147/3000\n",
      "\n",
      "Epoch 00147: val_loss improved from 1.35915 to 1.34906, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 1.4106 - acc: 0.9881 - val_loss: 1.3491 - val_acc: 0.9858\n",
      "Epoch 148/3000\n",
      "\n",
      "Epoch 00148: val_loss improved from 1.34906 to 1.34089, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 1.3984 - acc: 0.9904 - val_loss: 1.3409 - val_acc: 0.9855\n",
      "Epoch 149/3000\n",
      "\n",
      "Epoch 00149: val_loss improved from 1.34089 to 1.33199, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 1.3912 - acc: 0.9903 - val_loss: 1.3320 - val_acc: 0.9861\n",
      "Epoch 150/3000\n",
      "\n",
      "Epoch 00150: val_loss improved from 1.33199 to 1.32211, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 1.3798 - acc: 0.9904 - val_loss: 1.3221 - val_acc: 0.9860\n",
      "Epoch 151/3000\n",
      "\n",
      "Epoch 00151: val_loss improved from 1.32211 to 1.31200, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 1.3690 - acc: 0.9906 - val_loss: 1.3120 - val_acc: 0.9860\n",
      "Epoch 152/3000\n",
      "\n",
      "Epoch 00152: val_loss improved from 1.31200 to 1.30204, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 1.3632 - acc: 0.9908 - val_loss: 1.3020 - val_acc: 0.9863\n",
      "Epoch 153/3000\n",
      "\n",
      "Epoch 00153: val_loss improved from 1.30204 to 1.29035, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 1.3544 - acc: 0.9907 - val_loss: 1.2903 - val_acc: 0.9868\n",
      "Epoch 154/3000\n",
      "\n",
      "Epoch 00154: val_loss improved from 1.29035 to 1.28209, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 1.3420 - acc: 0.9914 - val_loss: 1.2821 - val_acc: 0.9868\n",
      "Epoch 155/3000\n",
      "\n",
      "Epoch 00155: val_loss improved from 1.28209 to 1.27444, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 1.3336 - acc: 0.9914 - val_loss: 1.2744 - val_acc: 0.9867\n",
      "Epoch 156/3000\n",
      "\n",
      "Epoch 00156: val_loss improved from 1.27444 to 1.26437, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 1.3249 - acc: 0.9917 - val_loss: 1.2644 - val_acc: 0.9871\n",
      "Epoch 157/3000\n",
      "\n",
      "Epoch 00157: val_loss improved from 1.26437 to 1.25496, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 1.3146 - acc: 0.9926 - val_loss: 1.2550 - val_acc: 0.9869\n",
      "Epoch 158/3000\n",
      "\n",
      "Epoch 00158: val_loss improved from 1.25496 to 1.24505, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 1.3081 - acc: 0.9921 - val_loss: 1.2451 - val_acc: 0.9869\n",
      "Epoch 159/3000\n",
      "\n",
      "Epoch 00159: val_loss improved from 1.24505 to 1.23408, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 1.2977 - acc: 0.9932 - val_loss: 1.2341 - val_acc: 0.9871\n",
      "Epoch 160/3000\n",
      "\n",
      "Epoch 00160: val_loss improved from 1.23408 to 1.22442, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 1.2885 - acc: 0.9930 - val_loss: 1.2244 - val_acc: 0.9866\n",
      "Epoch 161/3000\n",
      "\n",
      "Epoch 00161: val_loss improved from 1.22442 to 1.21445, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 1.2807 - acc: 0.9927 - val_loss: 1.2144 - val_acc: 0.9869\n",
      "Epoch 162/3000\n",
      "\n",
      "Epoch 00162: val_loss improved from 1.21445 to 1.20707, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 1.2697 - acc: 0.9933 - val_loss: 1.2071 - val_acc: 0.9872\n",
      "Epoch 163/3000\n",
      "\n",
      "Epoch 00163: val_loss improved from 1.20707 to 1.19751, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 1.2594 - acc: 0.9937 - val_loss: 1.1975 - val_acc: 0.9871\n",
      "Epoch 164/3000\n",
      "\n",
      "Epoch 00164: val_loss improved from 1.19751 to 1.18644, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 1.2516 - acc: 0.9930 - val_loss: 1.1864 - val_acc: 0.9872\n",
      "Epoch 165/3000\n",
      "\n",
      "Epoch 00165: val_loss improved from 1.18644 to 1.17629, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 1.2434 - acc: 0.9926 - val_loss: 1.1763 - val_acc: 0.9873\n",
      "Epoch 166/3000\n",
      "\n",
      "Epoch 00166: val_loss improved from 1.17629 to 1.16655, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 1.2329 - acc: 0.9938 - val_loss: 1.1666 - val_acc: 0.9871\n",
      "Epoch 167/3000\n",
      "\n",
      "Epoch 00167: val_loss improved from 1.16655 to 1.15930, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 1.2220 - acc: 0.9941 - val_loss: 1.1593 - val_acc: 0.9872\n",
      "Epoch 168/3000\n",
      "\n",
      "Epoch 00168: val_loss improved from 1.15930 to 1.15009, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 1.2145 - acc: 0.9945 - val_loss: 1.1501 - val_acc: 0.9875\n",
      "Epoch 169/3000\n",
      "\n",
      "Epoch 00169: val_loss improved from 1.15009 to 1.13972, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 1.2093 - acc: 0.9940 - val_loss: 1.1397 - val_acc: 0.9875\n",
      "Epoch 170/3000\n",
      "\n",
      "Epoch 00170: val_loss improved from 1.13972 to 1.13002, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 1.1985 - acc: 0.9940 - val_loss: 1.1300 - val_acc: 0.9875\n",
      "Epoch 171/3000\n",
      "\n",
      "Epoch 00171: val_loss improved from 1.13002 to 1.12097, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 1.1863 - acc: 0.9944 - val_loss: 1.1210 - val_acc: 0.9875\n",
      "Epoch 172/3000\n",
      "\n",
      "Epoch 00172: val_loss improved from 1.12097 to 1.11151, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 1.1813 - acc: 0.9943 - val_loss: 1.1115 - val_acc: 0.9871\n",
      "Epoch 173/3000\n",
      "\n",
      "Epoch 00173: val_loss improved from 1.11151 to 1.10338, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 1.1687 - acc: 0.9953 - val_loss: 1.1034 - val_acc: 0.9870\n",
      "Epoch 174/3000\n",
      "\n",
      "Epoch 00174: val_loss improved from 1.10338 to 1.09250, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 1.1603 - acc: 0.9951 - val_loss: 1.0925 - val_acc: 0.9872\n",
      "Epoch 175/3000\n",
      "\n",
      "Epoch 00175: val_loss improved from 1.09250 to 1.08365, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 1.1531 - acc: 0.9946 - val_loss: 1.0836 - val_acc: 0.9874\n",
      "Epoch 176/3000\n",
      "\n",
      "Epoch 00176: val_loss improved from 1.08365 to 1.07492, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 1.1427 - acc: 0.9956 - val_loss: 1.0749 - val_acc: 0.9871\n",
      "Epoch 177/3000\n",
      "\n",
      "Epoch 00177: val_loss improved from 1.07492 to 1.06484, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 1.1346 - acc: 0.9949 - val_loss: 1.0648 - val_acc: 0.9875\n",
      "Epoch 178/3000\n",
      "\n",
      "Epoch 00178: val_loss improved from 1.06484 to 1.05567, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 1.1222 - acc: 0.9947 - val_loss: 1.0557 - val_acc: 0.9875\n",
      "Epoch 179/3000\n",
      "\n",
      "Epoch 00179: val_loss improved from 1.05567 to 1.04613, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 1.1165 - acc: 0.9952 - val_loss: 1.0461 - val_acc: 0.9871\n",
      "Epoch 180/3000\n",
      "\n",
      "Epoch 00180: val_loss improved from 1.04613 to 1.03763, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 1.1071 - acc: 0.9946 - val_loss: 1.0376 - val_acc: 0.9871\n",
      "Epoch 181/3000\n",
      "\n",
      "Epoch 00181: val_loss improved from 1.03763 to 1.02779, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 1.0968 - acc: 0.9958 - val_loss: 1.0278 - val_acc: 0.9870\n",
      "Epoch 182/3000\n",
      "\n",
      "Epoch 00182: val_loss improved from 1.02779 to 1.01935, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 1.0873 - acc: 0.9955 - val_loss: 1.0194 - val_acc: 0.9875\n",
      "Epoch 183/3000\n",
      "\n",
      "Epoch 00183: val_loss improved from 1.01935 to 1.01050, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 1.0781 - acc: 0.9962 - val_loss: 1.0105 - val_acc: 0.9871\n",
      "Epoch 184/3000\n",
      "\n",
      "Epoch 00184: val_loss improved from 1.01050 to 1.00056, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 1.0715 - acc: 0.9956 - val_loss: 1.0006 - val_acc: 0.9875\n",
      "Epoch 185/3000\n",
      "\n",
      "Epoch 00185: val_loss improved from 1.00056 to 0.99169, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 1.0639 - acc: 0.9961 - val_loss: 0.9917 - val_acc: 0.9869\n",
      "Epoch 186/3000\n",
      "\n",
      "Epoch 00186: val_loss improved from 0.99169 to 0.98302, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 1.0520 - acc: 0.9964 - val_loss: 0.9830 - val_acc: 0.9875\n",
      "Epoch 187/3000\n",
      "\n",
      "Epoch 00187: val_loss improved from 0.98302 to 0.97472, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 1.0454 - acc: 0.9965 - val_loss: 0.9747 - val_acc: 0.9879\n",
      "Epoch 188/3000\n",
      "\n",
      "Epoch 00188: val_loss improved from 0.97472 to 0.96313, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 1.0336 - acc: 0.9961 - val_loss: 0.9631 - val_acc: 0.9874\n",
      "Epoch 189/3000\n",
      "\n",
      "Epoch 00189: val_loss improved from 0.96313 to 0.95431, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 1.0252 - acc: 0.9964 - val_loss: 0.9543 - val_acc: 0.9875\n",
      "Epoch 190/3000\n",
      "\n",
      "Epoch 00190: val_loss improved from 0.95431 to 0.94722, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 1.0210 - acc: 0.9959 - val_loss: 0.9472 - val_acc: 0.9877\n",
      "Epoch 191/3000\n",
      "\n",
      "Epoch 00191: val_loss improved from 0.94722 to 0.93903, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 1.0093 - acc: 0.9970 - val_loss: 0.9390 - val_acc: 0.9875\n",
      "Epoch 192/3000\n",
      "\n",
      "Epoch 00192: val_loss improved from 0.93903 to 0.92986, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 1.0008 - acc: 0.9970 - val_loss: 0.9299 - val_acc: 0.9877\n",
      "Epoch 193/3000\n",
      "\n",
      "Epoch 00193: val_loss improved from 0.92986 to 0.92007, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.9936 - acc: 0.9967 - val_loss: 0.9201 - val_acc: 0.9875\n",
      "Epoch 194/3000\n",
      "\n",
      "Epoch 00194: val_loss improved from 0.92007 to 0.91132, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.9846 - acc: 0.9967 - val_loss: 0.9113 - val_acc: 0.9873\n",
      "Epoch 195/3000\n",
      "\n",
      "Epoch 00195: val_loss improved from 0.91132 to 0.90439, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.9763 - acc: 0.9971 - val_loss: 0.9044 - val_acc: 0.9878\n",
      "Epoch 196/3000\n",
      "\n",
      "Epoch 00196: val_loss improved from 0.90439 to 0.89549, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.9677 - acc: 0.9971 - val_loss: 0.8955 - val_acc: 0.9876\n",
      "Epoch 197/3000\n",
      "\n",
      "Epoch 00197: val_loss improved from 0.89549 to 0.88469, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.9621 - acc: 0.9966 - val_loss: 0.8847 - val_acc: 0.9875\n",
      "Epoch 198/3000\n",
      "\n",
      "Epoch 00198: val_loss improved from 0.88469 to 0.87651, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.9526 - acc: 0.9969 - val_loss: 0.8765 - val_acc: 0.9877\n",
      "Epoch 199/3000\n",
      "\n",
      "Epoch 00199: val_loss improved from 0.87651 to 0.86868, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.9435 - acc: 0.9969 - val_loss: 0.8687 - val_acc: 0.9879\n",
      "Epoch 200/3000\n",
      "\n",
      "Epoch 00200: val_loss improved from 0.86868 to 0.86109, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.9362 - acc: 0.9970 - val_loss: 0.8611 - val_acc: 0.9875\n",
      "Epoch 201/3000\n",
      "\n",
      "Epoch 00201: val_loss improved from 0.86109 to 0.85267, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.9269 - acc: 0.9972 - val_loss: 0.8527 - val_acc: 0.9878\n",
      "Epoch 202/3000\n",
      "\n",
      "Epoch 00202: val_loss improved from 0.85267 to 0.84529, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.9165 - acc: 0.9977 - val_loss: 0.8453 - val_acc: 0.9883\n",
      "Epoch 203/3000\n",
      "\n",
      "Epoch 00203: val_loss improved from 0.84529 to 0.83742, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.9099 - acc: 0.9971 - val_loss: 0.8374 - val_acc: 0.9875\n",
      "Epoch 204/3000\n",
      "\n",
      "Epoch 00204: val_loss improved from 0.83742 to 0.82732, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.9033 - acc: 0.9972 - val_loss: 0.8273 - val_acc: 0.9881\n",
      "Epoch 205/3000\n",
      "\n",
      "Epoch 00205: val_loss improved from 0.82732 to 0.81965, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.8970 - acc: 0.9973 - val_loss: 0.8197 - val_acc: 0.9877\n",
      "Epoch 206/3000\n",
      "\n",
      "Epoch 00206: val_loss improved from 0.81965 to 0.81256, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.8867 - acc: 0.9978 - val_loss: 0.8126 - val_acc: 0.9876\n",
      "Epoch 207/3000\n",
      "\n",
      "Epoch 00207: val_loss improved from 0.81256 to 0.80501, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.8795 - acc: 0.9977 - val_loss: 0.8050 - val_acc: 0.9876\n",
      "Epoch 208/3000\n",
      "\n",
      "Epoch 00208: val_loss improved from 0.80501 to 0.79559, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.8716 - acc: 0.9974 - val_loss: 0.7956 - val_acc: 0.9876\n",
      "Epoch 209/3000\n",
      "\n",
      "Epoch 00209: val_loss improved from 0.79559 to 0.78831, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.8623 - acc: 0.9976 - val_loss: 0.7883 - val_acc: 0.9879\n",
      "Epoch 210/3000\n",
      "\n",
      "Epoch 00210: val_loss improved from 0.78831 to 0.78025, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.8569 - acc: 0.9974 - val_loss: 0.7803 - val_acc: 0.9882\n",
      "Epoch 211/3000\n",
      "\n",
      "Epoch 00211: val_loss improved from 0.78025 to 0.77296, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.8506 - acc: 0.9978 - val_loss: 0.7730 - val_acc: 0.9881\n",
      "Epoch 212/3000\n",
      "\n",
      "Epoch 00212: val_loss improved from 0.77296 to 0.76375, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.8425 - acc: 0.9977 - val_loss: 0.7637 - val_acc: 0.9875\n",
      "Epoch 213/3000\n",
      "\n",
      "Epoch 00213: val_loss improved from 0.76375 to 0.75544, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.8340 - acc: 0.9974 - val_loss: 0.7554 - val_acc: 0.9879\n",
      "Epoch 214/3000\n",
      "\n",
      "Epoch 00214: val_loss improved from 0.75544 to 0.74824, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.8275 - acc: 0.9979 - val_loss: 0.7482 - val_acc: 0.9878\n",
      "Epoch 215/3000\n",
      "\n",
      "Epoch 00215: val_loss improved from 0.74824 to 0.74157, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.8181 - acc: 0.9980 - val_loss: 0.7416 - val_acc: 0.9875\n",
      "Epoch 216/3000\n",
      "\n",
      "Epoch 00216: val_loss improved from 0.74157 to 0.73345, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.8117 - acc: 0.9981 - val_loss: 0.7334 - val_acc: 0.9879\n",
      "Epoch 217/3000\n",
      "\n",
      "Epoch 00217: val_loss improved from 0.73345 to 0.72735, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.8032 - acc: 0.9983 - val_loss: 0.7274 - val_acc: 0.9881\n",
      "Epoch 218/3000\n",
      "\n",
      "Epoch 00218: val_loss improved from 0.72735 to 0.71910, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.7963 - acc: 0.9981 - val_loss: 0.7191 - val_acc: 0.9879\n",
      "Epoch 219/3000\n",
      "\n",
      "Epoch 00219: val_loss improved from 0.71910 to 0.71190, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.7875 - acc: 0.9979 - val_loss: 0.7119 - val_acc: 0.9880\n",
      "Epoch 220/3000\n",
      "\n",
      "Epoch 00220: val_loss improved from 0.71190 to 0.70421, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.7828 - acc: 0.9981 - val_loss: 0.7042 - val_acc: 0.9880\n",
      "Epoch 221/3000\n",
      "\n",
      "Epoch 00221: val_loss improved from 0.70421 to 0.69592, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.7754 - acc: 0.9979 - val_loss: 0.6959 - val_acc: 0.9879\n",
      "Epoch 222/3000\n",
      "\n",
      "Epoch 00222: val_loss improved from 0.69592 to 0.68942, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.7678 - acc: 0.9983 - val_loss: 0.6894 - val_acc: 0.9879\n",
      "Epoch 223/3000\n",
      "\n",
      "Epoch 00223: val_loss improved from 0.68942 to 0.68302, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.7595 - acc: 0.9979 - val_loss: 0.6830 - val_acc: 0.9884\n",
      "Epoch 224/3000\n",
      "\n",
      "Epoch 00224: val_loss improved from 0.68302 to 0.67608, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.7529 - acc: 0.9983 - val_loss: 0.6761 - val_acc: 0.9883\n",
      "Epoch 225/3000\n",
      "\n",
      "Epoch 00225: val_loss improved from 0.67608 to 0.66877, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.7469 - acc: 0.9975 - val_loss: 0.6688 - val_acc: 0.9884\n",
      "Epoch 226/3000\n",
      "\n",
      "Epoch 00226: val_loss improved from 0.66877 to 0.66084, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.7388 - acc: 0.9980 - val_loss: 0.6608 - val_acc: 0.9887\n",
      "Epoch 227/3000\n",
      "\n",
      "Epoch 00227: val_loss improved from 0.66084 to 0.65456, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.7314 - acc: 0.9986 - val_loss: 0.6546 - val_acc: 0.9885\n",
      "Epoch 228/3000\n",
      "\n",
      "Epoch 00228: val_loss improved from 0.65456 to 0.64769, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.7262 - acc: 0.9982 - val_loss: 0.6477 - val_acc: 0.9884\n",
      "Epoch 229/3000\n",
      "\n",
      "Epoch 00229: val_loss improved from 0.64769 to 0.64049, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.7183 - acc: 0.9983 - val_loss: 0.6405 - val_acc: 0.9884\n",
      "Epoch 230/3000\n",
      "\n",
      "Epoch 00230: val_loss improved from 0.64049 to 0.63488, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.7108 - acc: 0.9986 - val_loss: 0.6349 - val_acc: 0.9885\n",
      "Epoch 231/3000\n",
      "\n",
      "Epoch 00231: val_loss improved from 0.63488 to 0.62767, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.7051 - acc: 0.9983 - val_loss: 0.6277 - val_acc: 0.9882\n",
      "Epoch 232/3000\n",
      "\n",
      "Epoch 00232: val_loss improved from 0.62767 to 0.61988, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.7018 - acc: 0.9987 - val_loss: 0.6199 - val_acc: 0.9885\n",
      "Epoch 233/3000\n",
      "\n",
      "Epoch 00233: val_loss improved from 0.61988 to 0.61433, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.6895 - acc: 0.9984 - val_loss: 0.6143 - val_acc: 0.9883\n",
      "Epoch 234/3000\n",
      "\n",
      "Epoch 00234: val_loss improved from 0.61433 to 0.60905, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.6863 - acc: 0.9986 - val_loss: 0.6091 - val_acc: 0.9882\n",
      "Epoch 235/3000\n",
      "\n",
      "Epoch 00235: val_loss improved from 0.60905 to 0.60112, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.6805 - acc: 0.9984 - val_loss: 0.6011 - val_acc: 0.9880\n",
      "Epoch 236/3000\n",
      "\n",
      "Epoch 00236: val_loss improved from 0.60112 to 0.59500, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.6758 - acc: 0.9984 - val_loss: 0.5950 - val_acc: 0.9882\n",
      "Epoch 237/3000\n",
      "\n",
      "Epoch 00237: val_loss improved from 0.59500 to 0.58799, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.6674 - acc: 0.9983 - val_loss: 0.5880 - val_acc: 0.9883\n",
      "Epoch 238/3000\n",
      "\n",
      "Epoch 00238: val_loss improved from 0.58799 to 0.58099, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.6622 - acc: 0.9984 - val_loss: 0.5810 - val_acc: 0.9884\n",
      "Epoch 239/3000\n",
      "\n",
      "Epoch 00239: val_loss improved from 0.58099 to 0.57410, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.6549 - acc: 0.9984 - val_loss: 0.5741 - val_acc: 0.9886\n",
      "Epoch 240/3000\n",
      "\n",
      "Epoch 00240: val_loss improved from 0.57410 to 0.56869, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.6493 - acc: 0.9988 - val_loss: 0.5687 - val_acc: 0.9882\n",
      "Epoch 241/3000\n",
      "\n",
      "Epoch 00241: val_loss improved from 0.56869 to 0.56177, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.6398 - acc: 0.9983 - val_loss: 0.5618 - val_acc: 0.9883\n",
      "Epoch 242/3000\n",
      "\n",
      "Epoch 00242: val_loss improved from 0.56177 to 0.55587, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.6387 - acc: 0.9985 - val_loss: 0.5559 - val_acc: 0.9883\n",
      "Epoch 243/3000\n",
      "\n",
      "Epoch 00243: val_loss improved from 0.55587 to 0.55126, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.6300 - acc: 0.9988 - val_loss: 0.5513 - val_acc: 0.9879\n",
      "Epoch 244/3000\n",
      "\n",
      "Epoch 00244: val_loss improved from 0.55126 to 0.54556, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.6246 - acc: 0.9984 - val_loss: 0.5456 - val_acc: 0.9882\n",
      "Epoch 245/3000\n",
      "\n",
      "Epoch 00245: val_loss improved from 0.54556 to 0.53854, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.6192 - acc: 0.9988 - val_loss: 0.5385 - val_acc: 0.9884\n",
      "Epoch 246/3000\n",
      "\n",
      "Epoch 00246: val_loss improved from 0.53854 to 0.53357, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.6116 - acc: 0.9991 - val_loss: 0.5336 - val_acc: 0.9883\n",
      "Epoch 247/3000\n",
      "\n",
      "Epoch 00247: val_loss improved from 0.53357 to 0.52791, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.6048 - acc: 0.9987 - val_loss: 0.5279 - val_acc: 0.9882\n",
      "Epoch 248/3000\n",
      "\n",
      "Epoch 00248: val_loss improved from 0.52791 to 0.52173, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.6012 - acc: 0.9985 - val_loss: 0.5217 - val_acc: 0.9884\n",
      "Epoch 249/3000\n",
      "\n",
      "Epoch 00249: val_loss improved from 0.52173 to 0.51620, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.5966 - acc: 0.9986 - val_loss: 0.5162 - val_acc: 0.9885\n",
      "Epoch 250/3000\n",
      "\n",
      "Epoch 00250: val_loss improved from 0.51620 to 0.51072, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.5920 - acc: 0.9989 - val_loss: 0.5107 - val_acc: 0.9883\n",
      "Epoch 251/3000\n",
      "\n",
      "Epoch 00251: val_loss improved from 0.51072 to 0.50537, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.5839 - acc: 0.9988 - val_loss: 0.5054 - val_acc: 0.9883\n",
      "Epoch 252/3000\n",
      "\n",
      "Epoch 00252: val_loss improved from 0.50537 to 0.50002, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.5805 - acc: 0.9989 - val_loss: 0.5000 - val_acc: 0.9887\n",
      "Epoch 253/3000\n",
      "\n",
      "Epoch 00253: val_loss improved from 0.50002 to 0.49372, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.5770 - acc: 0.9991 - val_loss: 0.4937 - val_acc: 0.9890\n",
      "Epoch 254/3000\n",
      "\n",
      "Epoch 00254: val_loss improved from 0.49372 to 0.48843, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.5676 - acc: 0.9984 - val_loss: 0.4884 - val_acc: 0.9886\n",
      "Epoch 255/3000\n",
      "\n",
      "Epoch 00255: val_loss improved from 0.48843 to 0.48268, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.5605 - acc: 0.9985 - val_loss: 0.4827 - val_acc: 0.9884\n",
      "Epoch 256/3000\n",
      "\n",
      "Epoch 00256: val_loss improved from 0.48268 to 0.47938, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.5564 - acc: 0.9986 - val_loss: 0.4794 - val_acc: 0.9887\n",
      "Epoch 257/3000\n",
      "\n",
      "Epoch 00257: val_loss improved from 0.47938 to 0.47241, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.5529 - acc: 0.9990 - val_loss: 0.4724 - val_acc: 0.9886\n",
      "Epoch 258/3000\n",
      "\n",
      "Epoch 00258: val_loss improved from 0.47241 to 0.46655, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.5456 - acc: 0.9989 - val_loss: 0.4665 - val_acc: 0.9886\n",
      "Epoch 259/3000\n",
      "\n",
      "Epoch 00259: val_loss improved from 0.46655 to 0.46244, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.5424 - acc: 0.9983 - val_loss: 0.4624 - val_acc: 0.9887\n",
      "Epoch 260/3000\n",
      "\n",
      "Epoch 00260: val_loss improved from 0.46244 to 0.45752, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.5377 - acc: 0.9987 - val_loss: 0.4575 - val_acc: 0.9886\n",
      "Epoch 261/3000\n",
      "\n",
      "Epoch 00261: val_loss improved from 0.45752 to 0.45269, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.5329 - acc: 0.9991 - val_loss: 0.4527 - val_acc: 0.9886\n",
      "Epoch 262/3000\n",
      "\n",
      "Epoch 00262: val_loss improved from 0.45269 to 0.44747, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.5269 - acc: 0.9989 - val_loss: 0.4475 - val_acc: 0.9884\n",
      "Epoch 263/3000\n",
      "\n",
      "Epoch 00263: val_loss improved from 0.44747 to 0.44376, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.5235 - acc: 0.9987 - val_loss: 0.4438 - val_acc: 0.9882\n",
      "Epoch 264/3000\n",
      "\n",
      "Epoch 00264: val_loss improved from 0.44376 to 0.43937, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.5178 - acc: 0.9989 - val_loss: 0.4394 - val_acc: 0.9884\n",
      "Epoch 265/3000\n",
      "\n",
      "Epoch 00265: val_loss improved from 0.43937 to 0.43340, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.5119 - acc: 0.9988 - val_loss: 0.4334 - val_acc: 0.9886\n",
      "Epoch 266/3000\n",
      "\n",
      "Epoch 00266: val_loss improved from 0.43340 to 0.42947, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.5084 - acc: 0.9989 - val_loss: 0.4295 - val_acc: 0.9883\n",
      "Epoch 267/3000\n",
      "\n",
      "Epoch 00267: val_loss improved from 0.42947 to 0.42501, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.5030 - acc: 0.9989 - val_loss: 0.4250 - val_acc: 0.9883\n",
      "Epoch 268/3000\n",
      "\n",
      "Epoch 00268: val_loss improved from 0.42501 to 0.41978, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.4984 - acc: 0.9990 - val_loss: 0.4198 - val_acc: 0.9883\n",
      "Epoch 269/3000\n",
      "\n",
      "Epoch 00269: val_loss improved from 0.41978 to 0.41366, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.4942 - acc: 0.9990 - val_loss: 0.4137 - val_acc: 0.9882\n",
      "Epoch 270/3000\n",
      "\n",
      "Epoch 00270: val_loss improved from 0.41366 to 0.40911, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.4877 - acc: 0.9993 - val_loss: 0.4091 - val_acc: 0.9883\n",
      "Epoch 271/3000\n",
      "\n",
      "Epoch 00271: val_loss improved from 0.40911 to 0.40511, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.4830 - acc: 0.9989 - val_loss: 0.4051 - val_acc: 0.9883\n",
      "Epoch 272/3000\n",
      "\n",
      "Epoch 00272: val_loss improved from 0.40511 to 0.40155, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.4763 - acc: 0.9987 - val_loss: 0.4016 - val_acc: 0.9882\n",
      "Epoch 273/3000\n",
      "\n",
      "Epoch 00273: val_loss improved from 0.40155 to 0.39719, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.4708 - acc: 0.9991 - val_loss: 0.3972 - val_acc: 0.9883\n",
      "Epoch 274/3000\n",
      "\n",
      "Epoch 00274: val_loss improved from 0.39719 to 0.39288, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.4694 - acc: 0.9988 - val_loss: 0.3929 - val_acc: 0.9885\n",
      "Epoch 275/3000\n",
      "\n",
      "Epoch 00275: val_loss improved from 0.39288 to 0.38898, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.4645 - acc: 0.9991 - val_loss: 0.3890 - val_acc: 0.9883\n",
      "Epoch 276/3000\n",
      "\n",
      "Epoch 00276: val_loss improved from 0.38898 to 0.38469, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.4602 - acc: 0.9989 - val_loss: 0.3847 - val_acc: 0.9883\n",
      "Epoch 277/3000\n",
      "\n",
      "Epoch 00277: val_loss improved from 0.38469 to 0.37928, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.4592 - acc: 0.9991 - val_loss: 0.3793 - val_acc: 0.9886\n",
      "Epoch 278/3000\n",
      "\n",
      "Epoch 00278: val_loss improved from 0.37928 to 0.37533, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.4500 - acc: 0.9990 - val_loss: 0.3753 - val_acc: 0.9882\n",
      "Epoch 279/3000\n",
      "\n",
      "Epoch 00279: val_loss improved from 0.37533 to 0.37180, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.4493 - acc: 0.9990 - val_loss: 0.3718 - val_acc: 0.9885\n",
      "Epoch 280/3000\n",
      "\n",
      "Epoch 00280: val_loss improved from 0.37180 to 0.36871, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.4425 - acc: 0.9990 - val_loss: 0.3687 - val_acc: 0.9883\n",
      "Epoch 281/3000\n",
      "\n",
      "Epoch 00281: val_loss improved from 0.36871 to 0.36333, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.4400 - acc: 0.9989 - val_loss: 0.3633 - val_acc: 0.9887\n",
      "Epoch 282/3000\n",
      "\n",
      "Epoch 00282: val_loss improved from 0.36333 to 0.36108, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.4354 - acc: 0.9991 - val_loss: 0.3611 - val_acc: 0.9887\n",
      "Epoch 283/3000\n",
      "\n",
      "Epoch 00283: val_loss improved from 0.36108 to 0.35700, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.4321 - acc: 0.9989 - val_loss: 0.3570 - val_acc: 0.9886\n",
      "Epoch 284/3000\n",
      "\n",
      "Epoch 00284: val_loss improved from 0.35700 to 0.35304, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.4297 - acc: 0.9990 - val_loss: 0.3530 - val_acc: 0.9884\n",
      "Epoch 285/3000\n",
      "\n",
      "Epoch 00285: val_loss improved from 0.35304 to 0.34870, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.4230 - acc: 0.9992 - val_loss: 0.3487 - val_acc: 0.9883\n",
      "Epoch 286/3000\n",
      "\n",
      "Epoch 00286: val_loss improved from 0.34870 to 0.34500, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.4222 - acc: 0.9994 - val_loss: 0.3450 - val_acc: 0.9879\n",
      "Epoch 287/3000\n",
      "\n",
      "Epoch 00287: val_loss improved from 0.34500 to 0.34087, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.4170 - acc: 0.9989 - val_loss: 0.3409 - val_acc: 0.9885\n",
      "Epoch 288/3000\n",
      "\n",
      "Epoch 00288: val_loss improved from 0.34087 to 0.33672, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.4123 - acc: 0.9990 - val_loss: 0.3367 - val_acc: 0.9889\n",
      "Epoch 289/3000\n",
      "\n",
      "Epoch 00289: val_loss improved from 0.33672 to 0.33318, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.4098 - acc: 0.9990 - val_loss: 0.3332 - val_acc: 0.9887\n",
      "Epoch 290/3000\n",
      "\n",
      "Epoch 00290: val_loss improved from 0.33318 to 0.32967, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.4029 - acc: 0.9991 - val_loss: 0.3297 - val_acc: 0.9890\n",
      "Epoch 291/3000\n",
      "\n",
      "Epoch 00291: val_loss improved from 0.32967 to 0.32708, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.4015 - acc: 0.9993 - val_loss: 0.3271 - val_acc: 0.9889\n",
      "Epoch 292/3000\n",
      "\n",
      "Epoch 00292: val_loss improved from 0.32708 to 0.32268, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.3970 - acc: 0.9993 - val_loss: 0.3227 - val_acc: 0.9889\n",
      "Epoch 293/3000\n",
      "\n",
      "Epoch 00293: val_loss improved from 0.32268 to 0.31885, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.3954 - acc: 0.9989 - val_loss: 0.3189 - val_acc: 0.9891\n",
      "Epoch 294/3000\n",
      "\n",
      "Epoch 00294: val_loss improved from 0.31885 to 0.31546, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.3892 - acc: 0.9990 - val_loss: 0.3155 - val_acc: 0.9889\n",
      "Epoch 295/3000\n",
      "\n",
      "Epoch 00295: val_loss improved from 0.31546 to 0.31306, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.3859 - acc: 0.9991 - val_loss: 0.3131 - val_acc: 0.9889\n",
      "Epoch 296/3000\n",
      "\n",
      "Epoch 00296: val_loss improved from 0.31306 to 0.31049, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.3820 - acc: 0.9991 - val_loss: 0.3105 - val_acc: 0.9887\n",
      "Epoch 297/3000\n",
      "\n",
      "Epoch 00297: val_loss improved from 0.31049 to 0.30646, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.3816 - acc: 0.9993 - val_loss: 0.3065 - val_acc: 0.9888\n",
      "Epoch 298/3000\n",
      "\n",
      "Epoch 00298: val_loss improved from 0.30646 to 0.30265, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.3746 - acc: 0.9990 - val_loss: 0.3027 - val_acc: 0.9888\n",
      "Epoch 299/3000\n",
      "\n",
      "Epoch 00299: val_loss improved from 0.30265 to 0.30002, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.3727 - acc: 0.9990 - val_loss: 0.3000 - val_acc: 0.9890\n",
      "Epoch 300/3000\n",
      "\n",
      "Epoch 00300: val_loss improved from 0.30002 to 0.29694, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.3693 - acc: 0.9992 - val_loss: 0.2969 - val_acc: 0.9890\n",
      "Epoch 301/3000\n",
      "\n",
      "Epoch 00301: val_loss improved from 0.29694 to 0.29349, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.3653 - acc: 0.9991 - val_loss: 0.2935 - val_acc: 0.9890\n",
      "Epoch 302/3000\n",
      "\n",
      "Epoch 00302: val_loss improved from 0.29349 to 0.29055, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.3619 - acc: 0.9994 - val_loss: 0.2905 - val_acc: 0.9890\n",
      "Epoch 303/3000\n",
      "\n",
      "Epoch 00303: val_loss improved from 0.29055 to 0.28772, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.3592 - acc: 0.9992 - val_loss: 0.2877 - val_acc: 0.9889\n",
      "Epoch 304/3000\n",
      "\n",
      "Epoch 00304: val_loss improved from 0.28772 to 0.28586, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.3546 - acc: 0.9993 - val_loss: 0.2859 - val_acc: 0.9888\n",
      "Epoch 305/3000\n",
      "\n",
      "Epoch 00305: val_loss improved from 0.28586 to 0.28222, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.3513 - acc: 0.9991 - val_loss: 0.2822 - val_acc: 0.9886\n",
      "Epoch 306/3000\n",
      "\n",
      "Epoch 00306: val_loss improved from 0.28222 to 0.27890, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.3495 - acc: 0.9992 - val_loss: 0.2789 - val_acc: 0.9888\n",
      "Epoch 307/3000\n",
      "\n",
      "Epoch 00307: val_loss improved from 0.27890 to 0.27690, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.3470 - acc: 0.9992 - val_loss: 0.2769 - val_acc: 0.9884\n",
      "Epoch 308/3000\n",
      "\n",
      "Epoch 00308: val_loss improved from 0.27690 to 0.27369, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.3419 - acc: 0.9993 - val_loss: 0.2737 - val_acc: 0.9889\n",
      "Epoch 309/3000\n",
      "\n",
      "Epoch 00309: val_loss improved from 0.27369 to 0.27056, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.3388 - acc: 0.9994 - val_loss: 0.2706 - val_acc: 0.9887\n",
      "Epoch 310/3000\n",
      "\n",
      "Epoch 00310: val_loss improved from 0.27056 to 0.26866, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.3367 - acc: 0.9994 - val_loss: 0.2687 - val_acc: 0.9889\n",
      "Epoch 311/3000\n",
      "\n",
      "Epoch 00311: val_loss improved from 0.26866 to 0.26615, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.3336 - acc: 0.9997 - val_loss: 0.2662 - val_acc: 0.9888\n",
      "Epoch 312/3000\n",
      "\n",
      "Epoch 00312: val_loss improved from 0.26615 to 0.26142, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.3324 - acc: 0.9993 - val_loss: 0.2614 - val_acc: 0.9887\n",
      "Epoch 313/3000\n",
      "\n",
      "Epoch 00313: val_loss improved from 0.26142 to 0.25892, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.3290 - acc: 0.9994 - val_loss: 0.2589 - val_acc: 0.9889\n",
      "Epoch 314/3000\n",
      "\n",
      "Epoch 00314: val_loss improved from 0.25892 to 0.25696, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.3247 - acc: 0.9994 - val_loss: 0.2570 - val_acc: 0.9889\n",
      "Epoch 315/3000\n",
      "\n",
      "Epoch 00315: val_loss improved from 0.25696 to 0.25441, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.3240 - acc: 0.9992 - val_loss: 0.2544 - val_acc: 0.9889\n",
      "Epoch 316/3000\n",
      "\n",
      "Epoch 00316: val_loss improved from 0.25441 to 0.25246, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.3195 - acc: 0.9996 - val_loss: 0.2525 - val_acc: 0.9888\n",
      "Epoch 317/3000\n",
      "\n",
      "Epoch 00317: val_loss improved from 0.25246 to 0.25037, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.3143 - acc: 0.9993 - val_loss: 0.2504 - val_acc: 0.9886\n",
      "Epoch 318/3000\n",
      "\n",
      "Epoch 00318: val_loss improved from 0.25037 to 0.24799, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.3147 - acc: 0.9993 - val_loss: 0.2480 - val_acc: 0.9887\n",
      "Epoch 319/3000\n",
      "\n",
      "Epoch 00319: val_loss improved from 0.24799 to 0.24579, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.3098 - acc: 0.9993 - val_loss: 0.2458 - val_acc: 0.9885\n",
      "Epoch 320/3000\n",
      "\n",
      "Epoch 00320: val_loss improved from 0.24579 to 0.24127, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.3105 - acc: 0.9994 - val_loss: 0.2413 - val_acc: 0.9890\n",
      "Epoch 321/3000\n",
      "\n",
      "Epoch 00321: val_loss improved from 0.24127 to 0.23881, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.3070 - acc: 0.9994 - val_loss: 0.2388 - val_acc: 0.9886\n",
      "Epoch 322/3000\n",
      "\n",
      "Epoch 00322: val_loss improved from 0.23881 to 0.23675, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.3026 - acc: 0.9995 - val_loss: 0.2367 - val_acc: 0.9886\n",
      "Epoch 323/3000\n",
      "\n",
      "Epoch 00323: val_loss improved from 0.23675 to 0.23479, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.3014 - acc: 0.9992 - val_loss: 0.2348 - val_acc: 0.9887\n",
      "Epoch 324/3000\n",
      "\n",
      "Epoch 00324: val_loss improved from 0.23479 to 0.23334, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.2982 - acc: 0.9993 - val_loss: 0.2333 - val_acc: 0.9889\n",
      "Epoch 325/3000\n",
      "\n",
      "Epoch 00325: val_loss improved from 0.23334 to 0.23006, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.2942 - acc: 0.9996 - val_loss: 0.2301 - val_acc: 0.9887\n",
      "Epoch 326/3000\n",
      "\n",
      "Epoch 00326: val_loss improved from 0.23006 to 0.22770, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.2948 - acc: 0.9993 - val_loss: 0.2277 - val_acc: 0.9890\n",
      "Epoch 327/3000\n",
      "\n",
      "Epoch 00327: val_loss improved from 0.22770 to 0.22520, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.2887 - acc: 0.9994 - val_loss: 0.2252 - val_acc: 0.9887\n",
      "Epoch 328/3000\n",
      "\n",
      "Epoch 00328: val_loss improved from 0.22520 to 0.22340, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.2873 - acc: 0.9993 - val_loss: 0.2234 - val_acc: 0.9886\n",
      "Epoch 329/3000\n",
      "\n",
      "Epoch 00329: val_loss improved from 0.22340 to 0.22172, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.2843 - acc: 0.9991 - val_loss: 0.2217 - val_acc: 0.9884\n",
      "Epoch 330/3000\n",
      "\n",
      "Epoch 00330: val_loss improved from 0.22172 to 0.21920, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.2829 - acc: 0.9994 - val_loss: 0.2192 - val_acc: 0.9882\n",
      "Epoch 331/3000\n",
      "\n",
      "Epoch 00331: val_loss improved from 0.21920 to 0.21713, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.2809 - acc: 0.9994 - val_loss: 0.2171 - val_acc: 0.9884\n",
      "Epoch 332/3000\n",
      "\n",
      "Epoch 00332: val_loss improved from 0.21713 to 0.21544, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.2777 - acc: 0.9993 - val_loss: 0.2154 - val_acc: 0.9886\n",
      "Epoch 333/3000\n",
      "\n",
      "Epoch 00333: val_loss improved from 0.21544 to 0.21327, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.2751 - acc: 0.9994 - val_loss: 0.2133 - val_acc: 0.9885\n",
      "Epoch 334/3000\n",
      "\n",
      "Epoch 00334: val_loss improved from 0.21327 to 0.21130, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.2753 - acc: 0.9995 - val_loss: 0.2113 - val_acc: 0.9885\n",
      "Epoch 335/3000\n",
      "\n",
      "Epoch 00335: val_loss improved from 0.21130 to 0.20912, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.2716 - acc: 0.9993 - val_loss: 0.2091 - val_acc: 0.9887\n",
      "Epoch 336/3000\n",
      "\n",
      "Epoch 00336: val_loss improved from 0.20912 to 0.20730, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.2669 - acc: 0.9995 - val_loss: 0.2073 - val_acc: 0.9886\n",
      "Epoch 337/3000\n",
      "\n",
      "Epoch 00337: val_loss improved from 0.20730 to 0.20494, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.2656 - acc: 0.9996 - val_loss: 0.2049 - val_acc: 0.9886\n",
      "Epoch 338/3000\n",
      "\n",
      "Epoch 00338: val_loss improved from 0.20494 to 0.20331, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.2643 - acc: 0.9993 - val_loss: 0.2033 - val_acc: 0.9883\n",
      "Epoch 339/3000\n",
      "\n",
      "Epoch 00339: val_loss improved from 0.20331 to 0.20136, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.2617 - acc: 0.9994 - val_loss: 0.2014 - val_acc: 0.9885\n",
      "Epoch 340/3000\n",
      "\n",
      "Epoch 00340: val_loss improved from 0.20136 to 0.19936, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.2595 - acc: 0.9994 - val_loss: 0.1994 - val_acc: 0.9887\n",
      "Epoch 341/3000\n",
      "\n",
      "Epoch 00341: val_loss improved from 0.19936 to 0.19826, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.2574 - acc: 0.9995 - val_loss: 0.1983 - val_acc: 0.9886\n",
      "Epoch 342/3000\n",
      "\n",
      "Epoch 00342: val_loss improved from 0.19826 to 0.19604, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.2550 - acc: 0.9996 - val_loss: 0.1960 - val_acc: 0.9887\n",
      "Epoch 343/3000\n",
      "\n",
      "Epoch 00343: val_loss improved from 0.19604 to 0.19429, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.2537 - acc: 0.9993 - val_loss: 0.1943 - val_acc: 0.9887\n",
      "Epoch 344/3000\n",
      "\n",
      "Epoch 00344: val_loss improved from 0.19429 to 0.19148, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.2499 - acc: 0.9992 - val_loss: 0.1915 - val_acc: 0.9888\n",
      "Epoch 345/3000\n",
      "\n",
      "Epoch 00345: val_loss improved from 0.19148 to 0.19006, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.2482 - acc: 0.9996 - val_loss: 0.1901 - val_acc: 0.9888\n",
      "Epoch 346/3000\n",
      "\n",
      "Epoch 00346: val_loss improved from 0.19006 to 0.18876, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.2444 - acc: 0.9995 - val_loss: 0.1888 - val_acc: 0.9890\n",
      "Epoch 347/3000\n",
      "\n",
      "Epoch 00347: val_loss improved from 0.18876 to 0.18675, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.2453 - acc: 0.9994 - val_loss: 0.1867 - val_acc: 0.9886\n",
      "Epoch 348/3000\n",
      "\n",
      "Epoch 00348: val_loss improved from 0.18675 to 0.18488, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.2437 - acc: 0.9996 - val_loss: 0.1849 - val_acc: 0.9884\n",
      "Epoch 349/3000\n",
      "\n",
      "Epoch 00349: val_loss improved from 0.18488 to 0.18302, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.2405 - acc: 0.9994 - val_loss: 0.1830 - val_acc: 0.9888\n",
      "Epoch 350/3000\n",
      "\n",
      "Epoch 00350: val_loss improved from 0.18302 to 0.18160, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.2364 - acc: 0.9995 - val_loss: 0.1816 - val_acc: 0.9887\n",
      "Epoch 351/3000\n",
      "\n",
      "Epoch 00351: val_loss improved from 0.18160 to 0.17964, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.2359 - acc: 0.9994 - val_loss: 0.1796 - val_acc: 0.9888\n",
      "Epoch 352/3000\n",
      "\n",
      "Epoch 00352: val_loss improved from 0.17964 to 0.17872, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.2328 - acc: 0.9997 - val_loss: 0.1787 - val_acc: 0.9886\n",
      "Epoch 353/3000\n",
      "\n",
      "Epoch 00353: val_loss improved from 0.17872 to 0.17782, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.2331 - acc: 0.9994 - val_loss: 0.1778 - val_acc: 0.9887\n",
      "Epoch 354/3000\n",
      "\n",
      "Epoch 00354: val_loss improved from 0.17782 to 0.17680, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.2294 - acc: 0.9997 - val_loss: 0.1768 - val_acc: 0.9885\n",
      "Epoch 355/3000\n",
      "\n",
      "Epoch 00355: val_loss improved from 0.17680 to 0.17398, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.2278 - acc: 0.9995 - val_loss: 0.1740 - val_acc: 0.9888\n",
      "Epoch 356/3000\n",
      "\n",
      "Epoch 00356: val_loss improved from 0.17398 to 0.17204, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.2265 - acc: 0.9996 - val_loss: 0.1720 - val_acc: 0.9891\n",
      "Epoch 357/3000\n",
      "\n",
      "Epoch 00357: val_loss improved from 0.17204 to 0.17034, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.2258 - acc: 0.9996 - val_loss: 0.1703 - val_acc: 0.9890\n",
      "Epoch 358/3000\n",
      "\n",
      "Epoch 00358: val_loss improved from 0.17034 to 0.16937, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.2226 - acc: 0.9995 - val_loss: 0.1694 - val_acc: 0.9887\n",
      "Epoch 359/3000\n",
      "\n",
      "Epoch 00359: val_loss improved from 0.16937 to 0.16820, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.2209 - acc: 0.9996 - val_loss: 0.1682 - val_acc: 0.9889\n",
      "Epoch 360/3000\n",
      "\n",
      "Epoch 00360: val_loss improved from 0.16820 to 0.16648, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.2185 - acc: 0.9995 - val_loss: 0.1665 - val_acc: 0.9887\n",
      "Epoch 361/3000\n",
      "\n",
      "Epoch 00361: val_loss improved from 0.16648 to 0.16451, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.2166 - acc: 0.9995 - val_loss: 0.1645 - val_acc: 0.9887\n",
      "Epoch 362/3000\n",
      "\n",
      "Epoch 00362: val_loss improved from 0.16451 to 0.16324, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.2146 - acc: 0.9996 - val_loss: 0.1632 - val_acc: 0.9893\n",
      "Epoch 363/3000\n",
      "\n",
      "Epoch 00363: val_loss improved from 0.16324 to 0.16206, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.2129 - acc: 0.9996 - val_loss: 0.1621 - val_acc: 0.9887\n",
      "Epoch 364/3000\n",
      "\n",
      "Epoch 00364: val_loss improved from 0.16206 to 0.16025, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.2113 - acc: 0.9997 - val_loss: 0.1603 - val_acc: 0.9890\n",
      "Epoch 365/3000\n",
      "\n",
      "Epoch 00365: val_loss improved from 0.16025 to 0.15895, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.2097 - acc: 0.9995 - val_loss: 0.1589 - val_acc: 0.9891\n",
      "Epoch 366/3000\n",
      "\n",
      "Epoch 00366: val_loss improved from 0.15895 to 0.15789, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.2066 - acc: 0.9996 - val_loss: 0.1579 - val_acc: 0.9894\n",
      "Epoch 367/3000\n",
      "\n",
      "Epoch 00367: val_loss improved from 0.15789 to 0.15619, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.2065 - acc: 0.9996 - val_loss: 0.1562 - val_acc: 0.9892\n",
      "Epoch 368/3000\n",
      "\n",
      "Epoch 00368: val_loss improved from 0.15619 to 0.15550, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.2056 - acc: 0.9996 - val_loss: 0.1555 - val_acc: 0.9890\n",
      "Epoch 369/3000\n",
      "\n",
      "Epoch 00369: val_loss improved from 0.15550 to 0.15371, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.2032 - acc: 0.9997 - val_loss: 0.1537 - val_acc: 0.9895\n",
      "Epoch 370/3000\n",
      "\n",
      "Epoch 00370: val_loss improved from 0.15371 to 0.15272, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.2033 - acc: 0.9994 - val_loss: 0.1527 - val_acc: 0.9893\n",
      "Epoch 371/3000\n",
      "\n",
      "Epoch 00371: val_loss improved from 0.15272 to 0.15140, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.1989 - acc: 0.9996 - val_loss: 0.1514 - val_acc: 0.9893\n",
      "Epoch 372/3000\n",
      "\n",
      "Epoch 00372: val_loss improved from 0.15140 to 0.15006, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.1966 - acc: 0.9995 - val_loss: 0.1501 - val_acc: 0.9895\n",
      "Epoch 373/3000\n",
      "\n",
      "Epoch 00373: val_loss improved from 0.15006 to 0.14936, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.1957 - acc: 0.9996 - val_loss: 0.1494 - val_acc: 0.9894\n",
      "Epoch 374/3000\n",
      "\n",
      "Epoch 00374: val_loss improved from 0.14936 to 0.14836, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.1951 - acc: 0.9996 - val_loss: 0.1484 - val_acc: 0.9890\n",
      "Epoch 375/3000\n",
      "\n",
      "Epoch 00375: val_loss improved from 0.14836 to 0.14559, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.1939 - acc: 0.9995 - val_loss: 0.1456 - val_acc: 0.9894\n",
      "Epoch 376/3000\n",
      "\n",
      "Epoch 00376: val_loss improved from 0.14559 to 0.14393, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.1923 - acc: 0.9997 - val_loss: 0.1439 - val_acc: 0.9893\n",
      "Epoch 377/3000\n",
      "\n",
      "Epoch 00377: val_loss improved from 0.14393 to 0.14382, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.1901 - acc: 0.9995 - val_loss: 0.1438 - val_acc: 0.9893\n",
      "Epoch 378/3000\n",
      "\n",
      "Epoch 00378: val_loss improved from 0.14382 to 0.14281, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.1895 - acc: 0.9996 - val_loss: 0.1428 - val_acc: 0.9892\n",
      "Epoch 379/3000\n",
      "\n",
      "Epoch 00379: val_loss improved from 0.14281 to 0.14079, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.1871 - acc: 0.9996 - val_loss: 0.1408 - val_acc: 0.9896\n",
      "Epoch 380/3000\n",
      "\n",
      "Epoch 00380: val_loss improved from 0.14079 to 0.14049, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.1868 - acc: 0.9997 - val_loss: 0.1405 - val_acc: 0.9895\n",
      "Epoch 381/3000\n",
      "\n",
      "Epoch 00381: val_loss did not improve from 0.14049\n",
      "29400/29400 - 1s - loss: 0.1851 - acc: 0.9995 - val_loss: 0.1410 - val_acc: 0.9890\n",
      "Epoch 382/3000\n",
      "\n",
      "Epoch 00382: val_loss improved from 0.14049 to 0.13990, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.1832 - acc: 0.9996 - val_loss: 0.1399 - val_acc: 0.9892\n",
      "Epoch 383/3000\n",
      "\n",
      "Epoch 00383: val_loss improved from 0.13990 to 0.13773, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.1810 - acc: 0.9995 - val_loss: 0.1377 - val_acc: 0.9890\n",
      "Epoch 384/3000\n",
      "\n",
      "Epoch 00384: val_loss improved from 0.13773 to 0.13647, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.1798 - acc: 0.9993 - val_loss: 0.1365 - val_acc: 0.9891\n",
      "Epoch 385/3000\n",
      "\n",
      "Epoch 00385: val_loss improved from 0.13647 to 0.13500, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.1782 - acc: 0.9996 - val_loss: 0.1350 - val_acc: 0.9889\n",
      "Epoch 386/3000\n",
      "\n",
      "Epoch 00386: val_loss improved from 0.13500 to 0.13409, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.1750 - acc: 0.9997 - val_loss: 0.1341 - val_acc: 0.9891\n",
      "Epoch 387/3000\n",
      "\n",
      "Epoch 00387: val_loss improved from 0.13409 to 0.13284, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.1769 - acc: 0.9996 - val_loss: 0.1328 - val_acc: 0.9890\n",
      "Epoch 388/3000\n",
      "\n",
      "Epoch 00388: val_loss improved from 0.13284 to 0.13175, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.1748 - acc: 0.9997 - val_loss: 0.1317 - val_acc: 0.9891\n",
      "Epoch 389/3000\n",
      "\n",
      "Epoch 00389: val_loss improved from 0.13175 to 0.13087, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.1737 - acc: 0.9994 - val_loss: 0.1309 - val_acc: 0.9891\n",
      "Epoch 390/3000\n",
      "\n",
      "Epoch 00390: val_loss improved from 0.13087 to 0.13046, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.1717 - acc: 0.9996 - val_loss: 0.1305 - val_acc: 0.9890\n",
      "Epoch 391/3000\n",
      "\n",
      "Epoch 00391: val_loss improved from 0.13046 to 0.12930, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.1700 - acc: 0.9995 - val_loss: 0.1293 - val_acc: 0.9887\n",
      "Epoch 392/3000\n",
      "\n",
      "Epoch 00392: val_loss improved from 0.12930 to 0.12836, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.1700 - acc: 0.9996 - val_loss: 0.1284 - val_acc: 0.9888\n",
      "Epoch 393/3000\n",
      "\n",
      "Epoch 00393: val_loss improved from 0.12836 to 0.12816, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.1682 - acc: 0.9995 - val_loss: 0.1282 - val_acc: 0.9889\n",
      "Epoch 394/3000\n",
      "\n",
      "Epoch 00394: val_loss improved from 0.12816 to 0.12693, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.1678 - acc: 0.9996 - val_loss: 0.1269 - val_acc: 0.9890\n",
      "Epoch 395/3000\n",
      "\n",
      "Epoch 00395: val_loss improved from 0.12693 to 0.12628, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.1673 - acc: 0.9995 - val_loss: 0.1263 - val_acc: 0.9885\n",
      "Epoch 396/3000\n",
      "\n",
      "Epoch 00396: val_loss improved from 0.12628 to 0.12567, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.1636 - acc: 0.9996 - val_loss: 0.1257 - val_acc: 0.9884\n",
      "Epoch 397/3000\n",
      "\n",
      "Epoch 00397: val_loss improved from 0.12567 to 0.12517, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.1624 - acc: 0.9998 - val_loss: 0.1252 - val_acc: 0.9883\n",
      "Epoch 398/3000\n",
      "\n",
      "Epoch 00398: val_loss improved from 0.12517 to 0.12324, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.1609 - acc: 0.9995 - val_loss: 0.1232 - val_acc: 0.9892\n",
      "Epoch 399/3000\n",
      "\n",
      "Epoch 00399: val_loss improved from 0.12324 to 0.12260, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.1591 - acc: 0.9994 - val_loss: 0.1226 - val_acc: 0.9893\n",
      "Epoch 400/3000\n",
      "\n",
      "Epoch 00400: val_loss improved from 0.12260 to 0.12173, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.1593 - acc: 0.9998 - val_loss: 0.1217 - val_acc: 0.9887\n",
      "Epoch 401/3000\n",
      "\n",
      "Epoch 00401: val_loss improved from 0.12173 to 0.12022, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.1571 - acc: 0.9997 - val_loss: 0.1202 - val_acc: 0.9890\n",
      "Epoch 402/3000\n",
      "\n",
      "Epoch 00402: val_loss improved from 0.12022 to 0.11928, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.1565 - acc: 0.9995 - val_loss: 0.1193 - val_acc: 0.9891\n",
      "Epoch 403/3000\n",
      "\n",
      "Epoch 00403: val_loss improved from 0.11928 to 0.11871, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.1555 - acc: 0.9996 - val_loss: 0.1187 - val_acc: 0.9888\n",
      "Epoch 404/3000\n",
      "\n",
      "Epoch 00404: val_loss improved from 0.11871 to 0.11839, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.1548 - acc: 0.9995 - val_loss: 0.1184 - val_acc: 0.9890\n",
      "Epoch 405/3000\n",
      "\n",
      "Epoch 00405: val_loss improved from 0.11839 to 0.11759, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.1534 - acc: 0.9995 - val_loss: 0.1176 - val_acc: 0.9893\n",
      "Epoch 406/3000\n",
      "\n",
      "Epoch 00406: val_loss improved from 0.11759 to 0.11653, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.1532 - acc: 0.9996 - val_loss: 0.1165 - val_acc: 0.9892\n",
      "Epoch 407/3000\n",
      "\n",
      "Epoch 00407: val_loss improved from 0.11653 to 0.11545, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.1511 - acc: 0.9996 - val_loss: 0.1154 - val_acc: 0.9891\n",
      "Epoch 408/3000\n",
      "\n",
      "Epoch 00408: val_loss improved from 0.11545 to 0.11398, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.1490 - acc: 0.9998 - val_loss: 0.1140 - val_acc: 0.9893\n",
      "Epoch 409/3000\n",
      "\n",
      "Epoch 00409: val_loss improved from 0.11398 to 0.11364, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.1501 - acc: 0.9997 - val_loss: 0.1136 - val_acc: 0.9891\n",
      "Epoch 410/3000\n",
      "\n",
      "Epoch 00410: val_loss improved from 0.11364 to 0.11346, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.1482 - acc: 0.9997 - val_loss: 0.1135 - val_acc: 0.9890\n",
      "Epoch 411/3000\n",
      "\n",
      "Epoch 00411: val_loss improved from 0.11346 to 0.11226, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.1463 - acc: 0.9997 - val_loss: 0.1123 - val_acc: 0.9887\n",
      "Epoch 412/3000\n",
      "\n",
      "Epoch 00412: val_loss improved from 0.11226 to 0.11081, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.1468 - acc: 0.9996 - val_loss: 0.1108 - val_acc: 0.9890\n",
      "Epoch 413/3000\n",
      "\n",
      "Epoch 00413: val_loss did not improve from 0.11081\n",
      "29400/29400 - 1s - loss: 0.1445 - acc: 0.9998 - val_loss: 0.1115 - val_acc: 0.9887\n",
      "Epoch 414/3000\n",
      "\n",
      "Epoch 00414: val_loss did not improve from 0.11081\n",
      "29400/29400 - 1s - loss: 0.1427 - acc: 0.9998 - val_loss: 0.1113 - val_acc: 0.9890\n",
      "Epoch 415/3000\n",
      "\n",
      "Epoch 00415: val_loss improved from 0.11081 to 0.10983, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.1422 - acc: 0.9997 - val_loss: 0.1098 - val_acc: 0.9893\n",
      "Epoch 416/3000\n",
      "\n",
      "Epoch 00416: val_loss improved from 0.10983 to 0.10888, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.1416 - acc: 0.9997 - val_loss: 0.1089 - val_acc: 0.9887\n",
      "Epoch 417/3000\n",
      "\n",
      "Epoch 00417: val_loss did not improve from 0.10888\n",
      "29400/29400 - 1s - loss: 0.1403 - acc: 0.9996 - val_loss: 0.1094 - val_acc: 0.9887\n",
      "Epoch 418/3000\n",
      "\n",
      "Epoch 00418: val_loss improved from 0.10888 to 0.10846, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.1383 - acc: 0.9998 - val_loss: 0.1085 - val_acc: 0.9888\n",
      "Epoch 419/3000\n",
      "\n",
      "Epoch 00419: val_loss improved from 0.10846 to 0.10766, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.1373 - acc: 0.9996 - val_loss: 0.1077 - val_acc: 0.9890\n",
      "Epoch 420/3000\n",
      "\n",
      "Epoch 00420: val_loss improved from 0.10766 to 0.10738, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.1371 - acc: 0.9996 - val_loss: 0.1074 - val_acc: 0.9891\n",
      "Epoch 421/3000\n",
      "\n",
      "Epoch 00421: val_loss improved from 0.10738 to 0.10687, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.1363 - acc: 0.9993 - val_loss: 0.1069 - val_acc: 0.9892\n",
      "Epoch 422/3000\n",
      "\n",
      "Epoch 00422: val_loss improved from 0.10687 to 0.10612, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.1357 - acc: 0.9996 - val_loss: 0.1061 - val_acc: 0.9894\n",
      "Epoch 423/3000\n",
      "\n",
      "Epoch 00423: val_loss improved from 0.10612 to 0.10498, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.1332 - acc: 0.9996 - val_loss: 0.1050 - val_acc: 0.9893\n",
      "Epoch 424/3000\n",
      "\n",
      "Epoch 00424: val_loss improved from 0.10498 to 0.10398, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.1322 - acc: 0.9996 - val_loss: 0.1040 - val_acc: 0.9895\n",
      "Epoch 425/3000\n",
      "\n",
      "Epoch 00425: val_loss improved from 0.10398 to 0.10340, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.1318 - acc: 0.9997 - val_loss: 0.1034 - val_acc: 0.9893\n",
      "Epoch 426/3000\n",
      "\n",
      "Epoch 00426: val_loss improved from 0.10340 to 0.10316, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.1300 - acc: 0.9997 - val_loss: 0.1032 - val_acc: 0.9888\n",
      "Epoch 427/3000\n",
      "\n",
      "Epoch 00427: val_loss improved from 0.10316 to 0.10237, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.1299 - acc: 0.9998 - val_loss: 0.1024 - val_acc: 0.9887\n",
      "Epoch 428/3000\n",
      "\n",
      "Epoch 00428: val_loss improved from 0.10237 to 0.10187, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.1291 - acc: 0.9998 - val_loss: 0.1019 - val_acc: 0.9889\n",
      "Epoch 429/3000\n",
      "\n",
      "Epoch 00429: val_loss improved from 0.10187 to 0.10105, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.1272 - acc: 0.9997 - val_loss: 0.1011 - val_acc: 0.9890\n",
      "Epoch 430/3000\n",
      "\n",
      "Epoch 00430: val_loss improved from 0.10105 to 0.10072, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.1264 - acc: 0.9997 - val_loss: 0.1007 - val_acc: 0.9890\n",
      "Epoch 431/3000\n",
      "\n",
      "Epoch 00431: val_loss improved from 0.10072 to 0.10061, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.1256 - acc: 0.9997 - val_loss: 0.1006 - val_acc: 0.9890\n",
      "Epoch 432/3000\n",
      "\n",
      "Epoch 00432: val_loss improved from 0.10061 to 0.09987, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.1251 - acc: 0.9998 - val_loss: 0.0999 - val_acc: 0.9890\n",
      "Epoch 433/3000\n",
      "\n",
      "Epoch 00433: val_loss improved from 0.09987 to 0.09912, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.1229 - acc: 0.9995 - val_loss: 0.0991 - val_acc: 0.9888\n",
      "Epoch 434/3000\n",
      "\n",
      "Epoch 00434: val_loss improved from 0.09912 to 0.09874, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.1243 - acc: 0.9998 - val_loss: 0.0987 - val_acc: 0.9889\n",
      "Epoch 435/3000\n",
      "\n",
      "Epoch 00435: val_loss improved from 0.09874 to 0.09798, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.1233 - acc: 0.9996 - val_loss: 0.0980 - val_acc: 0.9889\n",
      "Epoch 436/3000\n",
      "\n",
      "Epoch 00436: val_loss improved from 0.09798 to 0.09728, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.1211 - acc: 0.9996 - val_loss: 0.0973 - val_acc: 0.9893\n",
      "Epoch 437/3000\n",
      "\n",
      "Epoch 00437: val_loss improved from 0.09728 to 0.09655, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.1210 - acc: 0.9997 - val_loss: 0.0966 - val_acc: 0.9894\n",
      "Epoch 438/3000\n",
      "\n",
      "Epoch 00438: val_loss improved from 0.09655 to 0.09566, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.1211 - acc: 0.9993 - val_loss: 0.0957 - val_acc: 0.9898\n",
      "Epoch 439/3000\n",
      "\n",
      "Epoch 00439: val_loss improved from 0.09566 to 0.09465, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.1205 - acc: 0.9996 - val_loss: 0.0946 - val_acc: 0.9893\n",
      "Epoch 440/3000\n",
      "\n",
      "Epoch 00440: val_loss did not improve from 0.09465\n",
      "29400/29400 - 1s - loss: 0.1176 - acc: 0.9998 - val_loss: 0.0951 - val_acc: 0.9887\n",
      "Epoch 441/3000\n",
      "\n",
      "Epoch 00441: val_loss improved from 0.09465 to 0.09464, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.1177 - acc: 0.9995 - val_loss: 0.0946 - val_acc: 0.9888\n",
      "Epoch 442/3000\n",
      "\n",
      "Epoch 00442: val_loss improved from 0.09464 to 0.09319, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.1170 - acc: 0.9995 - val_loss: 0.0932 - val_acc: 0.9894\n",
      "Epoch 443/3000\n",
      "\n",
      "Epoch 00443: val_loss improved from 0.09319 to 0.09271, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.1160 - acc: 0.9996 - val_loss: 0.0927 - val_acc: 0.9890\n",
      "Epoch 444/3000\n",
      "\n",
      "Epoch 00444: val_loss improved from 0.09271 to 0.09219, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.1149 - acc: 0.9997 - val_loss: 0.0922 - val_acc: 0.9890\n",
      "Epoch 445/3000\n",
      "\n",
      "Epoch 00445: val_loss did not improve from 0.09219\n",
      "29400/29400 - 1s - loss: 0.1148 - acc: 0.9997 - val_loss: 0.0922 - val_acc: 0.9889\n",
      "Epoch 446/3000\n",
      "\n",
      "Epoch 00446: val_loss did not improve from 0.09219\n",
      "29400/29400 - 1s - loss: 0.1120 - acc: 0.9998 - val_loss: 0.0927 - val_acc: 0.9888\n",
      "Epoch 447/3000\n",
      "\n",
      "Epoch 00447: val_loss improved from 0.09219 to 0.09212, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.1123 - acc: 0.9996 - val_loss: 0.0921 - val_acc: 0.9888\n",
      "Epoch 448/3000\n",
      "\n",
      "Epoch 00448: val_loss improved from 0.09212 to 0.09161, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.1115 - acc: 0.9998 - val_loss: 0.0916 - val_acc: 0.9890\n",
      "Epoch 449/3000\n",
      "\n",
      "Epoch 00449: val_loss improved from 0.09161 to 0.09141, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.1118 - acc: 0.9997 - val_loss: 0.0914 - val_acc: 0.9890\n",
      "Epoch 450/3000\n",
      "\n",
      "Epoch 00450: val_loss improved from 0.09141 to 0.09072, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.1096 - acc: 0.9996 - val_loss: 0.0907 - val_acc: 0.9888\n",
      "Epoch 451/3000\n",
      "\n",
      "Epoch 00451: val_loss improved from 0.09072 to 0.08905, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.1087 - acc: 0.9997 - val_loss: 0.0890 - val_acc: 0.9888\n",
      "Epoch 452/3000\n",
      "\n",
      "Epoch 00452: val_loss improved from 0.08905 to 0.08834, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.1086 - acc: 0.9998 - val_loss: 0.0883 - val_acc: 0.9890\n",
      "Epoch 453/3000\n",
      "\n",
      "Epoch 00453: val_loss improved from 0.08834 to 0.08824, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.1085 - acc: 0.9994 - val_loss: 0.0882 - val_acc: 0.9890\n",
      "Epoch 454/3000\n",
      "\n",
      "Epoch 00454: val_loss improved from 0.08824 to 0.08716, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.1077 - acc: 0.9996 - val_loss: 0.0872 - val_acc: 0.9890\n",
      "Epoch 455/3000\n",
      "\n",
      "Epoch 00455: val_loss improved from 0.08716 to 0.08641, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.1063 - acc: 0.9998 - val_loss: 0.0864 - val_acc: 0.9892\n",
      "Epoch 456/3000\n",
      "\n",
      "Epoch 00456: val_loss did not improve from 0.08641\n",
      "29400/29400 - 1s - loss: 0.1052 - acc: 0.9998 - val_loss: 0.0870 - val_acc: 0.9889\n",
      "Epoch 457/3000\n",
      "\n",
      "Epoch 00457: val_loss did not improve from 0.08641\n",
      "29400/29400 - 1s - loss: 0.1052 - acc: 0.9998 - val_loss: 0.0873 - val_acc: 0.9889\n",
      "Epoch 458/3000\n",
      "\n",
      "Epoch 00458: val_loss did not improve from 0.08641\n",
      "29400/29400 - 1s - loss: 0.1049 - acc: 0.9996 - val_loss: 0.0873 - val_acc: 0.9888\n",
      "Epoch 459/3000\n",
      "\n",
      "Epoch 00459: val_loss did not improve from 0.08641\n",
      "29400/29400 - 1s - loss: 0.1028 - acc: 0.9997 - val_loss: 0.0864 - val_acc: 0.9886\n",
      "Epoch 460/3000\n",
      "\n",
      "Epoch 00460: val_loss improved from 0.08641 to 0.08571, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.1039 - acc: 0.9995 - val_loss: 0.0857 - val_acc: 0.9889\n",
      "Epoch 461/3000\n",
      "\n",
      "Epoch 00461: val_loss improved from 0.08571 to 0.08521, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.1028 - acc: 0.9996 - val_loss: 0.0852 - val_acc: 0.9889\n",
      "Epoch 462/3000\n",
      "\n",
      "Epoch 00462: val_loss improved from 0.08521 to 0.08429, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.1019 - acc: 0.9998 - val_loss: 0.0843 - val_acc: 0.9892\n",
      "Epoch 463/3000\n",
      "\n",
      "Epoch 00463: val_loss improved from 0.08429 to 0.08367, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.1021 - acc: 0.9997 - val_loss: 0.0837 - val_acc: 0.9894\n",
      "Epoch 464/3000\n",
      "\n",
      "Epoch 00464: val_loss improved from 0.08367 to 0.08339, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.1004 - acc: 0.9996 - val_loss: 0.0834 - val_acc: 0.9893\n",
      "Epoch 465/3000\n",
      "\n",
      "Epoch 00465: val_loss improved from 0.08339 to 0.08280, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.0996 - acc: 0.9999 - val_loss: 0.0828 - val_acc: 0.9892\n",
      "Epoch 466/3000\n",
      "\n",
      "Epoch 00466: val_loss did not improve from 0.08280\n",
      "29400/29400 - 1s - loss: 0.0992 - acc: 0.9998 - val_loss: 0.0834 - val_acc: 0.9892\n",
      "Epoch 467/3000\n",
      "\n",
      "Epoch 00467: val_loss did not improve from 0.08280\n",
      "29400/29400 - 1s - loss: 0.0973 - acc: 0.9998 - val_loss: 0.0831 - val_acc: 0.9891\n",
      "Epoch 468/3000\n",
      "\n",
      "Epoch 00468: val_loss improved from 0.08280 to 0.08212, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.0980 - acc: 0.9997 - val_loss: 0.0821 - val_acc: 0.9890\n",
      "Epoch 469/3000\n",
      "\n",
      "Epoch 00469: val_loss did not improve from 0.08212\n",
      "29400/29400 - 1s - loss: 0.0967 - acc: 0.9994 - val_loss: 0.0824 - val_acc: 0.9891\n",
      "Epoch 470/3000\n",
      "\n",
      "Epoch 00470: val_loss did not improve from 0.08212\n",
      "29400/29400 - 1s - loss: 0.0962 - acc: 0.9998 - val_loss: 0.0826 - val_acc: 0.9886\n",
      "Epoch 471/3000\n",
      "\n",
      "Epoch 00471: val_loss did not improve from 0.08212\n",
      "29400/29400 - 1s - loss: 0.0960 - acc: 0.9998 - val_loss: 0.0822 - val_acc: 0.9887\n",
      "Epoch 472/3000\n",
      "\n",
      "Epoch 00472: val_loss did not improve from 0.08212\n",
      "29400/29400 - 1s - loss: 0.0950 - acc: 0.9995 - val_loss: 0.0830 - val_acc: 0.9889\n",
      "Epoch 473/3000\n",
      "\n",
      "Epoch 00473: val_loss improved from 0.08212 to 0.08151, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.0943 - acc: 0.9996 - val_loss: 0.0815 - val_acc: 0.9890\n",
      "Epoch 474/3000\n",
      "\n",
      "Epoch 00474: val_loss improved from 0.08151 to 0.08036, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.0936 - acc: 0.9998 - val_loss: 0.0804 - val_acc: 0.9890\n",
      "Epoch 475/3000\n",
      "\n",
      "Epoch 00475: val_loss did not improve from 0.08036\n",
      "29400/29400 - 1s - loss: 0.0932 - acc: 0.9997 - val_loss: 0.0804 - val_acc: 0.9890\n",
      "Epoch 476/3000\n",
      "\n",
      "Epoch 00476: val_loss did not improve from 0.08036\n",
      "29400/29400 - 1s - loss: 0.0912 - acc: 0.9997 - val_loss: 0.0808 - val_acc: 0.9891\n",
      "Epoch 477/3000\n",
      "\n",
      "Epoch 00477: val_loss did not improve from 0.08036\n",
      "29400/29400 - 1s - loss: 0.0924 - acc: 0.9999 - val_loss: 0.0804 - val_acc: 0.9894\n",
      "Epoch 478/3000\n",
      "\n",
      "Epoch 00478: val_loss improved from 0.08036 to 0.08030, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.0908 - acc: 0.9998 - val_loss: 0.0803 - val_acc: 0.9888\n",
      "Epoch 479/3000\n",
      "\n",
      "Epoch 00479: val_loss did not improve from 0.08030\n",
      "29400/29400 - 1s - loss: 0.0911 - acc: 0.9997 - val_loss: 0.0806 - val_acc: 0.9887\n",
      "Epoch 480/3000\n",
      "\n",
      "Epoch 00480: val_loss improved from 0.08030 to 0.07999, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.0896 - acc: 0.9996 - val_loss: 0.0800 - val_acc: 0.9890\n",
      "Epoch 481/3000\n",
      "\n",
      "Epoch 00481: val_loss improved from 0.07999 to 0.07940, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.0901 - acc: 0.9998 - val_loss: 0.0794 - val_acc: 0.9890\n",
      "Epoch 482/3000\n",
      "\n",
      "Epoch 00482: val_loss improved from 0.07940 to 0.07848, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.0885 - acc: 0.9996 - val_loss: 0.0785 - val_acc: 0.9888\n",
      "Epoch 483/3000\n",
      "\n",
      "Epoch 00483: val_loss did not improve from 0.07848\n",
      "29400/29400 - 1s - loss: 0.0874 - acc: 0.9998 - val_loss: 0.0788 - val_acc: 0.9884\n",
      "Epoch 484/3000\n",
      "\n",
      "Epoch 00484: val_loss did not improve from 0.07848\n",
      "29400/29400 - 1s - loss: 0.0888 - acc: 0.9996 - val_loss: 0.0789 - val_acc: 0.9885\n",
      "Epoch 485/3000\n",
      "\n",
      "Epoch 00485: val_loss did not improve from 0.07848\n",
      "29400/29400 - 1s - loss: 0.0856 - acc: 0.9997 - val_loss: 0.0789 - val_acc: 0.9883\n",
      "Epoch 486/3000\n",
      "\n",
      "Epoch 00486: val_loss improved from 0.07848 to 0.07830, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.0869 - acc: 0.9996 - val_loss: 0.0783 - val_acc: 0.9887\n",
      "Epoch 487/3000\n",
      "\n",
      "Epoch 00487: val_loss improved from 0.07830 to 0.07772, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.0860 - acc: 0.9998 - val_loss: 0.0777 - val_acc: 0.9890\n",
      "Epoch 488/3000\n",
      "\n",
      "Epoch 00488: val_loss improved from 0.07772 to 0.07727, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.0846 - acc: 0.9996 - val_loss: 0.0773 - val_acc: 0.9889\n",
      "Epoch 489/3000\n",
      "\n",
      "Epoch 00489: val_loss improved from 0.07727 to 0.07706, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.0840 - acc: 0.9998 - val_loss: 0.0771 - val_acc: 0.9893\n",
      "Epoch 490/3000\n",
      "\n",
      "Epoch 00490: val_loss improved from 0.07706 to 0.07634, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.0835 - acc: 0.9997 - val_loss: 0.0763 - val_acc: 0.9889\n",
      "Epoch 491/3000\n",
      "\n",
      "Epoch 00491: val_loss did not improve from 0.07634\n",
      "29400/29400 - 1s - loss: 0.0836 - acc: 0.9998 - val_loss: 0.0769 - val_acc: 0.9887\n",
      "Epoch 492/3000\n",
      "\n",
      "Epoch 00492: val_loss did not improve from 0.07634\n",
      "29400/29400 - 1s - loss: 0.0819 - acc: 0.9999 - val_loss: 0.0773 - val_acc: 0.9885\n",
      "Epoch 493/3000\n",
      "\n",
      "Epoch 00493: val_loss improved from 0.07634 to 0.07576, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.0824 - acc: 0.9998 - val_loss: 0.0758 - val_acc: 0.9886\n",
      "Epoch 494/3000\n",
      "\n",
      "Epoch 00494: val_loss improved from 0.07576 to 0.07480, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.0825 - acc: 0.9997 - val_loss: 0.0748 - val_acc: 0.9887\n",
      "Epoch 495/3000\n",
      "\n",
      "Epoch 00495: val_loss did not improve from 0.07480\n",
      "29400/29400 - 1s - loss: 0.0816 - acc: 0.9997 - val_loss: 0.0751 - val_acc: 0.9887\n",
      "Epoch 496/3000\n",
      "\n",
      "Epoch 00496: val_loss did not improve from 0.07480\n",
      "29400/29400 - 1s - loss: 0.0807 - acc: 0.9996 - val_loss: 0.0754 - val_acc: 0.9888\n",
      "Epoch 497/3000\n",
      "\n",
      "Epoch 00497: val_loss improved from 0.07480 to 0.07441, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.0800 - acc: 0.9996 - val_loss: 0.0744 - val_acc: 0.9887\n",
      "Epoch 498/3000\n",
      "\n",
      "Epoch 00498: val_loss did not improve from 0.07441\n",
      "29400/29400 - 1s - loss: 0.0802 - acc: 0.9997 - val_loss: 0.0750 - val_acc: 0.9885\n",
      "Epoch 499/3000\n",
      "\n",
      "Epoch 00499: val_loss did not improve from 0.07441\n",
      "29400/29400 - 1s - loss: 0.0790 - acc: 0.9998 - val_loss: 0.0751 - val_acc: 0.9888\n",
      "Epoch 500/3000\n",
      "\n",
      "Epoch 00500: val_loss did not improve from 0.07441\n",
      "29400/29400 - 1s - loss: 0.0783 - acc: 0.9998 - val_loss: 0.0752 - val_acc: 0.9889\n",
      "Epoch 501/3000\n",
      "\n",
      "Epoch 00501: val_loss did not improve from 0.07441\n",
      "29400/29400 - 1s - loss: 0.0783 - acc: 0.9998 - val_loss: 0.0748 - val_acc: 0.9892\n",
      "Epoch 502/3000\n",
      "\n",
      "Epoch 00502: val_loss improved from 0.07441 to 0.07288, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.0784 - acc: 0.9998 - val_loss: 0.0729 - val_acc: 0.9891\n",
      "Epoch 503/3000\n",
      "\n",
      "Epoch 00503: val_loss improved from 0.07288 to 0.07229, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.0780 - acc: 0.9996 - val_loss: 0.0723 - val_acc: 0.9892\n",
      "Epoch 504/3000\n",
      "\n",
      "Epoch 00504: val_loss did not improve from 0.07229\n",
      "29400/29400 - 1s - loss: 0.0769 - acc: 0.9998 - val_loss: 0.0730 - val_acc: 0.9889\n",
      "Epoch 505/3000\n",
      "\n",
      "Epoch 00505: val_loss did not improve from 0.07229\n",
      "29400/29400 - 1s - loss: 0.0771 - acc: 0.9998 - val_loss: 0.0738 - val_acc: 0.9887\n",
      "Epoch 506/3000\n",
      "\n",
      "Epoch 00506: val_loss did not improve from 0.07229\n",
      "29400/29400 - 1s - loss: 0.0764 - acc: 0.9997 - val_loss: 0.0736 - val_acc: 0.9890\n",
      "Epoch 507/3000\n",
      "\n",
      "Epoch 00507: val_loss did not improve from 0.07229\n",
      "29400/29400 - 1s - loss: 0.0749 - acc: 0.9998 - val_loss: 0.0739 - val_acc: 0.9887\n",
      "Epoch 508/3000\n",
      "\n",
      "Epoch 00508: val_loss did not improve from 0.07229\n",
      "29400/29400 - 1s - loss: 0.0753 - acc: 0.9998 - val_loss: 0.0727 - val_acc: 0.9887\n",
      "Epoch 509/3000\n",
      "\n",
      "Epoch 00509: val_loss improved from 0.07229 to 0.07148, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.0750 - acc: 0.9998 - val_loss: 0.0715 - val_acc: 0.9891\n",
      "Epoch 510/3000\n",
      "\n",
      "Epoch 00510: val_loss improved from 0.07148 to 0.07091, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.0747 - acc: 0.9997 - val_loss: 0.0709 - val_acc: 0.9892\n",
      "Epoch 511/3000\n",
      "\n",
      "Epoch 00511: val_loss did not improve from 0.07091\n",
      "29400/29400 - 1s - loss: 0.0739 - acc: 0.9996 - val_loss: 0.0716 - val_acc: 0.9887\n",
      "Epoch 512/3000\n",
      "\n",
      "Epoch 00512: val_loss did not improve from 0.07091\n",
      "29400/29400 - 1s - loss: 0.0740 - acc: 0.9998 - val_loss: 0.0718 - val_acc: 0.9890\n",
      "Epoch 513/3000\n",
      "\n",
      "Epoch 00513: val_loss did not improve from 0.07091\n",
      "29400/29400 - 1s - loss: 0.0733 - acc: 0.9997 - val_loss: 0.0714 - val_acc: 0.9888\n",
      "Epoch 514/3000\n",
      "\n",
      "Epoch 00514: val_loss did not improve from 0.07091\n",
      "29400/29400 - 1s - loss: 0.0724 - acc: 0.9997 - val_loss: 0.0717 - val_acc: 0.9890\n",
      "Epoch 515/3000\n",
      "\n",
      "Epoch 00515: val_loss did not improve from 0.07091\n",
      "29400/29400 - 1s - loss: 0.0731 - acc: 0.9997 - val_loss: 0.0714 - val_acc: 0.9890\n",
      "Epoch 516/3000\n",
      "\n",
      "Epoch 00516: val_loss did not improve from 0.07091\n",
      "29400/29400 - 1s - loss: 0.0709 - acc: 0.9996 - val_loss: 0.0711 - val_acc: 0.9891\n",
      "Epoch 517/3000\n",
      "\n",
      "Epoch 00517: val_loss improved from 0.07091 to 0.06989, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.0720 - acc: 0.9997 - val_loss: 0.0699 - val_acc: 0.9892\n",
      "Epoch 518/3000\n",
      "\n",
      "Epoch 00518: val_loss improved from 0.06989 to 0.06899, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.0705 - acc: 0.9998 - val_loss: 0.0690 - val_acc: 0.9893\n",
      "Epoch 519/3000\n",
      "\n",
      "Epoch 00519: val_loss did not improve from 0.06899\n",
      "29400/29400 - 1s - loss: 0.0697 - acc: 0.9997 - val_loss: 0.0700 - val_acc: 0.9890\n",
      "Epoch 520/3000\n",
      "\n",
      "Epoch 00520: val_loss did not improve from 0.06899\n",
      "29400/29400 - 1s - loss: 0.0699 - acc: 0.9996 - val_loss: 0.0703 - val_acc: 0.9888\n",
      "Epoch 521/3000\n",
      "\n",
      "Epoch 00521: val_loss did not improve from 0.06899\n",
      "29400/29400 - 1s - loss: 0.0692 - acc: 0.9998 - val_loss: 0.0706 - val_acc: 0.9891\n",
      "Epoch 522/3000\n",
      "\n",
      "Epoch 00522: val_loss did not improve from 0.06899\n",
      "29400/29400 - 1s - loss: 0.0688 - acc: 0.9997 - val_loss: 0.0696 - val_acc: 0.9892\n",
      "Epoch 523/3000\n",
      "\n",
      "Epoch 00523: val_loss improved from 0.06899 to 0.06872, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.0682 - acc: 0.9997 - val_loss: 0.0687 - val_acc: 0.9891\n",
      "Epoch 524/3000\n",
      "\n",
      "Epoch 00524: val_loss improved from 0.06872 to 0.06831, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.0680 - acc: 0.9998 - val_loss: 0.0683 - val_acc: 0.9894\n",
      "Epoch 525/3000\n",
      "\n",
      "Epoch 00525: val_loss improved from 0.06831 to 0.06645, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.0676 - acc: 0.9997 - val_loss: 0.0664 - val_acc: 0.9896\n",
      "Epoch 526/3000\n",
      "\n",
      "Epoch 00526: val_loss did not improve from 0.06645\n",
      "29400/29400 - 1s - loss: 0.0670 - acc: 1.0000 - val_loss: 0.0682 - val_acc: 0.9890\n",
      "Epoch 527/3000\n",
      "\n",
      "Epoch 00527: val_loss did not improve from 0.06645\n",
      "29400/29400 - 1s - loss: 0.0663 - acc: 0.9996 - val_loss: 0.0702 - val_acc: 0.9890\n",
      "Epoch 528/3000\n",
      "\n",
      "Epoch 00528: val_loss did not improve from 0.06645\n",
      "29400/29400 - 1s - loss: 0.0657 - acc: 0.9997 - val_loss: 0.0704 - val_acc: 0.9892\n",
      "Epoch 529/3000\n",
      "\n",
      "Epoch 00529: val_loss did not improve from 0.06645\n",
      "29400/29400 - 1s - loss: 0.0658 - acc: 0.9997 - val_loss: 0.0686 - val_acc: 0.9895\n",
      "Epoch 530/3000\n",
      "\n",
      "Epoch 00530: val_loss did not improve from 0.06645\n",
      "29400/29400 - 1s - loss: 0.0654 - acc: 0.9997 - val_loss: 0.0689 - val_acc: 0.9896\n",
      "Epoch 531/3000\n",
      "\n",
      "Epoch 00531: val_loss did not improve from 0.06645\n",
      "29400/29400 - 1s - loss: 0.0649 - acc: 0.9998 - val_loss: 0.0686 - val_acc: 0.9894\n",
      "Epoch 532/3000\n",
      "\n",
      "Epoch 00532: val_loss did not improve from 0.06645\n",
      "29400/29400 - 1s - loss: 0.0641 - acc: 0.9998 - val_loss: 0.0682 - val_acc: 0.9891\n",
      "Epoch 533/3000\n",
      "\n",
      "Epoch 00533: val_loss did not improve from 0.06645\n",
      "29400/29400 - 1s - loss: 0.0651 - acc: 0.9997 - val_loss: 0.0681 - val_acc: 0.9892\n",
      "Epoch 534/3000\n",
      "\n",
      "Epoch 00534: val_loss did not improve from 0.06645\n",
      "29400/29400 - 1s - loss: 0.0636 - acc: 0.9998 - val_loss: 0.0692 - val_acc: 0.9891\n",
      "Epoch 535/3000\n",
      "\n",
      "Epoch 00535: val_loss did not improve from 0.06645\n",
      "29400/29400 - 1s - loss: 0.0634 - acc: 0.9998 - val_loss: 0.0688 - val_acc: 0.9890\n",
      "Epoch 536/3000\n",
      "\n",
      "Epoch 00536: val_loss did not improve from 0.06645\n",
      "29400/29400 - 1s - loss: 0.0626 - acc: 0.9999 - val_loss: 0.0678 - val_acc: 0.9889\n",
      "Epoch 537/3000\n",
      "\n",
      "Epoch 00537: val_loss did not improve from 0.06645\n",
      "29400/29400 - 1s - loss: 0.0627 - acc: 0.9999 - val_loss: 0.0680 - val_acc: 0.9889\n",
      "Epoch 538/3000\n",
      "\n",
      "Epoch 00538: val_loss did not improve from 0.06645\n",
      "29400/29400 - 1s - loss: 0.0620 - acc: 0.9998 - val_loss: 0.0670 - val_acc: 0.9894\n",
      "Epoch 539/3000\n",
      "\n",
      "Epoch 00539: val_loss did not improve from 0.06645\n",
      "29400/29400 - 1s - loss: 0.0626 - acc: 0.9998 - val_loss: 0.0666 - val_acc: 0.9892\n",
      "Epoch 540/3000\n",
      "\n",
      "Epoch 00540: val_loss did not improve from 0.06645\n",
      "29400/29400 - 1s - loss: 0.0623 - acc: 0.9998 - val_loss: 0.0665 - val_acc: 0.9893\n",
      "Epoch 541/3000\n",
      "\n",
      "Epoch 00541: val_loss improved from 0.06645 to 0.06608, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 2s - loss: 0.0619 - acc: 0.9996 - val_loss: 0.0661 - val_acc: 0.9894\n",
      "Epoch 542/3000\n",
      "\n",
      "Epoch 00542: val_loss improved from 0.06608 to 0.06554, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.0625 - acc: 0.9995 - val_loss: 0.0655 - val_acc: 0.9896\n",
      "Epoch 543/3000\n",
      "\n",
      "Epoch 00543: val_loss did not improve from 0.06554\n",
      "29400/29400 - 1s - loss: 0.0598 - acc: 1.0000 - val_loss: 0.0659 - val_acc: 0.9898\n",
      "Epoch 544/3000\n",
      "\n",
      "Epoch 00544: val_loss did not improve from 0.06554\n",
      "29400/29400 - 1s - loss: 0.0593 - acc: 0.9999 - val_loss: 0.0661 - val_acc: 0.9898\n",
      "Epoch 545/3000\n",
      "\n",
      "Epoch 00545: val_loss did not improve from 0.06554\n",
      "29400/29400 - 1s - loss: 0.0602 - acc: 0.9998 - val_loss: 0.0657 - val_acc: 0.9896\n",
      "Epoch 546/3000\n",
      "\n",
      "Epoch 00546: val_loss did not improve from 0.06554\n",
      "29400/29400 - 1s - loss: 0.0591 - acc: 0.9996 - val_loss: 0.0657 - val_acc: 0.9898\n",
      "Epoch 547/3000\n",
      "\n",
      "Epoch 00547: val_loss did not improve from 0.06554\n",
      "29400/29400 - 1s - loss: 0.0591 - acc: 0.9998 - val_loss: 0.0666 - val_acc: 0.9894\n",
      "Epoch 548/3000\n",
      "\n",
      "Epoch 00548: val_loss did not improve from 0.06554\n",
      "29400/29400 - 1s - loss: 0.0584 - acc: 0.9997 - val_loss: 0.0660 - val_acc: 0.9895\n",
      "Epoch 549/3000\n",
      "\n",
      "Epoch 00549: val_loss did not improve from 0.06554\n",
      "29400/29400 - 1s - loss: 0.0581 - acc: 0.9998 - val_loss: 0.0671 - val_acc: 0.9890\n",
      "Epoch 550/3000\n",
      "\n",
      "Epoch 00550: val_loss improved from 0.06554 to 0.06488, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.0583 - acc: 0.9998 - val_loss: 0.0649 - val_acc: 0.9896\n",
      "Epoch 551/3000\n",
      "\n",
      "Epoch 00551: val_loss did not improve from 0.06488\n",
      "29400/29400 - 1s - loss: 0.0583 - acc: 0.9997 - val_loss: 0.0663 - val_acc: 0.9894\n",
      "Epoch 552/3000\n",
      "\n",
      "Epoch 00552: val_loss did not improve from 0.06488\n",
      "29400/29400 - 1s - loss: 0.0570 - acc: 0.9997 - val_loss: 0.0659 - val_acc: 0.9894\n",
      "Epoch 553/3000\n",
      "\n",
      "Epoch 00553: val_loss did not improve from 0.06488\n",
      "29400/29400 - 1s - loss: 0.0564 - acc: 0.9998 - val_loss: 0.0654 - val_acc: 0.9896\n",
      "Epoch 554/3000\n",
      "\n",
      "Epoch 00554: val_loss did not improve from 0.06488\n",
      "29400/29400 - 1s - loss: 0.0575 - acc: 0.9997 - val_loss: 0.0655 - val_acc: 0.9894\n",
      "Epoch 555/3000\n",
      "\n",
      "Epoch 00555: val_loss did not improve from 0.06488\n",
      "29400/29400 - 1s - loss: 0.0566 - acc: 0.9996 - val_loss: 0.0656 - val_acc: 0.9894\n",
      "Epoch 556/3000\n",
      "\n",
      "Epoch 00556: val_loss improved from 0.06488 to 0.06417, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.0560 - acc: 0.9998 - val_loss: 0.0642 - val_acc: 0.9894\n",
      "Epoch 557/3000\n",
      "\n",
      "Epoch 00557: val_loss improved from 0.06417 to 0.06369, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.0547 - acc: 0.9998 - val_loss: 0.0637 - val_acc: 0.9896\n",
      "Epoch 558/3000\n",
      "\n",
      "Epoch 00558: val_loss did not improve from 0.06369\n",
      "29400/29400 - 1s - loss: 0.0555 - acc: 0.9998 - val_loss: 0.0650 - val_acc: 0.9894\n",
      "Epoch 559/3000\n",
      "\n",
      "Epoch 00559: val_loss did not improve from 0.06369\n",
      "29400/29400 - 1s - loss: 0.0555 - acc: 0.9997 - val_loss: 0.0650 - val_acc: 0.9894\n",
      "Epoch 560/3000\n",
      "\n",
      "Epoch 00560: val_loss did not improve from 0.06369\n",
      "29400/29400 - 1s - loss: 0.0543 - acc: 0.9998 - val_loss: 0.0653 - val_acc: 0.9893\n",
      "Epoch 561/3000\n",
      "\n",
      "Epoch 00561: val_loss did not improve from 0.06369\n",
      "29400/29400 - 1s - loss: 0.0544 - acc: 0.9998 - val_loss: 0.0641 - val_acc: 0.9892\n",
      "Epoch 562/3000\n",
      "\n",
      "Epoch 00562: val_loss did not improve from 0.06369\n",
      "29400/29400 - 1s - loss: 0.0541 - acc: 0.9996 - val_loss: 0.0653 - val_acc: 0.9891\n",
      "Epoch 563/3000\n",
      "\n",
      "Epoch 00563: val_loss did not improve from 0.06369\n",
      "29400/29400 - 1s - loss: 0.0536 - acc: 0.9998 - val_loss: 0.0672 - val_acc: 0.9888\n",
      "Epoch 564/3000\n",
      "\n",
      "Epoch 00564: val_loss did not improve from 0.06369\n",
      "29400/29400 - 1s - loss: 0.0529 - acc: 0.9999 - val_loss: 0.0651 - val_acc: 0.9894\n",
      "Epoch 565/3000\n",
      "\n",
      "Epoch 00565: val_loss did not improve from 0.06369\n",
      "29400/29400 - 1s - loss: 0.0526 - acc: 0.9998 - val_loss: 0.0646 - val_acc: 0.9893\n",
      "Epoch 566/3000\n",
      "\n",
      "Epoch 00566: val_loss improved from 0.06369 to 0.06331, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.0522 - acc: 0.9997 - val_loss: 0.0633 - val_acc: 0.9893\n",
      "Epoch 567/3000\n",
      "\n",
      "Epoch 00567: val_loss improved from 0.06331 to 0.06276, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.0529 - acc: 0.9998 - val_loss: 0.0628 - val_acc: 0.9892\n",
      "Epoch 568/3000\n",
      "\n",
      "Epoch 00568: val_loss did not improve from 0.06276\n",
      "29400/29400 - 1s - loss: 0.0520 - acc: 0.9996 - val_loss: 0.0645 - val_acc: 0.9894\n",
      "Epoch 569/3000\n",
      "\n",
      "Epoch 00569: val_loss did not improve from 0.06276\n",
      "29400/29400 - 1s - loss: 0.0513 - acc: 0.9999 - val_loss: 0.0646 - val_acc: 0.9894\n",
      "Epoch 570/3000\n",
      "\n",
      "Epoch 00570: val_loss did not improve from 0.06276\n",
      "29400/29400 - 1s - loss: 0.0509 - acc: 0.9998 - val_loss: 0.0636 - val_acc: 0.9896\n",
      "Epoch 571/3000\n",
      "\n",
      "Epoch 00571: val_loss improved from 0.06276 to 0.06194, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.0503 - acc: 0.9998 - val_loss: 0.0619 - val_acc: 0.9898\n",
      "Epoch 572/3000\n",
      "\n",
      "Epoch 00572: val_loss improved from 0.06194 to 0.06102, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.0518 - acc: 0.9996 - val_loss: 0.0610 - val_acc: 0.9897\n",
      "Epoch 573/3000\n",
      "\n",
      "Epoch 00573: val_loss did not improve from 0.06102\n",
      "29400/29400 - 1s - loss: 0.0500 - acc: 0.9999 - val_loss: 0.0623 - val_acc: 0.9897\n",
      "Epoch 574/3000\n",
      "\n",
      "Epoch 00574: val_loss did not improve from 0.06102\n",
      "29400/29400 - 1s - loss: 0.0506 - acc: 0.9997 - val_loss: 0.0634 - val_acc: 0.9893\n",
      "Epoch 575/3000\n",
      "\n",
      "Epoch 00575: val_loss did not improve from 0.06102\n",
      "29400/29400 - 1s - loss: 0.0510 - acc: 0.9997 - val_loss: 0.0642 - val_acc: 0.9893\n",
      "Epoch 576/3000\n",
      "\n",
      "Epoch 00576: val_loss did not improve from 0.06102\n",
      "29400/29400 - 1s - loss: 0.0499 - acc: 0.9997 - val_loss: 0.0634 - val_acc: 0.9894\n",
      "Epoch 577/3000\n",
      "\n",
      "Epoch 00577: val_loss did not improve from 0.06102\n",
      "29400/29400 - 1s - loss: 0.0500 - acc: 0.9997 - val_loss: 0.0632 - val_acc: 0.9894\n",
      "Epoch 578/3000\n",
      "\n",
      "Epoch 00578: val_loss did not improve from 0.06102\n",
      "29400/29400 - 1s - loss: 0.0493 - acc: 0.9997 - val_loss: 0.0642 - val_acc: 0.9890\n",
      "Epoch 579/3000\n",
      "\n",
      "Epoch 00579: val_loss did not improve from 0.06102\n",
      "29400/29400 - 1s - loss: 0.0497 - acc: 0.9996 - val_loss: 0.0638 - val_acc: 0.9891\n",
      "Epoch 580/3000\n",
      "\n",
      "Epoch 00580: val_loss did not improve from 0.06102\n",
      "29400/29400 - 1s - loss: 0.0486 - acc: 0.9996 - val_loss: 0.0648 - val_acc: 0.9890\n",
      "Epoch 581/3000\n",
      "\n",
      "Epoch 00581: val_loss did not improve from 0.06102\n",
      "29400/29400 - 1s - loss: 0.0487 - acc: 0.9998 - val_loss: 0.0644 - val_acc: 0.9893\n",
      "Epoch 582/3000\n",
      "\n",
      "Epoch 00582: val_loss did not improve from 0.06102\n",
      "29400/29400 - 1s - loss: 0.0484 - acc: 0.9998 - val_loss: 0.0638 - val_acc: 0.9894\n",
      "Epoch 583/3000\n",
      "\n",
      "Epoch 00583: val_loss did not improve from 0.06102\n",
      "29400/29400 - 1s - loss: 0.0477 - acc: 0.9999 - val_loss: 0.0627 - val_acc: 0.9895\n",
      "Epoch 584/3000\n",
      "\n",
      "Epoch 00584: val_loss did not improve from 0.06102\n",
      "29400/29400 - 1s - loss: 0.0477 - acc: 0.9998 - val_loss: 0.0617 - val_acc: 0.9895\n",
      "Epoch 585/3000\n",
      "\n",
      "Epoch 00585: val_loss did not improve from 0.06102\n",
      "29400/29400 - 1s - loss: 0.0474 - acc: 0.9998 - val_loss: 0.0617 - val_acc: 0.9895\n",
      "Epoch 586/3000\n",
      "\n",
      "Epoch 00586: val_loss did not improve from 0.06102\n",
      "29400/29400 - 1s - loss: 0.0470 - acc: 0.9997 - val_loss: 0.0630 - val_acc: 0.9897\n",
      "Epoch 587/3000\n",
      "\n",
      "Epoch 00587: val_loss did not improve from 0.06102\n",
      "29400/29400 - 1s - loss: 0.0451 - acc: 0.9998 - val_loss: 0.0611 - val_acc: 0.9898\n",
      "Epoch 588/3000\n",
      "\n",
      "Epoch 00588: val_loss did not improve from 0.06102\n",
      "29400/29400 - 1s - loss: 0.0470 - acc: 0.9997 - val_loss: 0.0614 - val_acc: 0.9895\n",
      "Epoch 589/3000\n",
      "\n",
      "Epoch 00589: val_loss did not improve from 0.06102\n",
      "29400/29400 - 1s - loss: 0.0459 - acc: 0.9998 - val_loss: 0.0614 - val_acc: 0.9895\n",
      "Epoch 590/3000\n",
      "\n",
      "Epoch 00590: val_loss did not improve from 0.06102\n",
      "29400/29400 - 1s - loss: 0.0458 - acc: 0.9999 - val_loss: 0.0631 - val_acc: 0.9892\n",
      "Epoch 591/3000\n",
      "\n",
      "Epoch 00591: val_loss did not improve from 0.06102\n",
      "29400/29400 - 1s - loss: 0.0457 - acc: 0.9999 - val_loss: 0.0628 - val_acc: 0.9893\n",
      "Epoch 592/3000\n",
      "\n",
      "Epoch 00592: val_loss did not improve from 0.06102\n",
      "29400/29400 - 1s - loss: 0.0447 - acc: 0.9998 - val_loss: 0.0632 - val_acc: 0.9892\n",
      "Epoch 593/3000\n",
      "\n",
      "Epoch 00593: val_loss did not improve from 0.06102\n",
      "29400/29400 - 1s - loss: 0.0446 - acc: 0.9998 - val_loss: 0.0626 - val_acc: 0.9890\n",
      "Epoch 594/3000\n",
      "\n",
      "Epoch 00594: val_loss did not improve from 0.06102\n",
      "29400/29400 - 1s - loss: 0.0448 - acc: 0.9998 - val_loss: 0.0617 - val_acc: 0.9894\n",
      "Epoch 595/3000\n",
      "\n",
      "Epoch 00595: val_loss did not improve from 0.06102\n",
      "29400/29400 - 1s - loss: 0.0447 - acc: 0.9998 - val_loss: 0.0618 - val_acc: 0.9893\n",
      "Epoch 596/3000\n",
      "\n",
      "Epoch 00596: val_loss did not improve from 0.06102\n",
      "29400/29400 - 1s - loss: 0.0458 - acc: 0.9998 - val_loss: 0.0620 - val_acc: 0.9893\n",
      "Epoch 597/3000\n",
      "\n",
      "Epoch 00597: val_loss did not improve from 0.06102\n",
      "29400/29400 - 1s - loss: 0.0437 - acc: 0.9999 - val_loss: 0.0625 - val_acc: 0.9894\n",
      "Epoch 598/3000\n",
      "\n",
      "Epoch 00598: val_loss did not improve from 0.06102\n",
      "29400/29400 - 1s - loss: 0.0435 - acc: 0.9997 - val_loss: 0.0625 - val_acc: 0.9890\n",
      "Epoch 599/3000\n",
      "\n",
      "Epoch 00599: val_loss did not improve from 0.06102\n",
      "29400/29400 - 1s - loss: 0.0433 - acc: 0.9998 - val_loss: 0.0623 - val_acc: 0.9893\n",
      "Epoch 600/3000\n",
      "\n",
      "Epoch 00600: val_loss did not improve from 0.06102\n",
      "29400/29400 - 1s - loss: 0.0429 - acc: 0.9998 - val_loss: 0.0617 - val_acc: 0.9894\n",
      "Epoch 601/3000\n",
      "\n",
      "Epoch 00601: val_loss did not improve from 0.06102\n",
      "29400/29400 - 1s - loss: 0.0433 - acc: 0.9998 - val_loss: 0.0616 - val_acc: 0.9896\n",
      "Epoch 602/3000\n",
      "\n",
      "Epoch 00602: val_loss did not improve from 0.06102\n",
      "29400/29400 - 1s - loss: 0.0422 - acc: 0.9998 - val_loss: 0.0628 - val_acc: 0.9892\n",
      "Epoch 603/3000\n",
      "\n",
      "Epoch 00603: val_loss did not improve from 0.06102\n",
      "29400/29400 - 1s - loss: 0.0424 - acc: 0.9997 - val_loss: 0.0630 - val_acc: 0.9889\n",
      "Epoch 604/3000\n",
      "\n",
      "Epoch 00604: val_loss did not improve from 0.06102\n",
      "29400/29400 - 1s - loss: 0.0420 - acc: 0.9997 - val_loss: 0.0631 - val_acc: 0.9890\n",
      "Epoch 605/3000\n",
      "\n",
      "Epoch 00605: val_loss did not improve from 0.06102\n",
      "29400/29400 - 1s - loss: 0.0418 - acc: 0.9998 - val_loss: 0.0625 - val_acc: 0.9891\n",
      "Epoch 606/3000\n",
      "\n",
      "Epoch 00606: val_loss did not improve from 0.06102\n",
      "29400/29400 - 1s - loss: 0.0418 - acc: 0.9997 - val_loss: 0.0620 - val_acc: 0.9891\n",
      "Epoch 607/3000\n",
      "\n",
      "Epoch 00607: val_loss did not improve from 0.06102\n",
      "29400/29400 - 1s - loss: 0.0415 - acc: 0.9998 - val_loss: 0.0616 - val_acc: 0.9894\n",
      "Epoch 608/3000\n",
      "\n",
      "Epoch 00608: val_loss did not improve from 0.06102\n",
      "29400/29400 - 1s - loss: 0.0411 - acc: 0.9998 - val_loss: 0.0613 - val_acc: 0.9895\n",
      "Epoch 609/3000\n",
      "\n",
      "Epoch 00609: val_loss did not improve from 0.06102\n",
      "29400/29400 - 1s - loss: 0.0419 - acc: 0.9997 - val_loss: 0.0619 - val_acc: 0.9894\n",
      "Epoch 610/3000\n",
      "\n",
      "Epoch 00610: val_loss did not improve from 0.06102\n",
      "29400/29400 - 1s - loss: 0.0408 - acc: 0.9999 - val_loss: 0.0617 - val_acc: 0.9891\n",
      "Epoch 611/3000\n",
      "\n",
      "Epoch 00611: val_loss did not improve from 0.06102\n",
      "29400/29400 - 1s - loss: 0.0411 - acc: 0.9999 - val_loss: 0.0612 - val_acc: 0.9894\n",
      "Epoch 612/3000\n",
      "\n",
      "Epoch 00612: val_loss did not improve from 0.06102\n",
      "29400/29400 - 1s - loss: 0.0400 - acc: 0.9999 - val_loss: 0.0615 - val_acc: 0.9895\n",
      "Epoch 613/3000\n",
      "\n",
      "Epoch 00613: val_loss did not improve from 0.06102\n",
      "29400/29400 - 1s - loss: 0.0408 - acc: 0.9999 - val_loss: 0.0614 - val_acc: 0.9894\n",
      "Epoch 614/3000\n",
      "\n",
      "Epoch 00614: val_loss did not improve from 0.06102\n",
      "29400/29400 - 1s - loss: 0.0403 - acc: 0.9999 - val_loss: 0.0619 - val_acc: 0.9894\n",
      "Epoch 615/3000\n",
      "\n",
      "Epoch 00615: val_loss did not improve from 0.06102\n",
      "29400/29400 - 1s - loss: 0.0390 - acc: 0.9999 - val_loss: 0.0628 - val_acc: 0.9891\n",
      "Epoch 616/3000\n",
      "\n",
      "Epoch 00616: val_loss did not improve from 0.06102\n",
      "29400/29400 - 1s - loss: 0.0387 - acc: 0.9999 - val_loss: 0.0630 - val_acc: 0.9891\n",
      "Epoch 617/3000\n",
      "\n",
      "Epoch 00617: val_loss did not improve from 0.06102\n",
      "29400/29400 - 1s - loss: 0.0390 - acc: 0.9998 - val_loss: 0.0620 - val_acc: 0.9894\n",
      "Epoch 618/3000\n",
      "\n",
      "Epoch 00618: val_loss improved from 0.06102 to 0.06032, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 2s - loss: 0.0389 - acc: 0.9999 - val_loss: 0.0603 - val_acc: 0.9894\n",
      "Epoch 619/3000\n",
      "\n",
      "Epoch 00619: val_loss improved from 0.06032 to 0.06030, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.0394 - acc: 0.9997 - val_loss: 0.0603 - val_acc: 0.9890\n",
      "Epoch 620/3000\n",
      "\n",
      "Epoch 00620: val_loss did not improve from 0.06030\n",
      "29400/29400 - 1s - loss: 0.0390 - acc: 0.9999 - val_loss: 0.0611 - val_acc: 0.9893\n",
      "Epoch 621/3000\n",
      "\n",
      "Epoch 00621: val_loss did not improve from 0.06030\n",
      "29400/29400 - 1s - loss: 0.0388 - acc: 0.9998 - val_loss: 0.0616 - val_acc: 0.9891\n",
      "Epoch 622/3000\n",
      "\n",
      "Epoch 00622: val_loss did not improve from 0.06030\n",
      "29400/29400 - 1s - loss: 0.0387 - acc: 0.9999 - val_loss: 0.0611 - val_acc: 0.9894\n",
      "Epoch 623/3000\n",
      "\n",
      "Epoch 00623: val_loss did not improve from 0.06030\n",
      "29400/29400 - 1s - loss: 0.0378 - acc: 0.9998 - val_loss: 0.0603 - val_acc: 0.9895\n",
      "Epoch 624/3000\n",
      "\n",
      "Epoch 00624: val_loss improved from 0.06030 to 0.05972, saving model to checkpoint-epoch-3000-batch-1024-trial-001.h5\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "29400/29400 - 1s - loss: 0.0384 - acc: 0.9999 - val_loss: 0.0597 - val_acc: 0.9898\n",
      "Epoch 625/3000\n",
      "\n",
      "Epoch 00625: val_loss did not improve from 0.05972\n",
      "29400/29400 - 1s - loss: 0.0375 - acc: 0.9998 - val_loss: 0.0598 - val_acc: 0.9897\n",
      "Epoch 626/3000\n",
      "\n",
      "Epoch 00626: val_loss did not improve from 0.05972\n",
      "29400/29400 - 1s - loss: 0.0375 - acc: 0.9998 - val_loss: 0.0602 - val_acc: 0.9898\n",
      "Epoch 627/3000\n",
      "\n",
      "Epoch 00627: val_loss did not improve from 0.05972\n",
      "29400/29400 - 1s - loss: 0.0374 - acc: 0.9998 - val_loss: 0.0607 - val_acc: 0.9893\n",
      "Epoch 628/3000\n",
      "\n",
      "Epoch 00628: val_loss did not improve from 0.05972\n",
      "29400/29400 - 1s - loss: 0.0374 - acc: 0.9998 - val_loss: 0.0603 - val_acc: 0.9898\n",
      "Epoch 629/3000\n",
      "\n",
      "Epoch 00629: val_loss did not improve from 0.05972\n",
      "29400/29400 - 1s - loss: 0.0367 - acc: 0.9998 - val_loss: 0.0619 - val_acc: 0.9891\n",
      "Epoch 630/3000\n",
      "\n",
      "Epoch 00630: val_loss did not improve from 0.05972\n",
      "29400/29400 - 1s - loss: 0.0364 - acc: 0.9999 - val_loss: 0.0617 - val_acc: 0.9894\n",
      "Epoch 631/3000\n",
      "\n",
      "Epoch 00631: val_loss did not improve from 0.05972\n",
      "29400/29400 - 1s - loss: 0.0358 - acc: 1.0000 - val_loss: 0.0617 - val_acc: 0.9893\n",
      "Epoch 632/3000\n",
      "\n",
      "Epoch 00632: val_loss did not improve from 0.05972\n",
      "29400/29400 - 1s - loss: 0.0362 - acc: 0.9998 - val_loss: 0.0630 - val_acc: 0.9892\n",
      "Epoch 633/3000\n",
      "\n",
      "Epoch 00633: val_loss did not improve from 0.05972\n",
      "29400/29400 - 1s - loss: 0.0361 - acc: 0.9998 - val_loss: 0.0622 - val_acc: 0.9894\n",
      "Epoch 634/3000\n",
      "\n",
      "Epoch 00634: val_loss did not improve from 0.05972\n",
      "29400/29400 - 1s - loss: 0.0361 - acc: 0.9997 - val_loss: 0.0615 - val_acc: 0.9892\n",
      "Epoch 635/3000\n",
      "\n",
      "Epoch 00635: val_loss did not improve from 0.05972\n",
      "29400/29400 - 1s - loss: 0.0353 - acc: 0.9997 - val_loss: 0.0609 - val_acc: 0.9893\n",
      "Epoch 636/3000\n",
      "\n",
      "Epoch 00636: val_loss did not improve from 0.05972\n",
      "29400/29400 - 1s - loss: 0.0360 - acc: 0.9997 - val_loss: 0.0615 - val_acc: 0.9898\n",
      "Epoch 637/3000\n",
      "\n",
      "Epoch 00637: val_loss did not improve from 0.05972\n",
      "29400/29400 - 1s - loss: 0.0360 - acc: 0.9998 - val_loss: 0.0629 - val_acc: 0.9896\n",
      "Epoch 638/3000\n",
      "\n",
      "Epoch 00638: val_loss did not improve from 0.05972\n",
      "29400/29400 - 1s - loss: 0.0352 - acc: 0.9997 - val_loss: 0.0624 - val_acc: 0.9896\n",
      "Epoch 639/3000\n",
      "\n",
      "Epoch 00639: val_loss did not improve from 0.05972\n",
      "29400/29400 - 1s - loss: 0.0351 - acc: 0.9997 - val_loss: 0.0616 - val_acc: 0.9895\n",
      "Epoch 640/3000\n",
      "\n",
      "Epoch 00640: val_loss did not improve from 0.05972\n",
      "29400/29400 - 1s - loss: 0.0350 - acc: 0.9997 - val_loss: 0.0623 - val_acc: 0.9894\n",
      "Epoch 641/3000\n",
      "\n",
      "Epoch 00641: val_loss did not improve from 0.05972\n",
      "29400/29400 - 1s - loss: 0.0350 - acc: 0.9997 - val_loss: 0.0627 - val_acc: 0.9894\n",
      "Epoch 642/3000\n",
      "\n",
      "Epoch 00642: val_loss did not improve from 0.05972\n",
      "29400/29400 - 1s - loss: 0.0340 - acc: 0.9999 - val_loss: 0.0607 - val_acc: 0.9892\n",
      "Epoch 643/3000\n",
      "\n",
      "Epoch 00643: val_loss did not improve from 0.05972\n",
      "29400/29400 - 1s - loss: 0.0344 - acc: 0.9998 - val_loss: 0.0604 - val_acc: 0.9892\n",
      "Epoch 644/3000\n",
      "\n",
      "Epoch 00644: val_loss did not improve from 0.05972\n",
      "29400/29400 - 1s - loss: 0.0344 - acc: 0.9998 - val_loss: 0.0648 - val_acc: 0.9890\n",
      "Epoch 645/3000\n",
      "\n",
      "Epoch 00645: val_loss did not improve from 0.05972\n",
      "29400/29400 - 1s - loss: 0.0338 - acc: 0.9996 - val_loss: 0.0601 - val_acc: 0.9892\n",
      "Epoch 646/3000\n",
      "\n",
      "Epoch 00646: val_loss did not improve from 0.05972\n",
      "29400/29400 - 1s - loss: 0.0339 - acc: 0.9999 - val_loss: 0.0618 - val_acc: 0.9898\n",
      "Epoch 647/3000\n",
      "\n",
      "Epoch 00647: val_loss did not improve from 0.05972\n",
      "29400/29400 - 1s - loss: 0.0327 - acc: 0.9999 - val_loss: 0.0657 - val_acc: 0.9887\n",
      "Epoch 648/3000\n",
      "\n",
      "Epoch 00648: val_loss did not improve from 0.05972\n",
      "29400/29400 - 1s - loss: 0.0332 - acc: 0.9997 - val_loss: 0.0625 - val_acc: 0.9895\n",
      "Epoch 649/3000\n",
      "\n",
      "Epoch 00649: val_loss did not improve from 0.05972\n",
      "29400/29400 - 1s - loss: 0.0336 - acc: 0.9997 - val_loss: 0.0612 - val_acc: 0.9894\n",
      "Epoch 650/3000\n",
      "\n",
      "Epoch 00650: val_loss did not improve from 0.05972\n",
      "29400/29400 - 1s - loss: 0.0332 - acc: 0.9999 - val_loss: 0.0614 - val_acc: 0.9892\n",
      "Epoch 651/3000\n",
      "\n",
      "Epoch 00651: val_loss did not improve from 0.05972\n",
      "29400/29400 - 1s - loss: 0.0325 - acc: 0.9998 - val_loss: 0.0631 - val_acc: 0.9890\n",
      "Epoch 652/3000\n",
      "\n",
      "Epoch 00652: val_loss did not improve from 0.05972\n",
      "29400/29400 - 1s - loss: 0.0325 - acc: 0.9999 - val_loss: 0.0639 - val_acc: 0.9889\n",
      "Epoch 653/3000\n",
      "\n",
      "Epoch 00653: val_loss did not improve from 0.05972\n",
      "29400/29400 - 1s - loss: 0.0323 - acc: 0.9999 - val_loss: 0.0621 - val_acc: 0.9892\n",
      "Epoch 654/3000\n",
      "\n",
      "Epoch 00654: val_loss did not improve from 0.05972\n",
      "29400/29400 - 1s - loss: 0.0325 - acc: 0.9998 - val_loss: 0.0618 - val_acc: 0.9894\n",
      "Epoch 655/3000\n",
      "\n",
      "Epoch 00655: val_loss did not improve from 0.05972\n",
      "29400/29400 - 1s - loss: 0.0319 - acc: 0.9998 - val_loss: 0.0620 - val_acc: 0.9894\n",
      "Epoch 656/3000\n",
      "\n",
      "Epoch 00656: val_loss did not improve from 0.05972\n",
      "29400/29400 - 1s - loss: 0.0327 - acc: 0.9998 - val_loss: 0.0621 - val_acc: 0.9894\n",
      "Epoch 657/3000\n",
      "\n",
      "Epoch 00657: val_loss did not improve from 0.05972\n",
      "29400/29400 - 1s - loss: 0.0312 - acc: 0.9999 - val_loss: 0.0617 - val_acc: 0.9897\n",
      "Epoch 658/3000\n",
      "\n",
      "Epoch 00658: val_loss did not improve from 0.05972\n",
      "29400/29400 - 1s - loss: 0.0319 - acc: 0.9999 - val_loss: 0.0615 - val_acc: 0.9897\n",
      "Epoch 659/3000\n",
      "\n",
      "Epoch 00659: val_loss did not improve from 0.05972\n",
      "29400/29400 - 1s - loss: 0.0309 - acc: 0.9999 - val_loss: 0.0618 - val_acc: 0.9894\n",
      "Epoch 660/3000\n",
      "\n",
      "Epoch 00660: val_loss did not improve from 0.05972\n",
      "29400/29400 - 1s - loss: 0.0311 - acc: 0.9998 - val_loss: 0.0635 - val_acc: 0.9888\n",
      "Epoch 661/3000\n",
      "\n",
      "Epoch 00661: val_loss did not improve from 0.05972\n",
      "29400/29400 - 1s - loss: 0.0314 - acc: 0.9997 - val_loss: 0.0633 - val_acc: 0.9887\n",
      "Epoch 662/3000\n",
      "\n",
      "Epoch 00662: val_loss did not improve from 0.05972\n",
      "29400/29400 - 1s - loss: 0.0309 - acc: 0.9999 - val_loss: 0.0632 - val_acc: 0.9890\n",
      "Epoch 663/3000\n",
      "\n",
      "Epoch 00663: val_loss did not improve from 0.05972\n",
      "29400/29400 - 1s - loss: 0.0304 - acc: 0.9998 - val_loss: 0.0623 - val_acc: 0.9893\n",
      "Epoch 664/3000\n",
      "\n",
      "Epoch 00664: val_loss did not improve from 0.05972\n",
      "29400/29400 - 1s - loss: 0.0308 - acc: 0.9998 - val_loss: 0.0617 - val_acc: 0.9892\n",
      "Epoch 665/3000\n",
      "\n",
      "Epoch 00665: val_loss did not improve from 0.05972\n",
      "29400/29400 - 1s - loss: 0.0296 - acc: 0.9999 - val_loss: 0.0616 - val_acc: 0.9891\n",
      "Epoch 666/3000\n",
      "\n",
      "Epoch 00666: val_loss did not improve from 0.05972\n",
      "29400/29400 - 1s - loss: 0.0303 - acc: 0.9998 - val_loss: 0.0616 - val_acc: 0.9891\n",
      "Epoch 667/3000\n",
      "\n",
      "Epoch 00667: val_loss did not improve from 0.05972\n",
      "29400/29400 - 1s - loss: 0.0300 - acc: 0.9999 - val_loss: 0.0606 - val_acc: 0.9892\n",
      "Epoch 668/3000\n",
      "\n",
      "Epoch 00668: val_loss did not improve from 0.05972\n",
      "29400/29400 - 1s - loss: 0.0299 - acc: 0.9998 - val_loss: 0.0609 - val_acc: 0.9890\n",
      "Epoch 669/3000\n",
      "\n",
      "Epoch 00669: val_loss did not improve from 0.05972\n",
      "29400/29400 - 1s - loss: 0.0297 - acc: 0.9997 - val_loss: 0.0609 - val_acc: 0.9892\n",
      "Epoch 670/3000\n",
      "\n",
      "Epoch 00670: val_loss did not improve from 0.05972\n",
      "29400/29400 - 1s - loss: 0.0289 - acc: 0.9997 - val_loss: 0.0607 - val_acc: 0.9898\n",
      "Epoch 671/3000\n",
      "\n",
      "Epoch 00671: val_loss did not improve from 0.05972\n",
      "29400/29400 - 1s - loss: 0.0298 - acc: 0.9997 - val_loss: 0.0609 - val_acc: 0.9894\n",
      "Epoch 672/3000\n",
      "\n",
      "Epoch 00672: val_loss did not improve from 0.05972\n",
      "29400/29400 - 1s - loss: 0.0298 - acc: 0.9999 - val_loss: 0.0603 - val_acc: 0.9894\n",
      "Epoch 673/3000\n",
      "\n",
      "Epoch 00673: val_loss did not improve from 0.05972\n",
      "29400/29400 - 1s - loss: 0.0292 - acc: 0.9997 - val_loss: 0.0603 - val_acc: 0.9892\n",
      "Epoch 674/3000\n",
      "\n",
      "Epoch 00674: val_loss did not improve from 0.05972\n",
      "Restoring model weights from the end of the best epoch\n",
      "29400/29400 - 1s - loss: 0.0282 - acc: 0.9998 - val_loss: 0.0611 - val_acc: 0.9893\n",
      "Epoch 00674: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs=3000, batch_size=3000, validation_data=[x_val, y_val], \n",
    "                    callbacks = [checkpoint, early_stopping], verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1546,
     "status": "ok",
     "timestamp": 1584384717938,
     "user": {
      "displayName": "이재빈",
      "photoUrl": "",
      "userId": "06683534214657838443"
     },
     "user_tz": -540
    },
    "id": "mDqADBh5dvC3",
    "outputId": "dae51c4e-21c1-47ee-a11b-fe3aa226030d"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAacAAAEGCAYAAADBr1rTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFyfnnHOF8/8XmTV71F2aRwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, loss_ax = plt.subplots()\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "loss_ax.plot(history.history['loss'], 'y', label='train loss')\n",
    "loss_ax.plot(history.history['val_loss'], 'r', label='val loss')\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "loss_ax.legend(loc='upper left')\n",
    "\n",
    "acc_ax.plot(history.history['acc'], 'b', label='train acc')\n",
    "acc_ax.plot(history.history['val_acc'], 'g', label='val acc')\n",
    "acc_ax.set_ylabel('accuracy')\n",
    "acc_ax.legend(loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3496,
     "status": "ok",
     "timestamp": 1584384826478,
     "user": {
      "displayName": "이재빈",
      "photoUrl": "",
      "userId": "06683534214657838443"
     },
     "user_tz": -540
    },
    "id": "7LiekuHBsQXK",
    "outputId": "8d22fdd7-6cc6-476d-a8a4-4171cbecf6fe"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>57808</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4960</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35755</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15543</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48968</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Id  Category\n",
       "0  57808         8\n",
       "1   4960         0\n",
       "2  35755         5\n",
       "3  15543         3\n",
       "4  48968         8"
      ]
     },
     "execution_count": 60,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict_classes(X_test)\n",
    "sample_submission[\"Category\"] = pd.Series(pred)\n",
    "sample_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QfLYDCwFsYOg"
   },
   "outputs": [],
   "source": [
    "sample_submission.to_csv(\"keras4.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3FPaqf00dzYF"
   },
   "outputs": [],
   "source": [
    "prediction2 = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q7c51GPAjgOL"
   },
   "source": [
    "### 3. Ensemble (kaggle score: 0.98814)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GXdfrfE-jfR5"
   },
   "outputs": [],
   "source": [
    "final_pred = (prediction1 + prediction2)/2\n",
    "final_pred = np.argmax(final_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1206,
     "status": "ok",
     "timestamp": 1584384847307,
     "user": {
      "displayName": "이재빈",
      "photoUrl": "",
      "userId": "06683534214657838443"
     },
     "user_tz": -540
    },
    "id": "6LnRH6p5jx0i",
    "outputId": "8290ae17-11e8-48da-bbab-b2145feeb868"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>57808</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4960</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35755</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15543</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48968</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Id  Category\n",
       "0  57808         8\n",
       "1   4960         0\n",
       "2  35755         5\n",
       "3  15543         3\n",
       "4  48968         8"
      ]
     },
     "execution_count": 65,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission[\"Category\"] = pd.Series(final_pred)\n",
    "sample_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2XEIcH3pjzG_"
   },
   "outputs": [],
   "source": [
    "sample_submission.to_csv(\"keras5.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XgAh5gH6uKJN"
   },
   "source": [
    "### 4. CNN \n",
    "* optimizer RMSprop - (kaggle score: 0.99814)\n",
    "* optimizer RAdamOptimizer - (kaggle score: 0.99592)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K0JCQrPwuTBy"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1141,
     "status": "ok",
     "timestamp": 1584386524072,
     "user": {
      "displayName": "이재빈",
      "photoUrl": "",
      "userId": "06683534214657838443"
     },
     "user_tz": -540
    },
    "id": "xfWHBcy2k5ys",
    "outputId": "f5f47147-591c-47d9-b580-750ba098bbb9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29400, 784) (12600, 784) (29400,) (12600,)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=111)\n",
    "print(x_train.shape, x_val.shape, y_train.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EEDoh2pauO1U"
   },
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(-1, 28, 28,1)\n",
    "x_val = x_val.reshape(-1, 28, 28,1)\n",
    "y_train = to_categorical(y_train)\n",
    "y_val = to_categorical(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aoyx1DUUuR4i"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(64, (3,3), padding='same', input_shape=(28, 28, 1)),\n",
    "    tf.keras.layers.BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\"),\n",
    "    tf.keras.layers.LeakyReLU(alpha=0.1),\n",
    "    tf.keras.layers.Conv2D(64,  (3,3), padding='same'),\n",
    "    tf.keras.layers.BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\"),\n",
    "    tf.keras.layers.LeakyReLU(alpha=0.1),\n",
    "    tf.keras.layers.Conv2D(64,  (3,3), padding='same'),\n",
    "    tf.keras.layers.BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\"),\n",
    "    tf.keras.layers.LeakyReLU(alpha=0.1),\n",
    "\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Dropout(0.25),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(128, (3,3), padding='same'),\n",
    "    tf.keras.layers.BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\"),\n",
    "    tf.keras.layers.LeakyReLU(alpha=0.1),\n",
    "    tf.keras.layers.Conv2D(128, (3,3), padding='same'),\n",
    "    tf.keras.layers.BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\"),\n",
    "    tf.keras.layers.LeakyReLU(alpha=0.1),\n",
    "    tf.keras.layers.Conv2D(128, (3,3), padding='same'),\n",
    "    tf.keras.layers.BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\"),\n",
    "    tf.keras.layers.LeakyReLU(alpha=0.1),\n",
    "    \n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Dropout(0.25),    \n",
    "    \n",
    "    tf.keras.layers.Conv2D(256, (3,3), padding='same'),\n",
    "    tf.keras.layers.BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\"),\n",
    "    tf.keras.layers.LeakyReLU(alpha=0.1),\n",
    "    tf.keras.layers.Conv2D(256, (3,3), padding='same'),\n",
    "    tf.keras.layers.BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\"),##\n",
    "    tf.keras.layers.LeakyReLU(alpha=0.1),\n",
    "\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Dropout(0.25),\n",
    "    \n",
    "    \n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(256),\n",
    "    tf.keras.layers.LeakyReLU(alpha=0.1),\n",
    " \n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v3DDZaYBv36L"
   },
   "outputs": [],
   "source": [
    "optimizer = RMSprop(learning_rate=0.002, rho=0.9, momentum=0.1, epsilon=1e-07, centered=True, name='RMSprop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p_UttnwDy6Y1"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1248,
     "status": "ok",
     "timestamp": 1584388696450,
     "user": {
      "displayName": "이재빈",
      "photoUrl": "",
      "userId": "06683534214657838443"
     },
     "user_tz": -540
    },
    "id": "6TyIe-6A550t",
    "outputId": "fa81b851-0582-4fb2-e749-5fe558f91cb0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_8 (Conv2D)            (None, 28, 28, 64)        640       \n",
      "_________________________________________________________________\n",
      "batch_normalization_35 (Batc (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_35 (LeakyReLU)   (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 28, 28, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_36 (Batc (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_36 (LeakyReLU)   (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 28, 28, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_37 (Batc (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_37 (LeakyReLU)   (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 14, 14, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_38 (Batc (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_38 (LeakyReLU)   (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 14, 14, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_39 (Batc (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_39 (LeakyReLU)   (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 14, 14, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_40 (Batc (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_40 (LeakyReLU)   (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 7, 7, 256)         295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_41 (Batc (None, 7, 7, 256)         1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_41 (LeakyReLU)   (None, 7, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 7, 7, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_42 (Batc (None, 7, 7, 256)         1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_42 (LeakyReLU)   (None, 7, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_31 (Dropout)         (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 256)               590080    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_43 (LeakyReLU)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_43 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 1,926,794\n",
      "Trainable params: 1,924,106\n",
      "Non-trainable params: 2,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vArSapccyZET"
   },
   "outputs": [],
   "source": [
    "batch_size = 1024\n",
    "num_classes = 10\n",
    "epochs = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8DudVAVSyfPA"
   },
   "outputs": [],
   "source": [
    "datagen_train = ImageDataGenerator(rotation_range = 10,\n",
    "                                   width_shift_range = 0.25,\n",
    "                                   height_shift_range = 0.25,\n",
    "                                   shear_range = 0.1,\n",
    "                                   zoom_range = 0.4,\n",
    "                                   horizontal_flip = False)\n",
    "\n",
    "datagen_val = ImageDataGenerator() \n",
    "\n",
    "\n",
    "step_train = x_train.shape[0] // batch_size\n",
    "step_val = x_val.shape[0] // batch_size\n",
    "\n",
    "learning_rate_reduction = tf.keras.callbacks.ReduceLROnPlateau( \n",
    "    monitor='loss', factor=0.25,  patience=2, verbose=1, mode=\"auto\", min_delta=0.0001, cooldown=0, min_lr=0.00001)\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1007547,
     "status": "ok",
     "timestamp": 1584388538554,
     "user": {
      "displayName": "이재빈",
      "photoUrl": "",
      "userId": "06683534214657838443"
     },
     "user_tz": -540
    },
    "id": "PPMlbPVyv6jW",
    "outputId": "9670e7be-4448-4537-a486-943454a6e8f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "28/28 - 26s - loss: 1.5903 - accuracy: 0.4596 - val_loss: 2.3164 - val_accuracy: 0.1000\n",
      "Epoch 2/40\n",
      "28/28 - 25s - loss: 0.5435 - accuracy: 0.8202 - val_loss: 2.3035 - val_accuracy: 0.1000\n",
      "Epoch 3/40\n",
      "28/28 - 25s - loss: 0.2715 - accuracy: 0.9118 - val_loss: 1.4072 - val_accuracy: 0.6307\n",
      "Epoch 4/40\n",
      "28/28 - 25s - loss: 0.1978 - accuracy: 0.9348 - val_loss: 0.6192 - val_accuracy: 0.8713\n",
      "Epoch 5/40\n",
      "28/28 - 25s - loss: 0.1466 - accuracy: 0.9531 - val_loss: 0.4878 - val_accuracy: 0.9384\n",
      "Epoch 6/40\n",
      "28/28 - 25s - loss: 0.1371 - accuracy: 0.9539 - val_loss: 0.3570 - val_accuracy: 0.9818\n",
      "Epoch 7/40\n",
      "28/28 - 25s - loss: 0.1156 - accuracy: 0.9616 - val_loss: 0.2734 - val_accuracy: 0.9848\n",
      "Epoch 8/40\n",
      "28/28 - 25s - loss: 0.1364 - accuracy: 0.9547 - val_loss: 0.1765 - val_accuracy: 0.9877\n",
      "Epoch 9/40\n",
      "28/28 - 25s - loss: 0.0964 - accuracy: 0.9680 - val_loss: 0.4547 - val_accuracy: 0.8502\n",
      "Epoch 10/40\n",
      "28/28 - 25s - loss: 0.0935 - accuracy: 0.9681 - val_loss: 0.0737 - val_accuracy: 0.9920\n",
      "Epoch 11/40\n",
      "28/28 - 25s - loss: 0.0850 - accuracy: 0.9713 - val_loss: 0.0604 - val_accuracy: 0.9884\n",
      "Epoch 12/40\n",
      "28/28 - 25s - loss: 0.0798 - accuracy: 0.9730 - val_loss: 0.0506 - val_accuracy: 0.9869\n",
      "Epoch 13/40\n",
      "28/28 - 25s - loss: 0.0795 - accuracy: 0.9731 - val_loss: 0.0356 - val_accuracy: 0.9930\n",
      "Epoch 14/40\n",
      "28/28 - 25s - loss: 0.0775 - accuracy: 0.9740 - val_loss: 0.0308 - val_accuracy: 0.9910\n",
      "Epoch 15/40\n",
      "28/28 - 25s - loss: 0.0738 - accuracy: 0.9757 - val_loss: 0.0226 - val_accuracy: 0.9939\n",
      "Epoch 16/40\n",
      "28/28 - 25s - loss: 0.0685 - accuracy: 0.9768 - val_loss: 0.0191 - val_accuracy: 0.9938\n",
      "Epoch 17/40\n",
      "28/28 - 25s - loss: 0.0679 - accuracy: 0.9774 - val_loss: 0.1090 - val_accuracy: 0.9566\n",
      "Epoch 18/40\n",
      "28/28 - 25s - loss: 0.0622 - accuracy: 0.9791 - val_loss: 0.0200 - val_accuracy: 0.9941\n",
      "Epoch 19/40\n",
      "28/28 - 25s - loss: 0.0637 - accuracy: 0.9790 - val_loss: 0.0225 - val_accuracy: 0.9930\n",
      "Epoch 20/40\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "28/28 - 25s - loss: 0.0640 - accuracy: 0.9782 - val_loss: 0.0275 - val_accuracy: 0.9915\n",
      "Epoch 21/40\n",
      "28/28 - 25s - loss: 0.0536 - accuracy: 0.9823 - val_loss: 0.0107 - val_accuracy: 0.9971\n",
      "Epoch 22/40\n",
      "28/28 - 26s - loss: 0.0467 - accuracy: 0.9841 - val_loss: 0.0110 - val_accuracy: 0.9969\n",
      "Epoch 23/40\n",
      "28/28 - 25s - loss: 0.0448 - accuracy: 0.9847 - val_loss: 0.0102 - val_accuracy: 0.9967\n",
      "Epoch 24/40\n",
      "28/28 - 25s - loss: 0.0459 - accuracy: 0.9847 - val_loss: 0.0115 - val_accuracy: 0.9971\n",
      "Epoch 25/40\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "28/28 - 25s - loss: 0.0450 - accuracy: 0.9856 - val_loss: 0.0112 - val_accuracy: 0.9971\n",
      "Epoch 26/40\n",
      "28/28 - 25s - loss: 0.0416 - accuracy: 0.9858 - val_loss: 0.0096 - val_accuracy: 0.9977\n",
      "Epoch 27/40\n",
      "28/28 - 25s - loss: 0.0435 - accuracy: 0.9854 - val_loss: 0.0094 - val_accuracy: 0.9975\n",
      "Epoch 28/40\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "28/28 - 25s - loss: 0.0424 - accuracy: 0.9856 - val_loss: 0.0097 - val_accuracy: 0.9976\n",
      "Epoch 29/40\n",
      "28/28 - 25s - loss: 0.0370 - accuracy: 0.9874 - val_loss: 0.0094 - val_accuracy: 0.9977\n",
      "Epoch 30/40\n",
      "28/28 - 25s - loss: 0.0372 - accuracy: 0.9877 - val_loss: 0.0094 - val_accuracy: 0.9977\n",
      "Epoch 31/40\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "28/28 - 25s - loss: 0.0371 - accuracy: 0.9875 - val_loss: 0.0095 - val_accuracy: 0.9978\n",
      "Epoch 32/40\n",
      "28/28 - 25s - loss: 0.0412 - accuracy: 0.9857 - val_loss: 0.0094 - val_accuracy: 0.9977\n",
      "Epoch 33/40\n",
      "28/28 - 25s - loss: 0.0410 - accuracy: 0.9863 - val_loss: 0.0093 - val_accuracy: 0.9977\n",
      "Epoch 34/40\n",
      "28/28 - 25s - loss: 0.0403 - accuracy: 0.9864 - val_loss: 0.0093 - val_accuracy: 0.9977\n",
      "Epoch 35/40\n",
      "28/28 - 25s - loss: 0.0391 - accuracy: 0.9867 - val_loss: 0.0093 - val_accuracy: 0.9979\n",
      "Epoch 36/40\n",
      "28/28 - 25s - loss: 0.0370 - accuracy: 0.9869 - val_loss: 0.0094 - val_accuracy: 0.9978\n",
      "Epoch 37/40\n",
      "28/28 - 25s - loss: 0.0408 - accuracy: 0.9860 - val_loss: 0.0094 - val_accuracy: 0.9978\n",
      "Epoch 38/40\n",
      "28/28 - 25s - loss: 0.0398 - accuracy: 0.9866 - val_loss: 0.0093 - val_accuracy: 0.9978\n",
      "Epoch 39/40\n",
      "28/28 - 25s - loss: 0.0394 - accuracy: 0.9863 - val_loss: 0.0093 - val_accuracy: 0.9978\n",
      "Epoch 40/40\n",
      "28/28 - 25s - loss: 0.0391 - accuracy: 0.9864 - val_loss: 0.0093 - val_accuracy: 0.9978\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(datagen_train.flow(x_train, y_train, batch_size=batch_size),\n",
    "                              steps_per_epoch=len(x_train)//batch_size,\n",
    "                              epochs=epochs,\n",
    "                              validation_data=(x_val, y_val),\n",
    "                              validation_steps=50,\n",
    "                              callbacks=[learning_rate_reduction, es],\n",
    "                              verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1275,
     "status": "ok",
     "timestamp": 1584388592531,
     "user": {
      "displayName": "이재빈",
      "photoUrl": "",
      "userId": "06683534214657838443"
     },
     "user_tz": -540
    },
    "id": "eVc1c3FgwEHW",
    "outputId": "d378aa02-a75c-4b4b-9a17-5c86110cc3e7"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAacAAAEGCAYAAADBr1rTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nY8ykY8HJGGPMpGPByRhjzKTz/wGQDN+t0zxA2QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, loss_ax = plt.subplots()\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "loss_ax.plot(history.history['loss'], 'y', label='train loss')\n",
    "loss_ax.plot(history.history['val_loss'], 'r', label='val loss')\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "loss_ax.legend(loc='upper left')\n",
    "\n",
    "acc_ax.plot(history.history['accuracy'], 'b', label='train acc')\n",
    "acc_ax.plot(history.history['val_accuracy'], 'g', label='val acc')\n",
    "acc_ax.set_ylabel('accuracy')\n",
    "acc_ax.legend(loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7D0R5s5f7dAq"
   },
   "outputs": [],
   "source": [
    "test=X_test.reshape(-1,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WhwGnCPc0CeE"
   },
   "outputs": [],
   "source": [
    "prediction3 = model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7585,
     "status": "ok",
     "timestamp": 1584388875157,
     "user": {
      "displayName": "이재빈",
      "photoUrl": "",
      "userId": "06683534214657838443"
     },
     "user_tz": -540
    },
    "id": "fVIL8m8szSP_",
    "outputId": "7370b39d-913c-4836-d336-f375e4623a88"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>57808</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4960</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35755</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15543</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48968</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Id  Category\n",
       "0  57808         8\n",
       "1   4960         0\n",
       "2  35755         5\n",
       "3  15543         3\n",
       "4  48968         8"
      ]
     },
     "execution_count": 90,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict_classes(test)\n",
    "sample_submission[\"Category\"] = pd.Series(pred)\n",
    "sample_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SsGf3GOhzVjz"
   },
   "outputs": [],
   "source": [
    "sample_submission.to_csv(\"keras6.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KDloxTzVz-IB"
   },
   "source": [
    "### Ensemble\n",
    "* Linear + CNN - (kaggle score: 0.99092)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q-Mo7nfvz8lP"
   },
   "outputs": [],
   "source": [
    "final_pred = (prediction1 + prediction2 + prediction3)/3\n",
    "final_pred = np.argmax(final_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 675,
     "status": "ok",
     "timestamp": 1584388903648,
     "user": {
      "displayName": "이재빈",
      "photoUrl": "",
      "userId": "06683534214657838443"
     },
     "user_tz": -540
    },
    "id": "mYynY0A60Mum",
    "outputId": "b939e86f-85a5-4f2e-f415-43929af7fec6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>57808</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4960</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35755</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15543</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48968</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Id  Category\n",
       "0  57808         8\n",
       "1   4960         0\n",
       "2  35755         5\n",
       "3  15543         3\n",
       "4  48968         8"
      ]
     },
     "execution_count": 93,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission[\"Category\"] = pd.Series(final_pred)\n",
    "sample_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nEgkCbEs0RGg"
   },
   "outputs": [],
   "source": [
    "sample_submission.to_csv(\"keras7.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hC0yBTJ88vTy"
   },
   "source": [
    "### Ensemble - Hard Voting (kaggle score: 0.99740)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4RZZWv5h87sA"
   },
   "outputs": [],
   "source": [
    "keras5 = pd.read_csv(\"keras5.csv\") # Linear - (kaggle score: 0.98814)\n",
    "keras6 = pd.read_csv(\"keras6.csv\") # CNN: RMSprop - (kaggle score: 0.99814)\n",
    "keras7 = pd.read_csv(\"keras7.csv\") # Linear + CNN - (kaggle score: 0.99092)\n",
    "keras8 = pd.read_csv(\"keras8.csv\") # CNN: RAdamOptimizer - (kaggle score: 0.99592)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = keras5[\"Category\"]\n",
    "x2 = keras6[\"Category\"]\n",
    "x3 = keras7[\"Category\"]\n",
    "x4 = keras8[\"Category\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = []\n",
    "for a,b,c,d in zip(x1,x2,x3,x4): \n",
    "    if not (a==b==c==d):\n",
    "        k.append(np.argmax(np.bincount([a,b,c,d], weights=[0.15,0.4,0.15,0.3]))) # 가장 잘 나온 예측값에 큰 가중치 부여  \n",
    "    else: \n",
    "        k.append(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>57808</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4960</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35755</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15543</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48968</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Id  Category\n",
       "0  57808         8\n",
       "1   4960         0\n",
       "2  35755         5\n",
       "3  15543         3\n",
       "4  48968         8"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission[\"Category\"] = pd.Series(k)\n",
    "sample_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.to_csv(\"keras9.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNhOV63ZRTJOz0wwcLGOhvc",
   "collapsed_sections": [],
   "mount_file_id": "104KfkoRDLRlXkrxfQlKNFK57lSzqeTS5",
   "name": "keras3.ipynb",
   "provenance": [
    {
     "file_id": "1Ad1e61KLBj0mCHzLvZmvCN7xKsWaYQQx",
     "timestamp": 1584380144045
    },
    {
     "file_id": "1w6qcbSALZOzAQ54iwWFwhkXaC6sz455L",
     "timestamp": 1584365161410
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8rc1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
